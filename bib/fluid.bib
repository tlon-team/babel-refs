
@online{80000Hours2022ChinaRelatedAi,
	langid = {english},
	file = {~/Google Drive/library-html/80000Hours2022ChinaRelatedAi.html;~/Google Drive/library-pdf/80000Hours2022ChinaRelatedAi.pdf},
	date = {2022-02},
	author = {{80,000 Hours}},
	abstract = {Do you have a background in China? If so, you could have the opportunity to help solve one of the world’s biggest problems.},
	journaltitle = {80,000 Hours},
	timestamp = {2024-08-30 07:25:55 (GMT)},
	title = {China-related {AI} safety and governance paths},
	url = {https://80000hours.org/career-reviews/china-related-ai-safety-and-governance-paths/},
	urldate = {2024-08-30}
}

@online{80000Hours2023MostUsefulSkills,
	file = {~/Google Drive/library-html/80000Hours2023MostUsefulSkills.html;~/Google Drive/library-pdf/80000Hours2023MostUsefulSkills.pdf},
	abstract = {Early career, we recommend you focus on building useful skills. So which skills are most useful for solving important global problems? Here’s our list. We recommend choosing between these skills primarily based on which one you could be best at – your personal fit. Click through to the profiles to learn more about why we recommend them, how to get started learning them, and how to work out which is the best fit for you.},
	date = {2023-12},
	author = {{80,000 Hours}},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 08:26:48 (GMT)},
	title = {The most useful skills for making a difference},
	url = {https://80000hours.org/skills/},
	urldate = {2024-08-09}
}

@online{80000Hours2023WhyWhenAnd,
	file = {~/Google Drive/library-pdf/802023WhyWhenAnd.pdf;~/Google Drive/library-html/802023WhyWhenAnd.html},
	date = {2023-08},
	author = {{80,000 Hours}},
	abstract = {Working in policy is among the most effective ways to have a positive impact in areas like AI, biosecurity, animal welfare, or global health. Getting a policy master’s degree (e.g. in security studies or public policy) can help you pivot into or accelerate your policy career in the US. This two-part overview explains why, when, where, and how to get a policy master’s degree, with a focus on people who want to work in the US federal government. The first half focuses on the “why” and the “when” and alternatives to policy master’s. The second half considers criteria for choosing where to apply, specific degrees we recommend, how to apply, and how to secure funding.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-29 18:19:13 (GMT)},
	title = {Why, when, and how to get a {US} policy master's degree},
	url = {https://80000hours.org/career-reviews/us-policy-masters-degrees/},
	urldate = {2024-08-29}
}

@online{Aird2022CollectionOfWork,
	langid = {english},
	abstract = {This is a quickly made, low-effort post, but I'm hoping it'll be useful to some people anyway. Please let me know if you know of things I missed. I list things in order of recency, and I'm including some things that aren't primarily about the question in the title but are still quite relevant to it.},
	file = {~/Google Drive/library-pdf/Aird2022CollectionOfWork.pdf;~/Google Drive/library-html/Aird2022CollectionOfWork.html},
	author = {Aird, Michael},
	date = {2022-08-05},
	journaltitle = {Effective Altruism Forum},
	keywords = {Career choice, Cause prioritization, Policy, {AI} safety, Collections and resources, {AI} governance, California effect, European Union},
	shorttitle = {Collection of work on 'Should you focus on the {EU} if you're interested in {AI} governance for longtermist/x-risk reasons?},
	timestamp = {2024-08-30 08:43:24 (GMT)},
	title = {Collection of work on 'Should you focus on the {EU} if you're interested in {AI} governance for longtermist/x-risk reasons?'},
	url = {https://forum.effectivealtruism.org/posts/yNxn4HxDSMdRyrv6E},
	urldate = {2024-08-30}
}

@online{Alexander2013AllDebatesAre,
	abstract = {The article argues that many debates revolve around the question of what level of personal responsibility or caution is appropriate in a given situation. The author asserts that one reason for this phenomenon is that people often have different life experiences, leading them to perceive the world differently. For example, someone who grew up in a highly critical environment may be inclined towards self-blame, while someone from a supportive environment may be more prone to excuse their own failures. The author concludes that in order to have a productive discussion, it is important to recognize that participants are often coming from different backgrounds and perspectives, and that their views are likely informed by their own unique experiences. – AI-generated abstract.},
	file = {~/Google Drive/library-html/Alexander2013AllDebatesAre.html;~/Google Drive/library-pdf/Alexander2013AllDebatesAre.pdf},
	author = {Alexander, Scott},
	date = {2013-06-10},
	journaltitle = {Slate Star Codex},
	langid = {american},
	timestamp = {2024-08-22 17:59:59 (GMT)},
	title = {All debates are bravery debates},
	url = {https://slatestarcodex.com/2013/06/09/all-debates-are-bravery-debates/},
	urldate = {2024-08-22}
}

@Report{Aschenbrenner2024ExistentialRiskAnd,
	file = {~/Google Drive/library-pdf/Panzer2024ExistentialRiskAnd.pdf},
	number = {GPI Working Paper No. 13-2024},
	institution = {Global Priorities Institute and Department of Economics, University of Oxford},
	abstract = {Technology increases consumption but can create or mitigate existential risk to human civilization. Though accelerating technological development may increase the hazard rate (the risk of existential catastrophe per period) in the short run, two considerations suggest that acceleration typically decreases the risk that such a catastrophe ever occurs. First, acceleration decreases the time spent at each technology level. Second, given a policy option to sacrifice consumption for safety, acceleration motivates greater sacrifices by decreasing the marginal utility of consumption and increasing the value of the future. Under broad conditions, optimal policy thus produces an “existential risk Kuznets curve”, in which the hazard rate rises and then falls with the technology level and acceleration pulls forward a future in which risk is low. The negative impacts of acceleration on risk are offset only given policy failures, or direct contributions of acceleration to cumulative risk, that are sufficiently extreme.},
	author = {Aschenbrenner, Leopold and Trammell, Philip},
	date = {2024-05-22},
	journaltitle = {Global Priorities Institute},
	langid = {english},
	timestamp = {2024-07-15 11:17:38 (GMT)},
	title = {Existential risk and growth},
	url = {https://globalprioritiesinstitute.org/existential-risk-and-growth-aschenbrenner-and-trammell/},
	urldate = {2024-07-15}
}

@article{Azoulay2020AgeAndHigh,
	author = {Azoulay, Pierre and Jones, Benjamin F. and Kim, J. Daniel and
                  Miranda, Javier},
	title = {Age and high-growth entrepreneurship},
	volume = {2},
	number = {1},
	pages = {65--82},
	doi = {10.1257/aeri.20180582},
	url = {https://www.aeaweb.org/articles?id=10.1257/aeri.20180582},
	abstract = {Many observers, and many investors, believe that young people
                  are especially likely to produce the most successful new
                  firms. Integrating administrative data on firms, workers, and
                  owners, we study start-ups systematically in the United States
                  and find that successful entrepreneurs are middle-aged, not
                  young. The mean age at founding for the 1-in-1,000 fastest
                  growing new ventures is 45.0. The findings are similar when
                  considering high-technology sectors, entrepreneurial hubs, and
                  successful firm exits. Prior experience in the specific
                  industry predicts much greater rates of entrepreneurial
                  success. These findings strongly reject common hypotheses that
                  emphasize youth as a key trait of successful entrepreneurs.},
	date = {2020-03},
	issn = {2640-205X},
	journaltitle = {American Economic Review: Insights},
	keywords = {Investment Banking, Venture Capital, Brokerage, Ratings and
                  Ratings Agencies, Economics of the Elderly, Economics of the
                  Handicapped, Non-labor Market Discrimination,
                  Entrepreneurship, New Firms, Startups, Innovation and
                  Invention: Processes and Incentives},
	langid = {english},
	timestamp = {2024-09-17 10:19:21 (GMT)},
	urldate = {2024-09-17}
}

@Article{Bernardi2024SocietalAdaptationTo,
	langid = {english},
	number = {arXiv:2405.10295 [cs]},
	abstract = {Existing strategies for managing risks from advanced {AI} systems often focus on affecting what {AI} systems are developed and how they diffuse. However, this approach becomes less feasible as the number of developers of advanced {AI} grows, and impedes beneficial use-cases as well as harmful ones. In response, we urge a complementary approach: increasing societal adaptation to advanced {AI}, that is, reducing the expected negative impacts from a given level of diffusion of a given {AI} capability. We introduce a conceptual framework which helps identify adaptive interventions that avoid, defend against and remedy potentially harmful uses of {AI} systems, illustrated with examples in election manipulation, cyberterrorism, and loss of control to {AI} decision-makers. We discuss a three-step cycle that society can implement to adapt to {AI}. Increasing society's ability to implement this cycle builds its resilience to advanced {AI}. We conclude with concrete recommendations for governments, industry, and third-parties.},
	author = {Bernardi, Jamie and Mukobi, Gabriel and Greaves, Hilary and Heim, Lennart and Anderljung, Markus},
	date = {2024-05-16},
	keywords = {Computer Science - Computers and Society, Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
	publisher = {{arXiv}},
	timestamp = {2024-08-30 08:52:34 (GMT)},
	title = {Societal adaptation to advanced {AI}},
	url = {http://arxiv.org/abs/2405.10295},
	urldate = {2024-08-30}
}

@incollection{Bishop1998MethodologyForSafety,
	abstract = {A safety case is a requirement in many safety standards. Explicit safety cases are required for military systems, the off shore oil industry, rail transport and the nuclear industry. Furthermore, equivalent requirements can be found in other industry standards, such as IEC 1508 (which requires a “functional safety assessment”) the EN 292 Machinery Directive (which requires a “technical file”) and DO 178B for avionics (which requires an “accomplishment summary”).},
	file = {~/Google Drive/library-pdf/Bishop1998MethodologyForSafety.pdf},
	author = {Bishop, Peter and Bloomfield, Robin},
	booktitle = {Industrial Perspectives of Safety-critical Systems},
	date = {1998},
	doi = {10.1007/978-1-4471-1534-2_14},
	editor = {Redmill, Felix and Anderson, Tom},
	isbn = {9781447115342},
	langid = {english},
	location = {London},
	pages = {194--203},
	publisher = {Springer London},
	timestamp = {2024-08-30 08:49:44 (GMT)},
	title = {A methodology for safety case development},
	url = {http://link.springer.com/10.1007/978-1-4471-1534-2_14},
	urldate = {2024-08-30}
}

@article{Boenigk2016HappinessOfGiving,
	abstract = {This study explores the causal direction between happiness and charitable giving. Through the application of Cohen’s path analysis, the main purpose of the study is to find evidence which of the possible causal directions—the one from giving to happiness or from happiness to giving—is the more dominant one. To that aim the authors use data from the German Socio-Economic Panel 2009/10. In a sample of 6906 donors, the relationships between monetary giving and life satisfaction were assed. Furthermore, we controlled for different variables such as age, gender, and marital status. Contradictory to the hypotheses development, the results of the Cohen’s path analysis indicate that the causal direction from happiness to charitable giving is the more dominant one. Through the study and our initial results we contribute to theory by highlighting the ambiguous causal relationship between the focal constructs and provide a statistical method to investigate such unclear causal relationships. We discuss how happiness, particularly the affective aspect, can be utilized by nonprofit managers to raise fundraising effectiveness and suggest areas for further research.},
	author = {Boenigk, Silke and Mayr, Marcel Lee},
	title = {The happiness of giving: Evidence from the German
                  socioeconomic panel that happier people are more generous},
	volume = {17},
	number = {5},
	pages = {1825--1846},
	doi = {10.1007/s10902-015-9672-2},
	url = {http://link.springer.com/10.1007/s10902-015-9672-2},
	date = {2016-10},
	issn = {1389-4978, 1573-7780},
	journaltitle = {Journal of Happiness Studies},
	langid = {english},
	shortjournal = {J Happiness Stud},
	shorttitle = {The Happiness of Giving},
	timestamp = {2024-08-12 09:11:25 (GMT)},
	urldate = {2024-08-12}
}

@online{Bowerman2019WorkingInUs,
	file = {~/Google Drive/library-pdf/Bowerman2019WorkingInUs.pdf;~/Google Drive/library-html/Bowerman2019WorkingInUs.html;~/Google Drive/library-html/Bowerman2019WorkingInUs.html},
	eventdate = {2023-07},
	date = {2019-01},
	author = {Bowerman, Niel},
	abstract = {This podcast episode discusses the problem of global catastrophic biological risks (GCBRs) and potential solutions to reduce those risks. It explores the potential motivations behind states pursuing biological weapons programs, including fear of adversaries, the belief in strategic or tactical advantages, and the belief in impunity from accountability. The episode then introduces a three-part recipe to strengthen global biosecurity by increasing transparency, strengthening international investigative mechanisms, and ensuring meaningful accountability for violations.  The importance of proactively anticipating threats through biosecurity intelligence is highlighted. The episode also details the proposed creation of a new international organization dedicated to biosecurity, with a focus on strengthening governance of bioscience research and development. The episode emphasizes the need for a layered defense approach to reducing GCBRs, targeting multiple intervention points throughout the bioscience research lifecycle, including funding, research oversight, material supply, and publication. The podcast highlights the need to address the capabilities gap in international mechanisms for investigating the origins of high-consequence biological events and the proposed creation of a Joint Assessment Mechanism for that purpose. The episode further discusses the potential role of traditional law enforcement in detecting and disrupting bioterrorism threats, underscoring the need for strengthened collaboration between law enforcement and the scientific community. The episode ends with a discussion of career paths for those interested in contributing to the field of biosecurity and the importance of expanding the talent pool beyond the US and Western Europe. – AI-generated abstract},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2024-08-29 18:27:36 (GMT)},
	title = {Working in {US} {AI} policy},
	url = {https://80000hours.org/articles/us-ai-policy/},
	urldate = {2024-08-29}
}

@article{Bradford2023ConsciousnessAndWelfare,
	author = {Bradford, Gwen},
	title = {Consciousness and Welfare Subjectivity},
	volume = {57},
	number = {4},
	pages = {905--921},
	doi = {10.1111/nous.12434},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/nous.12434},
	abstract = {Many philosophers tacitly accept the View: consciousness is necessary for being a welfare subject. That is, in order to be an eligible bearer of welfare goods and bads, an entity must be capable of phenomenal consciousness. However, this paper argues that, in the absence of a compelling rationale, we are not licensed to accept the View, because doing so amounts to fallacious reasoning in theorizing about welfare: insisting on the View when consciousness is not in fact important for welfare value in a systematic and significant way is objectionably “consciousist.” As a result, the View does not advance our understanding of the value of consciousness. The paper further diagnoses why we may be attracted to the View, and what we should accept instead.},
	date = {2023-12},
	issn = {0029-4624, 1468-0068},
	journaltitle = {Noûs},
	langid = {english},
	shortjournal = {Nous},
	timestamp = {2024-07-10 17:34:31 (GMT)},
	urldate = {2024-07-10}
}

@online{Bradford2024ValorDeConciencia,
	translator = {Tlön},
	translation = {Shiller2024ValueOfConsciousness},
	langid = {spanish},
	date = {2024},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {El valor de la conciencia como cuestión central},
	author = {Bradford, Gwen},
	timestamp = {2024-07-10 17:46:54 (GMT)}
}

@book{Buchanan2022NewFireWar,
	file = {~/Google Drive/library-pdf/Buchanan2022NewFireWar.pdf},
	langid = {english},
	author = {Buchanan, Ben and Imbrie, Andrew},
	title = {The new fire: war, peace, and Democracy in the age of {AI}},
	publisher = {The {MIT} Press},
	abstract = {"Is {AI} a force for ill or for good? How does it work? This book analyzes the potential of {AI} in many sectors, including global security"--},
	date = {2022},
	isbn = {9780262046541},
	keywords = {Artificial intelligence},
	location = {Cambridge, Massachusetts},
	pagetotal = {331},
	shorttitle = {The new fire},
	timestamp = {2024-08-30 07:58:23 (GMT)}
}

@book{Caplan2007MythRationalVoter,
	abstract = {Voters are systematically irrational, and this irrationality has profound effects on policy. The public underestimates the benefits of markets, of dealing with foreigners, of conserving labor, and of past and future economic performance. Economists and the public disagree widely about economic policy, and this gap is primarily driven by systematic errors in the public’s thinking. This book argues that voters are irrational not because they are ignorant, but because they prioritize their psychological well-being over their material well-being. Because their votes are unlikely to change the outcome of an election, voters face no material cost for indulging their false beliefs. Politicians, for their part, are not primarily driven by self-interest, but by the desire to win elections by conforming to voter preferences. They therefore have little incentive to correct popular errors. The result is that democracies make a lot of bad decisions, driven by the public’s persistent misconceptions. – AI-generated abstract},
	database = {Tlön},
	location = {Princeton},
	title = {The myth of the rational voter: why democracies choose bad policies},
	langid = {english},
	isbn = {978-0-691-13873-2},
	publisher = {Princeton University Press},
	author = {Caplan, Bryan},
	date = 2007,
	file = {~/Google Drive/library-pdf/Caplan2007MythRationalVoter.pdf}
}

@online{CentreforEffectiveAltruism2021EffectiveAltruismHandbook,
	abstract = {Effective altruism is an approach to doing good that emphasizes using reason and evidence to determine the most effective ways to improve the world. This handbook introduces readers to the key concepts and arguments behind effective altruism, exploring a range of global problems and potential solutions. It examines the effectiveness mindset, the importance of considering differences in impact, the case for radical empathy, the significance of existential risks, the potential of longtermism, the risks and opportunities associated with artificial intelligence, the importance of critical thinking, and practical steps for putting effective altruism into practice. The handbook provides a framework for analyzing global challenges, evaluating potential interventions, and making informed decisions about how to make a positive difference in the world. — AI-generated abstract},
	file = {~/Google Drive/library-pdf/CentreforEffectiveAltruism2021EffectiveAltruismHandbook.pdf;~/Google Drive/library-html/CentreforEffectiveAltruism2021EffectiveAltruismHandbook.html},
	langid = {english},
	url = {https://forum.effectivealtruism.org/handbook},
	date = {2021},
	title = {The Effective Altruism Handbook},
	author = {Centre for Effective Altruism},
	timestamp = {2024-06-27 12:25:10 (GMT)}
}

@Report{Chancel2022InformeSobreDesigualdad,
	abstract = {La desigualdad de ingresos y riqueza ha aumentado en casi todos los países desde la década de 1980, especialmente en países como Estados Unidos, Rusia e India.  Esto se ha debido a programas de desregulación y liberalización que se han aplicado en distintos países.  La desigualdad global de ingresos ha disminuido en las últimas décadas, pero la desigualdad dentro de los países se ha incrementado considerablemente, haciendo que la desigualdad mundial se acerque a los niveles del siglo XX.  La desigualdad de riqueza también ha aumentado en la parte superior de la distribución, con un 1\% superior que se ha llevado el 38\% de toda la riqueza adicional acumulada desde mediados de la década de 1990.  Las desigualdades de género siguen siendo notables, con las mujeres ganando aproximadamente el 35\% de todos los ingresos laborales.  Las emisiones de CO2 también están desigualmente distribuidas, con el 10\% superior de los emisores responsables de cerca del 50\% de todas las emisiones.  El informe sugiere que para abordar estos desafíos del siglo XXI se necesita una redistribución significativa de las desigualdades de ingresos y riqueza, similar a lo que ocurrió con la creación de los estados de bienestar modernos en el siglo XX.  Se proponen políticas como un impuesto progresivo sobre el patrimonio para recaudar recursos y financiar la inversión en educación, salud y la transición ecológica. - Resumen generado por inteligencia artificial.},
	file = {~/Google Drive/library-pdf/Chancel2022InformeSobreDesigualdad.pdf},
	langid = {spanish},
	translation = {Chancel2022WorldInequalityReport},
	url = {https://wir2022.wid.world/www-site/uploads/2021/12/Summary_WorldInequalityReport2022_Spanish.pdf},
	date = {2022},
	institution = {World Inequality Lab},
	title = {Informe sobre la desigualdad global 2022},
	author = {Chancel, Lucas},
	timestamp = {2024-09-18 11:46:34 (GMT)}
}

@Report{Chancel2022WorldInequalityReport,
	abstract = {The world remains highly unequal in income and wealth, despite the decline of international inequalities in recent decades. The share of global income captured by the bottom 50\% of the population is only 8.5\%, while the richest 10\% hold 76\% of global wealth. This inequality is driven by both between-country and within-country disparities. In the 19th and early 20th century, colonial empires and unequal economic and political systems contributed to growing inequalities both between and within countries. The rise of welfare states in the mid-20th century led to a decline in within-country inequalities in most high-income countries, but since the 1980s, these have been rising again. This has partially offset the decline in between-country inequalities, leading to a stabilization of global inequalities. Global carbon inequality is similarly pronounced, with the top 10\% of emitters responsible for nearly half of all emissions.  The report emphasizes the role of progressive wealth taxes and international cooperation in reducing income and wealth inequality. It also highlights the need for a global asset register and a minimum tax on multinational profits. – AI-generated abstract.},
	file = {~/Google Drive/library-pdf/Chancel2022WorldInequalityReport.pdf},
	date = {2022},
	institution = {World Inequality Lab},
	author = {Chancel, Lucas},
	journaltitle = {World Inequality Report 2022},
	langid = {english},
	timestamp = {2024-09-18 09:33:11 (GMT)},
	title = {The World Inequality Report 2022},
	url = {https://wir2022.wid.world/},
	urldate = {2024-09-18}
}

@online{Clare2023GreatPowerWar,
	wordcount = {12231},
	file = {~/Google Drive/library-html/Clare2023GreatPowerWar.html;~/Google Drive/library-pdf/Clare2023GreatPowerWar.pdf},
	date = {2023-06},
	author = {Clare, Stephen},
	abstract = {Another great power conflict could cause unprecedented destruction. But there are ways to reduce the risks.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-08 22:26:53 (GMT)},
	title = {Great power war},
	url = {https://80000hours.org/problem-profiles/great-power-conflict/},
	urldate = {2024-08-08}
}

@online{Cotra2016AmfAndPopulation,
	file = {~/Google Drive/library-html/Cotra2016AmfAndPopulation.html;~/Google Drive/library-pdf/Cotra2016AmfAndPopulation.pdf},
	abstract = {If you are concerned your stance on population ethics does not align with the {GiveWell} median, please download an editable copy of {GiveWell}’s {CEA} and input your own values for rows 7, 53, 63, and 64, rather than discounting {GiveWell}'s bottom-line cost-effectiveness estimate by some factor to account for expected differences in population ethics. We lay out some considerations for how to do that in this blog post, with respect to the Against Malaria Foundation.},
	author = {Cotra, Ajeya},
	date = {2016-12-13},
	journaltitle = {The {GiveWell} Blog},
	langid = {american},
	timestamp = {2024-09-19 18:57:39 (GMT)},
	title = {{AMF} and Population Ethics},
	url = {https://blog.givewell.org/2016/12/12/amf-population-ethics/},
	urldate = {2024-09-19}
}

@Report{Creamer2022PovertyInUnited,
	langid = {english},
	abstract = {This report presents estimates of poverty in the United States using both the official poverty measure and the Supplemental Poverty Measure (SPM) for calendar year 2021. The official poverty measure defines poverty by comparing pretax money income to a poverty threshold that is adjusted by family composition. The SPM expands the official poverty measure by accounting for many of the government programs that are designed to assist low-income families, but are not included in the official poverty measure. The SPM also includes federal and state taxes and work and medical expenses. In addition, the SPM accounts for geographic variation in poverty thresholds, while the official poverty measure does not. The report highlights that the SPM poverty rate in 2021 was 7.8 percent, a decrease of 1.4 percentage points from 2020, while the official poverty rate remained largely unchanged from 2020. This divergence in poverty rates is attributed to the effects of the American Rescue Plan Act (ARPA), which provided households with additional resources in the form of stimulus payments, expansions to refundable tax credits, and pandemic-specific school lunch benefits. The SPM accounts for these policy changes, while the official poverty measure does not.  – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Creamer2022PovertyInUnited.pdf},
	url = {https://www.census.gov/content/dam/Census/library/publications/2022/demo/p60-277.pdf},
	date = {2022-09},
	institution = {United States Census Bureau},
	title = {Poverty in the United States: 2021},
	author = {Creamer, John and Shrider, Emily A. and Burns, Kalee and Chen, Frances},
	timestamp = {2024-09-19 18:33:06 (GMT)}
}

@online{Davidsen2023ConcreteProjectsFor,
	date = {2023-21-06},
	author = {Davidsen Buhl, Marie and Kraprayoon, Jam},
	abstract = {This is a list of twenty projects that we (Rethink Priorities’ Existential Security Team) think might be especially promising projects for reducing existential risk, based on our very preliminary and high-level research to identify and compare projects.

You can see an overview of the full list here. Here are five ideas we (tentatively) think seem especially promising:

• Improving info/cybersec at top AI labs
• AI lab coordination
• Facilitating people’s transition from AI capabilities research to AI safety research
• Field building for AI policy
• Finding market opportunities for biodefence-relevant technologies},
	journaltitle = {Rethink Priorities},
	langid = {english},
	timestamp = {2024-09-17 12:42:01 (GMT)},
	title = {Concrete projects for reducing existential risk},
	url = {https://rethinkpriorities.org/longtermism-research-notes/concrete-projects-for-reducing-existential-risk},
	urldate = {2024-09-17}
}

@online{Davidson2023WhatComputeCentric,
	date = {2023},
	author = {Davidson, Tom},
	abstract = {In March 2023, we hosted a presentation by Tom Davidson (Open Philanthropy) about his draft paper "What a Compute-Centric Framework Says About Takeoff Speeds". {GovAI}'s Acting Director Ben Garfinkel..},
	langid = {english},
	timestamp = {2024-08-21 23:25:31 (GMT)},
	title = {What a compute-centric framework says about takeoff speeds},
	url = {https://www.governance.ai/post/tom-davidson-compute-centric-framework-takeoff-speeds},
	urldate = {2024-08-21}
}

@online{Disease2017NeglectedTropicalDiseases,
	abstract = {Neglected Tropical Diseases (NTDs) are a group of parasitic and bacterial diseases that cause substantial illness for more than one billion people globally. Affecting the world's poorest people, NTDs impair physical and cognitive development, contribute to mother and child illness and death, make it difficult to farm or earn a living, and limit productivity in the workplace. As a result, NTDs trap the poor in a cycle of poverty and disease.},
	langid = {english},
	journaltitle = {Centers for Disease Control and Prevention},
	author = {{Centers for Disease Control and Prevention}},
	date = {2017-03-11},
	timestamp = {2024-09-19 13:41:32 (GMT)},
	title = {Neglected Tropical Diseases},
	url = {http://web.archive.org/web/20170311163901/https://www.cdc.gov/globalhealth/ntd/},
	urldate = {2024-09-19}
}

@Report{DoDResponsibleAIWorkingCouncil2022USDepartmentofDefense,
	langid = {english},
	abstract = {The U.S. Department of Defense (DoD) Responsible AI Working Council has developed a strategy and implementation pathway for responsible artificial intelligence (AI) in the DoD. The strategy is built upon the principles of fairness, accountability, transparency, and effectiveness. The implementation pathway outlines a set of steps that the DoD will take to ensure that AI systems are developed and used responsibly. This includes establishing a framework for ethical AI, developing best practices for AI development, and creating a culture of responsible AI within the DoD. The strategy and implementation pathway aim to guide the DoD's use of AI while mitigating risks and ensuring that AI systems are aligned with ethical and legal standards. – AI-generated abstract.},
	file = {~/Google Drive/library-pdf/DoDResponsibleAIWorkingCouncil2022USDepartmentofDefense.pdf},
	url = {https://media.defense.gov/2022/Jun/22/2003022604/-1/-1/0/Department-of-Defense-Responsible-Artificial-Intelligence-Strategy-and-Implementation-Pathway.PDF},
	date = {2022-06},
	institution = {U.S. Department of Defense},
	title = {Responsible Artificial Intelligence Strategy and Implementation Pathway},
	author = {{DoD Responsible AI Working Council}},
	timestamp = {2024-08-30 08:34:29 (GMT)}
}

@collection{Edmonds2016PhilosophersTakeWorld,
	langid = {english},
	abstract = {Every day the news shows us provoking stories about what's going on in the world, about events which raise moral questions and problems. In Philosophers Take On the World a team of philosophers get to grips with a variety of these controversial issues, from the amusing to the shocking, in short, engaging, often controversial pieces. Covering topics from guns to abortion, the morality of drinking alone, hating a sports team, and being rude to cold callers, the essays will make you think again about the judgments we make on a daily basis and the ways in which we choose to conduct our lives. Philosophers Take On the World is based on the blog run by the Uehiro Centre for Practical Ethics at the University of Oxford, one of the world's leading centres for applied ethics.},
	database = {Tlön},
	location = {Oxford},
	title = {Philosophers take on the world},
	isbn = {978-0-19-875372-8},
	pagetotal = 250,
	publisher = {Oxford University Press},
	editor = {Edmonds, David},
	date = 2016,
	note = {{OCLC}: ocn940520567},
	file = {~/Google Drive/library-pdf/Edmonds2016PhilosophersTakeWorld.pdf}
}

@book{Edmonds2018FilosofosMiranHacia,
	translation = {Edmonds2016PhilosophersTakeWorld},
	database = {Tlön},
	langid = {spanish},
	date = {2018},
	publisher = {Cátedra},
	address = {Madrid},
	isbn = {9788437638911},
	editor = {Edmonds, David},
	title = {Los filósofos miran hacia el mundo},
	timestamp = {2023-05-25 21:06:27 (GMT)}
}

@Article{Erdil2024ExplosiveGrowthFrom,
	journaltitle = {arXiv},
	file = {~/Google Drive/library-pdf/Erdil2024ExplosiveGrowthFrom.pdf},
	langid = {english},
	abstract = {We examine whether substantial {AI} automation could accelerate global economic growth by about an order of magnitude, akin to the economic growth effects of the Industrial Revolution. We identify three primary drivers for such growth: 1) the scalability of an {AI} "labor force" restoring a regime of increasing returns to scale, 2) the rapid expansion of an {AI} labor force, and 3) a massive increase in output from rapid automation occurring over a brief period of time. Against this backdrop, we evaluate nine counterarguments, including regulatory hurdles, production bottlenecks, alignment issues, and the pace of automation. We tentatively assess these arguments, finding most are unlikely deciders. We conclude that explosive growth seems plausible with {AI} capable of broadly substituting for human labor, but high confidence in this claim seems currently unwarranted. Key questions remain about the intensity of regulatory responses to {AI}, physical bottlenecks in production, the economic value of superhuman abilities, and the rate at which {AI} automation could occur.},
	author = {Erdil, Ege and Besiroglu, Tamay},
	date = {2024-07-15},
	doi = {10.48550/arXiv.2309.11690},
	eprint = {2309.11690 [econ, q-fin]},
	eprinttype = {arxiv},
	keywords = {Economics - General Economics},
	publisher = {{arXiv}},
	shorttitle = {Explosive growth from {AI} automation},
	timestamp = {2024-08-20 02:11:22 (GMT)},
	title = {Explosive growth from {AI} automation: A review of the arguments},
	url = {http://arxiv.org/abs/2309.11690},
	urldate = {2024-08-20}
}

@online{EuropeanSummerProgramonRationality2021WhatESPR,
	database = {Tlön},
	title = {What is {ESPR}},
	abstract = {The European Summer Program on Rationality (ESPR) is an immersive summer workshop for mathematically talented students aged 16-19. The program, modeled after the American equivalent, SPARC, covers a wide range of topics including game theory, cryptography, mathematical logic, AI safety, communication styles, and cognitive science. ESPR's goal is to help students develop rigorous quantitative skills while providing them with a toolbox of useful concepts and practical techniques applicable to all walks of life. The program's curriculum includes lectures from intellectuals in cutting-edge fields, with past speakers including renowned theoretical scientist Scott Aaronson and existential risk researcher Shahar Avin.  ESPR's tuition, room, and board are free for all admitted students due to a generous grant from the Open Philanthropy Project. Need-based travel scholarships are also available. – AI-generated abstract.},
	langid = {english},
	url = {https://espr-camp.org/},
	journaltitle = {{ESPR}},
	author = {{European Summer Program on Rationality}},
	date = 2021,
	file = {~/Google Drive/library-pdf/EuropeanSummerProgramonRationality2021WhatESPR.pdf}
}

@online{Fenwick2023AiGovernanceAnd,
	file = {~/Google Drive/library-pdf/Fenwick2023AiGovernanceAnd.pdf;~/Google Drive/library-html/Fenwick2023AiGovernanceAnd.html},
	eventdate = {2024-08-22},
	date = {2023-06},
	author = {Fenwick, Cody},
	abstract = {Advanced AI systems could have massive impacts on humanity and potentially pose global catastrophic risks. There are opportunities in the broad field of AI governance to positively shape how society responds to and prepares for the challenges posed by the technology. Given the high stakes, pursuing this career path could be many people’s highest-impact option. But they should be very careful not to accidentally exacerbate the threats rather than mitigate them.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2024-08-28 17:28:13 (GMT)},
	title = {{AI} governance and policy},
	url = {https://80000hours.org/career-reviews/ai-policy-and-strategy/},
	urldate = {2024-08-28}
}

@online{Fenwick2024GouvernanceDeLia,
	translation = {Fenwick2023AiGovernanceAnd},
	langid = {french},
	date = {2024},
	title = {Gouvernance de l'IA et politique},
	journaltitle = {Bibliothèque Altruisme Efficace},
	author = {Fenwick, Cody},
	timestamp = {2024-08-28 17:39:58 (GMT)}
}

@online{Fischer2024AmaRethinkPriorities,
	file = {~/Google Drive/library-pdf/Fischer2024AmaRethinkPriorities.pdf;~/Google Drive/library-html/Fischer2024AmaRethinkPriorities.html},
	langid = {english},
	abstract = {Rethink Priorities’ Worldview Investigation Team ({WIT}) will run an Ask Me Anything ({AMA}). We’ll reply on the 7th and 8th of August. Please put your questions in the comments below!
{WIT} is Hayley Clatterbuck, Bob Fischer, Arvo Munoz Moran, David Moss, and Derek Shiller. Our team exists to improve resource allocation within and beyond the effective altruism movement, focusing on tractable, high-impact questions that bear on strategic priorities. We try to take action-relevant philosophical, methodological, and strategic problems and turn them into manageable, modelable problems. Our projects have included:},
	author = {Fischer, Bob and Clatterbuck, Hayley and Shiller, Derek and {Arvomm} and Moss, David},
	date = {2024-07-31},
	journaltitle = {Effective Altruism Forum},
	keywords = {Cause prioritization, Ask Me Anything, Rethink Priorities},
	shorttitle = {{AMA}},
	timestamp = {2024-07-31 13:06:50 (GMT)},
	title = {{AMA}: Rethink Priorities’ Worldview Investigation Team},
	url = {https://forum.effectivealtruism.org/posts/ipxePnfnxsRuasZW2},
	urldate = {2024-07-31}
}

@Book{Friedrich1962NomosIvLiberty,
	langid = {english},
	abstract = {The article explores the evolution of Western political freedom from the Renaissance and Reformation to the present day. The author argues that freedom is not a static concept but evolves through distinct historical stages. Each stage is characterized by a different understanding of freedom, authority, and order. The Renaissance and Reformation marked a transition from a system of multiple authorities to a single, centralized authority. The Enlightenment period, marked by the rise of absolutism, saw the emergence of a more generalized concept of freedom, with the state playing a dominant role. The revolutionary period, beginning in the mid-eighteenth century, witnessed the transition from freedom as a subordinate to a dominant value. The twentieth century, characterized by the rise of democracy and the clash between individual and collective freedoms, saw the demise of a unified conception of freedom. The author concludes that in the contemporary era, freedom is a dimension of human thought and action, with its character and extent dependent on the particular processes in which it is engaged. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Friedrich1962NomosIvLiberty.pdf},
	address = {New York},
	publisher = {Atherton Press},
	date = {1962},
	title = {Nomos IV: Liberty},
	editor = {Friedrich, Carl J.},
	timestamp = {2024-07-08 08:52:53 (GMT)}
}

@article{Gilbert2009WhyBrainTalks,
	file = {~/Google Drive/library-pdf/Gilbert2009WhyBrainTalks.pdf},
	author = {Gilbert, Daniel T. and Wilson, Timothy D.},
	title = {Why the brain talks to itself: sources of error in emotional
                  prediction},
	volume = {364},
	number = {1521},
	pages = {1335--1341},
	doi = {10.1098/rstb.2008.0305},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2008.0305},
	abstract = {People typically choose pleasure over pain. But how do they know which of these their choices will entail? The brain generates mental simulations (previews) of future events, which produce affective reactions (premotions), which are then used as a basis for forecasts (predictions) about the future event's emotional consequences. Research shows that this process leads to systematic errors of prediction. We review evidence indicating that these errors can be traced to five sources.},
	date = {2009-05-12},
	issn = {0962-8436, 1471-2970},
	journaltitle = {Philosophical Transactions of the Royal Society B:
                  Biological Sciences},
	langid = {english},
	shortjournal = {Phil. Trans. R. Soc. B},
	shorttitle = {Why the brain talks to itself},
	timestamp = {2024-08-12 08:26:23 (GMT)},
	urldate = {2024-08-12}
}

@online{GivingWhatWeCan2020WhatIsEffective,
	file = {~/Google Drive/library-pdf/GivingWhatWeCan2020WhatIsEffective.pdf;~/Google Drive/library-html/GivingWhatWeCan2020WhatIsEffective.html},
	date = {2020},
	journaltitle = {Giving What We Can},
	author = {Giving What We Can},
	abstract = {Effective altruism is a philosophy and social movement that promotes the use of reason and evidence to find the most effective ways to improve the world. It emphasizes doing good in a way that maximizes positive impact, considering the limited resources available. This approach involves identifying the most pressing global challenges, such as poverty, disease, and climate change, and then prioritizing actions that are likely to have the greatest impact. The effective altruism movement encourages individuals to donate to effective charities, pursue careers that align with their values, and engage in research and advocacy to further understanding and action in this area.  – AI-generated abstract.},
	langid = {english},
	timestamp = {2024-06-27 12:12:54 (GMT)},
	title = {What is effective altruism?},
	url = {https://www.givingwhatwecan.org/what-is-effective-altruism},
	urldate = {2024-06-27}
}

@collection{Gould2023RoutledgeHandbookOf,
	file = {~/Google Drive/library-pdf/Gould2023RoutledgeHandbookOf.pdf},
	langid = {english},
	abstract = {The Routledge Handbook of Translation and Activism provides an accessible, diverse and ground-breaking overview of literary, cultural, and political translation across a range of activist contexts.As the first extended collection to offer perspectives on translation and activism from a global perspective, this handbook includes case studies and histories of oppressed and marginalised people from over twenty different languages. The contributions will make visible the role of translation in promoting and enabling social change, in promoting equality, in fighting discrimination, in supporting human rights, and in challenging autocracy and injustice across the Middle East, Africa, Latin America, East Asia, the {US} and Europe.With a substantial introduction, thirty-one chapters, and an extensive bibliography, this Handbook is an indispensable resource for all activists, translators, students and researchers of translation and activism within translation and interpreting studies},
	date = {2023},
	edition = {First issued in paperback},
	editor = {Gould, Rebecca Ruth and Tahmasebian, Kayvan},
	isbn = {9781032570174},
	location = {London New York},
	pagetotal = {543},
	publisher = {Routledge, Taylor \& Franics Group},
	series = {Routledge handbooks in translation and interpreting studies},
	timestamp = {2024-08-04 15:19:42 (GMT)},
	title = {The Routledge handbook of translation and activism}
}

@online{Handbook2022BayesRuleGuide,
	url = {https://forum.effectivealtruism.org/posts/zQgpke5cZgbZWnLfw},
	journaltitle = {Effective Altruism Forum},
	database = {Tlön},
	abstract = {Bayes' rule or Bayes' theorem is the law of probability governing the strength of evidence —the rule saying how much to revise our probabilities (change our minds) when we learn a new fact or observe new evidence.},
	date = {2022},
	title = {Bayes' rule: Guide},
	author = {{EA Handbook}},
	langid = {english}
}

@book{Harari2017SapiensDeAnimales,
	translation = {Harari2015SapiensBriefHistory},
	langid = {spanish},
	author = {Harari, Yuval N.},
	title = {Sapiens: de animales a dioses: breve historia de la humanidad},
	publisher = {Debate},
	date = {2017},
	isbn = {9788499926223},
	location = {Barcelona},
	shorttitle = {Sapiens},
	timestamp = {2024-07-16 11:35:28 (GMT)},
	translator = {Ros, Joandoménec}
}

@Report{Health2022NiceHealthTechnology,
	file = {~/Google Drive/library-pdf/Health2022NiceHealthTechnology.pdf},
	langid = {english},
	eventdate = {2021-10-31},
	date = {2022-01-31},
	institution = {National Institute of Health and Care Excellence},
	author = {{National Institute of Health and Care Excellence}},
	abstract = {This guide describes the methods and processes, including expected timescales, that {NICE} follows when carrying out health technology evaluations. The methods and processes are designed to produce robust guidance for the {NHS} in an open, transparent and timely way, with appropriate contribution from stakeholders. Organisations invited to contribute to health technology evaluation development should read this manual in conjunction with the {NICE} health technology evaluation topic selection: the manual. All documents are available on the {NICE} website.},
	shorttitle = {Introduction to health technology evaluation {\textbar} {NICE} health technology evaluations},
	timestamp = {2024-09-19 18:52:09 (GMT)},
	title = {{NICE} health technology evaluations: the manual},
	url = {https://www.nice.org.uk/process/pmg36/chapter/introduction-to-health-technology-evaluation},
	urldate = {2024-09-19}
}

@online{Hilton2024HowYouCan,
	wordcount = {9909},
	file = {~/Google Drive/library-pdf/Hilton2024HowYouCan.pdf},
	date = {2024-06-14},
	author = {Hilton, Benjamin},
	abstract = {Nuclear weapons that are armed at all times have the potential to kill hundreds of millions of people directly, and billions due to subsequent effects on agriculture. They pose some unknown risk of human extinction through the potential for a 'nuclear winter' and a social collapse from which we never recover. There are many examples in history of moments in which the US or Russia came close to accidentally or deliberately using their nuclear weapons.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2024-06-26 21:10:40 (GMT)},
	title = {Nuclear weapons},
	url = {https://80000hours.org/problem-profiles/nuclear-security/},
	urldate = {2024-06-26}
}

@Article{Ho2016GenerativeAdversarialImitation,
	langid = {english},
	number = {arXiv:1606.03476 [cs]},
	abstract = {Consider learning a policy from example expert behavior, without interaction with the expert or access to reinforcement signal. One approach is to recover the expert's cost function with inverse reinforcement learning, then extract a policy from that cost function with reinforcement learning. This approach is indirect and can be slow. We propose a new general framework for directly extracting a policy from data, as if it were obtained by reinforcement learning following inverse reinforcement learning. We show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks, from which we derive a model-free imitation learning algorithm that obtains significant performance gains over existing model-free methods in imitating complex behaviors in large, high-dimensional environments.},
	author = {Ho, Jonathan and Ermon, Stefano},
	date = {2016-06-10},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	publisher = {{arXiv}},
	timestamp = {2024-08-14 15:12:03 (GMT)},
	title = {Generative adversarial imitation learning},
	url = {http://arxiv.org/abs/1606.03476},
	urldate = {2024-08-14}
}

@online{Ho2024AlgorithmicProgressIn,
	file = {~/Google Drive/library-html/Ho2024AlgorithmicProgressIn.html;~/Google Drive/library-pdf/Ho2024AlgorithmicProgressIn.pdf},
	abstract = {Progress in language model performance surpasses what we’d expect from merely increasing computing resources, occurring at a pace equivalent to doubling computational power every 5 to 14 months.},
	author = {Ho, Anson},
	date = {2024-03-12},
	journaltitle = {Epoch {AI}},
	langid = {english},
	timestamp = {2024-08-21 15:03:26 (GMT)},
	title = {Algorithmic Progress in Language Models},
	url = {https://epochai.org/blog/algorithmic-progress-in-language-models},
	urldate = {2024-08-21}
}

@book{Hollis1974PressureFromWithout,
	abstract = {Pressure groups in early Victorian England were not a form of mob rule, but were regarded as a legitimate, even essential, means of influencing government and Parliament. While these groups were often disparaged as being artificial and illegitimate expressions of public opinion, they were nonetheless instrumental in shaping legislation on a wide range of issues, including slavery, land reform, and education. The book examines the relationship of pressure groups to the evolving concept of ‘the people’ in early Victorian politics and explores how they operated and achieved their goals. Their success was largely dependent upon the ability of their leaders to co-opt and organize different segments of the population, to cultivate the support of sympathetic MPs, and to generate public opinion through a variety of tactics, such as public meetings, petitioning, and the press. The essays in this collection examine the tactics, strategies, and impact of a number of pressure groups involved in campaigns to address a range of issues that were at the forefront of Victorian social and political consciousness. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Hollis1974PressureFromWithout.pdf},
	langid = {english},
	author = {Hollis, Patricia},
	title = {Pressure from without in early Victorian England},
	publisher = {Edward Arnold},
	date = {1974},
	isbn = {9780713157307},
	keywords = {Pressure groups, History, Great Britain, Great Britain, Politics and government, 1837-1901},
	location = {London},
	pagetotal = {334},
	timestamp = {2024-07-08 08:40:01 (GMT)}
}

@online{Hutchinson2021PossibleGapsIn,
	file = {~/Google Drive/library-pdf/Hutchinson2021PossibleGapsIn.pdf;~/Google Drive/library-html/Hutchinson2021PossibleGapsIn.html},
	langid = {english},
	abstract = {I’m interested in having a better sense of what new kinds of projects should be set up within the EA community. I think I tend to bias towards scepticism, and so find it easier to get a sense of what worries me about projects than which projects I’m excited about. I thought I’d have a go at writing out a few ideas which seem promising to me. I’d love to hear people’s views on them, and also to read other people’s lists. To provide a nudge towards others producing such lists, I’ve also shared some of the prompts I used to come up with the thoughts below. 

I haven’t put a lot of time into this list, so I’m not suggesting any, let alone all, are great ideas - they’re just ones I’d be interested to hear more discussion around. I’m also biased by the corners of EA and the world I’ve spent most time in, for example academia.},
	author = {Hutchinson, Michelle},
	date = {2021-01-22},
	journaltitle = {Effective Altruism Forum},
	timestamp = {2024-09-17 10:25:30 (GMT)},
	title = {Possible gaps in the {EA} community},
	url = {https://forum.effectivealtruism.org/posts/3YqQnH8hsiwsfLoZw},
	urldate = {2024-09-17}
}

@online{Ingram2024NalinDavid,
	abstract = {David Nalin, a physician who began his career working in the Pakistan-SEATO Cholera Research Lab in Dhaka, Bangladesh, discovered that oral rehydration therapy (ORT) could be used to treat cholera patients. This discovery was a major breakthrough in the field of medicine, as it allowed for a simple, cost-effective way to treat a deadly disease that had previously been difficult to manage.  Nalin's key insight was that the volume of oral rehydration solution administered to patients should match or slightly exceed the volume of fluid lost through vomiting and diarrhea. He and his colleague, Richard Cash, conducted a clinical trial that demonstrated the efficacy of ORT. ORT has since been shown to be effective in treating a wide range of diarrheal illnesses, not just cholera, and has saved millions of lives around the world. – AI-generated abstract.},
	file = {~/Google Drive/library-html/Ingram2024NalinDavid.html;~/Google Drive/library-pdf/Ingram2024NalinDavid.pdf},
	langid = {english},
	date = {2022},
	journaltitle = {ScienceHeroes.com},
	author = {Ingram, April},
	timestamp = {2024-08-14 09:26:24 (GMT)},
	title = {Nalin, David},
	url = {https://www.scienceheroes.com/nailin},
	urldate = {2024-08-14}
}

@article{Judge2010RelationshipBetweenPay,
	file = {~/Google Drive/library-pdf/Judge2010RelationshipBetweenPay.pdf},
	abstract = {Whereas the motivational aspects of pay are well-documented, the notion that high pay leads to high levels of satisfaction is not without debate. The current study used meta-analysis to estimate the population correlation between pay level and measures of pay and job satisfaction. Cumulating across 115 correlations from 92 independent samples, results suggested that pay level was correlated .15 with job satisfaction and .23 with pay satisfaction. Various moderators of the relationship were investigated. Despite the popular theorizing, results suggest that pay level is only marginally related to satisfaction. Theoretical and practical implications of the results are discussed.},
	author = {Judge, Timothy A. and Piccolo, Ronald F. and Podsakoff, Nathan
                  P. and Shaw, John C. and Rich, Bruce L.},
	title = {The relationship between pay and job satisfaction: a
                  meta-analysis of the literature},
	volume = {77},
	number = {2},
	pages = {157--167},
	doi = {10.1016/j.jvb.2010.04.002},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0001879110000722},
	date = {2010-10},
	issn = {00018791},
	journaltitle = {Journal of Vocational Behavior},
	langid = {english},
	shortjournal = {Journal of Vocational Behavior},
	shorttitle = {The relationship between pay and job satisfaction},
	timestamp = {2024-08-12 08:57:56 (GMT)},
	urldate = {2024-08-12}
}

@online{Karnofsky2023TakingLeaveOf,
	abstract = {Holden Karnofsky, CEO of Open Philanthropy, announces he will be taking a leave of absence from the organization to work directly on AI safety. Karnofsky explains that he believes the risk of transformative AI being developed within the decade is too high and that working directly on AI safety is a more effective way to address this risk than grantmaking. He also mentions that he has always aspired to help build multiple organizations rather than running one indefinitely. During his leave, Karnofsky will focus on AI safety standards and explore other interventions to reduce AI risk. He plans to join or start another organization if he decides to work full-time on AI safety. Karnofsky expresses his intention to be transparent about his conflict of interest, which arises from his wife's equity ownership in OpenAI and Anthropic. He also discusses the possibility of his role being limited to advisory work due to the conflict of interest. – AI-generated abstract.},
	langid = {english},
	file = {~/Google Drive/library-pdf/Karnofsky2023TakingLeaveOf.pdf;~/Google Drive/library-html/Karnofsky2023TakingLeaveOf.html},
	author = {Karnofsky, Holden},
	date = {2023-02-23},
	journaltitle = {Effective Altruism Forum},
	timestamp = {2024-08-31 13:59:02 (GMT)},
	title = {Taking a leave of absence from Open Philanthropy to work on {AI} safety},
	url = {https://forum.effectivealtruism.org/posts/aJwcgm2nqiZu6zq2S/taking-a-leave-of-absence-from-open-philanthropy-to-work-on},
	urldate = {2024-08-31}
}

@book{Kelly2012FoundInTranslation,
	abstract = {Translation. It's everywhere we look, but seldom seen—until now. Found in Translation reveals the surprising and complex ways that translation shapes the world. Covering everything from holy books to hurricane warnings and poetry to peace treaties, Nataly Kelly and Jost Zetzscheoffer language lovers and pop culture fans alike an insider's view of the ways in which translation spreads culture, fuels the global economy, prevents wars, and stops the outbreak of disease, with examples that include how translation plays a key role at Google, NASA, the United Nations, the World Cup, and more.},
	file = {~/Google Drive/library-pdf/Kelly2012FoundInTranslation.pdf},
	langid = {english},
	author = {Kelly, Nataly and Zetzsche, Jost Oliver},
	title = {Found in translation: how language shapes our lives and transforms the world},
	publisher = {Perigee},
	date = {2012},
	isbn = {9780399537974},
	keywords = {Translating and interpreting, Social aspects, Sociolinguistics},
	location = {New York},
	pagetotal = {270},
	shorttitle = {Found in translation},
	timestamp = {2024-08-04 14:46:51 (GMT)}
}

@article{Kemp2008TestOfPeak,
	file = {~/Google Drive/library-pdf/Kemp2008TestOfPeak.pdf},
	abstract = {Forty-nine students went on vacation for an average of 7 days and sent daily text messages about the happiness they had experienced over the previous 24 h. After their vacation, they were questioned on the overall happiness they had experienced and were asked to recall the daily record of their happiness. The duration of the vacation had no effect on the subsequent evaluations, and participants were not able to recall the detail of their day-to-day changes in happiness. A number of summary measures provided reasonable prediction of the recalled overall happiness of the vacation. The peak-end rule was not an outstandingly good predictor. Overall, the results indicate much reconstruction of the affective states.},
	author = {Kemp, Simon and Burt, Christopher D. B. and Furneaux, Laura},
	title = {A test of the peak-end rule with extended autobiographical
                  events},
	volume = {36},
	number = {1},
	pages = {132--138},
	doi = {10.3758/MC.36.1.132},
	url = {http://link.springer.com/10.3758/MC.36.1.132},
	date = {2008-01},
	issn = {0090-502X, 1532-5946},
	journaltitle = {Memory \& Cognition},
	langid = {english},
	shortjournal = {Memory \& Cognition},
	timestamp = {2024-08-12 08:40:48 (GMT)},
	urldate = {2024-08-12}
}

@article{Killingsworth2023IncomeAndEmotional,
	author = {Killingsworth, Matthew A. and Kahneman, Daniel and Mellers,
                  Barbara},
	title = {Income and Emotional Well-Being: a Conflict Resolved},
	volume = {120},
	number = {10},
	pages = {e2208661120},
	doi = {10.1073/pnas.2208661120},
	url = {https://pnas.org/doi/10.1073/pnas.2208661120},
	abstract = {Do larger incomes make people happier? Two authors of the
                  present paper have published contradictory answers. Using
                  dichotomous questions about the preceding day, [Kahneman and
                  Deaton, Proc. Natl. Acad. Sci. U.S.A.  107 , 16489–16493
                  (2010)] reported a flattening pattern: happiness increased
                  steadily with log(income) up to a threshold and then
                  plateaued. Using experience sampling with a continuous scale,
                  [Killingsworth, Proc. Natl. Acad. Sci. U.S.A.  118 ,
                  e2016976118 (2021)] reported a linear-log pattern in which
                  average happiness rose consistently with log(income). We
                  engaged in an adversarial collaboration to search for a
                  coherent interpretation of both studies. A reanalysis of
                  Killingsworth’s experienced sampling data confirmed the
                  flattening pattern only for the least happy people. Happiness
                  increases steadily with log(income) among happier people, and
                  even accelerates in the happiest group. Complementary
                  nonlinearities contribute to the overall linear-log
                  relationship. We then explain why Kahneman and Deaton
                  overstated the flattening pattern and why Killingsworth failed
                  to find it. We suggest that Kahneman and Deaton might have
                  reached the correct conclusion if they had described their
                  results in terms of unhappiness rather than happiness; their
                  measures could not discriminate among degrees of happiness
                  because of a ceiling effect. The authors of both studies
                  failed to anticipate that increased income is associated with
                  systematic changes in the shape of the happiness distribution.
                  The mislabeling of the dependent variable and the incorrect
                  assumption of homogeneity were consequences of practices that
                  are standard in social science but should be questioned more
                  often. We flag the benefits of adversarial collaboration.},
	date = {2023-03-07},
	issn = {0027-8424, 1091-6490},
	journaltitle = {Proceedings of the National Academy of Sciences},
	langid = {english},
	shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
	shorttitle = {Income and emotional well-being},
	timestamp = {2024-08-12 09:00:56 (GMT)},
	urldate = {2024-08-12}
}

@Article{Kleimer1981HowNotTo,
	file = {~/Google Drive/library-pdf/Kleimer1981HowNotTo.pdf},
	langid = {english},
	pages = {89-111},
	number = {30},
	date = {1981},
	journaltitle = {CoEvolution Quarterly},
	title = {How not to commit suicide},
	author = {Kleimer, Art},
	timestamp = {2024-09-14 12:50:25 (GMT)}
}

@collection{Knauff2021HandbookOfRationality,
	file = {~/Google Drive/library-pdf/Knauff2021HandbookOfRationality.pdf},
	langid = {english},
	abstract = {The first reference on rationality that integrates accounts from psychology and philosophy, covering descriptive and normative theories from both disciplines.Both analytic philosophy and cognitive psychology have made dramatic advances in understanding rationality, but there has been little interaction between the disciplines. This volume offers the first integrated overview of the state of the art in the psychology and philosophy of rationality. Written by leading experts from both disciplines, The Handbook of Rationality covers the main normative and descriptive theories of rationality--how people ought to think, how they actually think, and why we often deviate from what we can call rational. It also offers insights from other fields such as artificial intelligence, economics, the social sciences, and cognitive neuroscience. The Handbook proposes a novel classification system for researchers in human rationality, and it creates new connections between rationality research in philosophy, psychology, and other disciplines. Following the basic distinction between theoretical and practical rationality, the book first considers the theoretical side, including normative and descriptive theories of logical, probabilistic, causal, and defeasible reasoning. It then turns to the practical side, discussing topics such as decision making, bounded rationality, game theory, deontic and legal reasoning, and the relation between rationality and morality. Finally, it covers topics that arise in both theoretical and practical rationality, including visual and spatial thinking, scientific rationality, how children learn to reason rationally, and the connection between intelligence and rationality.},
	date = {2021},
	editor = {Knauff, Markus and Spohn, Wolfgang},
	isbn = {9780262361859},
	location = {Cambridge},
	note = {{OCLC}: 1286368422},
	publisher = {The {MIT} Press},
	timestamp = {2024-06-26 14:52:23 (GMT)},
	title = {The handbook of rationality}
}

@online{Koehler2023ShouldYouWork,
	abstract = {This article discusses the potential risks and benefits of working at a frontier AI company, which is defined as a company leading the development and deployment of the most powerful AI models. It argues that while such roles can provide high impact by contributing to AI safety research and governance, they also carry a significant risk of accelerating the development of AI systems that could pose catastrophic risks to humanity. The article notes that the vast majority of roles at frontier AI companies likely contribute to the acceleration of AI progress, even those not directly involved in research and engineering. However, it also acknowledges that some roles, such as AI alignment research, might have net risk-reducing effects despite contributing to AI progress. The article stresses the importance of carefully considering the specific role, the company's overall responsibility, and the individual's own values and risk tolerance when deciding whether to work at a frontier AI company. It also emphasizes the importance of continued engagement with the broader AI safety community, vigilance, and readiness to leave the role if it becomes clear that the work is harmful.  – AI-generated abstract.},
	file = {~/Google Drive/library-pdf/Koehler2023ShouldYouWork.pdf;~/Google Drive/library-html/Koehler2023ShouldYouWork.html},
	eventdate = {2024-08-08},
	date = {2023-06},
	author = {Koehler, Arden and {80,000 Hours team}},
	journaltitle = {80,000 Hours},
	langid = {american},
	shorttitle = {Should you work at a frontier {AI} company?},
	timestamp = {2024-08-29 18:37:46 (GMT)},
	title = {Should you work at a frontier {AI} company? - Career review},
	url = {https://80000hours.org/career-reviews/working-at-an-ai-lab/},
	urldate = {2024-08-29}
}

@online{Kollipara2017EarthWontAs,
	abstract = {The sun is gradually getting brighter and hotter, which will eventually cause Earth's water to evaporate and end life as we know it.  Recent climate models have revised estimates of this "runaway greenhouse" effect, suggesting that it will not occur for at least 1 billion to 1.5 billion years, hundreds of millions of years later than previously predicted. These models incorporate more realistic factors, such as clouds and regional variations in moisture, leading to a slower warming rate. The revised estimates imply a longer lifespan for Earth and suggest a larger potential for habitable planets around sun-like stars. However, the models still assume constant carbon dioxide levels, and the actual timescale could be even longer if natural carbon sequestration processes accelerate. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Kollipara2017EarthWontAs.pdf;~/Google Drive/library-html/Kollipara2017EarthWontAs.html},
	langid = {english},
	journaltitle = {Science},
	author = {Kollipara, Puneet},
	date = {2017-03-04},
	timestamp = {2024-09-19 19:02:04 (GMT)},
	title = {Earth Won't Die as Soon as Thought {\textbar} Science {\textbar} {AAAS}},
	url = {https://www.science.org/content/article/earth-wont-die-soon-thought},
	urldate = {2024-09-19}
}

@article{Lee1999ParachutingForCharity,
	langid = {english},
	author = {Lee, C. T. and Williams, P. and Hadden, W. A.},
	title = {Parachuting for charity: is it worth the money? a 5-year audit
                  of parachute injuries in Tayside and the cost to the {NHS}},
	volume = {30},
	number = {4},
	pages = {283--287},
	doi = {10.1016/s0020-1383(99)00083-2},
	abstract = {All parachute injuries from two local parachute centres over
                  a 5-year period were analysed. Of 174 patients with injuries
                  of varying severity, 94\% were first-time
                  charity-parachutists. The injury rate in charity-parachutists
                  was 11\% at an average cost of 3751 Pounds per casualty.
                  Sixty-three percent of casualties who were
                  charity-parachutists required hospital admission, representing
                  a serious injury rate of 7\%, at an average cost of 5781
                  Pounds per patient. The amount raised per person for charity
                  was 30 Pounds. Each pound raised for charity cost the {NHS}
                  13.75 Pounds in return. Parachuting for charity costs more
                  money than it raises, carries a high risk of serious personal
                  injury and places a significant burden on health resources.},
	date = {1999-05},
	issn = {0020-1383},
	journaltitle = {Injury},
	keywords = {Accidents, Aviation, Adolescent, Adult, Aviation, Charities,
                  Fund Raising, Health Care Costs, Hospitals, Public, Humans,
                  Incidence, Middle Aged, Scotland, Shoes, State Medicine,
                  Wounds and Injuries},
	pmid = {10476298},
	shortjournal = {Injury},
	shorttitle = {Parachuting for charity},
	timestamp = {2024-09-18 07:05:05 (GMT)}
}

@book{Levy2004NewDivisionOf,
	file = {~/Google Drive/library-pdf/Levy2004NewDivisionOf.pdf},
	abstract = {As the current recession ends, many workers will not be returning to the jobs they once held—those jobs are gone. In The New Division of Labor, Frank Levy and Richard Murnane show how computers are changing the employment landscape and how the right kinds of education can ease the transition to the new job market.
The book tells stories of people at work—a high-end financial advisor, a customer service representative, a pair of successful chefs, a cardiologist, an automotive mechanic, the author Victor Hugo, floor traders in a London financial exchange. The authors merge these stories with insights from cognitive science, computer science, and economics to show how computers are enhancing productivity in many jobs even as they eliminate other jobs—both directly and by sending work offshore. At greatest risk are jobs that can be expressed in programmable rules—blue collar, clerical, and similar work that requires moderate skills and used to pay middle-class wages. The loss of these jobs leaves a growing division between those who can and cannot earn a good living in the computerized economy. Left unchecked, the division threatens the nation’s democratic institutions.
The nation’s challenge is to recognize this division and to prepare the population for the high-wage/high-skilled jobs that are rapidly growing in number—jobs involving extensive problem solving and interpersonal communication. Using detailed examples—a second grade classroom, an IBM managerial training program, Cisco Networking Academies—the authors describe how these skills can be taught and how our adjustment to the computerized workplace can begin in earnest.},
	langid = {english},
	author = {Levy, Frank and Murnane, Richard J.},
	title = {The new division of labor: how computers are creating the next job market},
	publisher = {Princeton University Press},
	date = {2004},
	isbn = {9780691119724},
	location = {New York},
	shorttitle = {The new division of labor},
	timestamp = {2024-09-20 09:49:02 (GMT)}
}

@online{Lewis2023SayHowMuch,
	abstract = {The author argues that using comparative language such as "overrated" or "underrated" is a poor substitute for direct assessments of the value of something. He proposes that instead of saying "forecasting is underrated", one should directly state how good forecasting is, for example, by giving it a score out of ten. He argues that this approach is more precise and avoids the ambiguity inherent in comparative language. For example, two people might agree that forecasting is underrated, but they may be disagreeing on how good forecasting is and on how other people rate it. The author concedes that direct assessments are more difficult to formulate and require more effort, but ultimately yield a more concrete and nuanced understanding of the topic at hand. – AI-generated abstract.},
	file = {~/Google Drive/library-html/Lewis2023SayHowMuch.html;~/Google Drive/library-pdf/Lewis2023SayHowMuch.pdf},
	langid = {english},
	author = {Lewis, Gregory},
	date = {2023-12-28},
	journaltitle = {Effective Altruism Forum},
	keywords = {Forecasting, Epistemology, Reasoning transparency, Transparency, Opinion},
	timestamp = {2024-06-25 15:45:08 (GMT)},
	title = {Say how much, not more or less versus someone else},
	url = {https://forum.effectivealtruism.org/posts/XatixHPupjA5DCCm8},
	urldate = {2024-06-25}
}

@book{Mackay2011SustainableEnergyWithout,
	abstract = {The best-selling book on understanding sustainable energy and how we can make energy plans that add up.},
	file = {~/Google Drive/library-pdf/Mackay2011SustainableEnergyWithout.pdf},
	langid = {english},
	author = {{MacKay}, David J. C.},
	title = {Sustainable energy - without the hot air},
	publisher = {{UIT} Cambridge},
	date = {2011},
	isbn = {9780954452933},
	location = {Cambridge},
	timestamp = {2024-09-19 10:06:38 (GMT)}
}

@collection{Millan2013RoutledgeHandbookOf,
	abstract = {The Routledge Handbook of Translation Studies provides a comprehensive, state-of-the-art account of the complex ﬁeld of translation studies. Written by leading specialists from around the world, this volume brings together authoritative original articles on pressing issues including: the current status of the ﬁeld and its interdisciplinary nature; the problematic deﬁnition of the object of study; the various theoretical frameworks; the research methodologies available. The Handbook also includes discussion of the most recent theoretical, descriptive and applied research, as well as glimpses of future directions within the ﬁeld and an extensive up-to-date bibliography. The Routledge Handbook of Translation Studies is an indispensable resource for postgraduate students of translation studies.},
	file = {~/Google Drive/library-pdf/Millan2013RoutledgeHandbookOf.pdf},
	langid = {english},
	date = {2013},
	editor = {Millán, Carmen and Bartrina, Francesca},
	isbn = {9780203102893},
	location = {Milton Park, Abingdon},
	publisher = {Routledge},
	series = {Routledge handbooks in applied linguistics},
	timestamp = {2024-08-04 14:53:32 (GMT)},
	title = {The Routledge handbook of translation studies}
}

@online{Muehlhauser202312TentativeIdeas,
	abstract = {The article presents twelve tentative ideas for US AI policy aimed at reducing existential risk from advanced artificial intelligence.  The author acknowledges that these are his own personal opinions, not necessarily those of Open Philanthropy or Anthropic, and that further analysis or developments could easily change his opinion. These policy options are offered in no particular order and include: software export controls, hardware security features on cutting-edge chips, tracking and licensing of cutting-edge chips and big compute clusters, tracking and licensing of frontier AI models, information security requirements, testing and evaluation requirements for frontier models, funding for alignment, interpretability, and model evaluation research and development, funding for defensive information security research and development, creating an antitrust safe harbor for AI safety and security collaboration, requiring AI incident reporting, clarifying liability for AI developers, and creating means for rapid shutdown of large compute clusters and training runs. The author believes these policies would plausibly also be good to implement in other jurisdictions, but that the US is a good place to start due to its leading role in AI development. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Muehlhauser202312TentativeIdeas.pdf;~/Google Drive/library-html/Muehlhauser202312TentativeIdeas.html},
	date = {2023-04-17},
	author = {Muehlhauser, Luke},
	journaltitle = {Open Philanthropy},
	langid = {english},
	timestamp = {2024-08-30 07:31:32 (GMT)},
	title = {12 Tentative Ideas for {US} {AI} Policy},
	url = {https://www.openphilanthropy.org/research/12-tentative-ideas-for-us-ai-policy/},
	urldate = {2024-08-30}
}

@book{Nagel1986ViewNowhere,
	langid = {english},
	location = {Oxford},
	title = {The view from nowhere},
	isbn = {0-19-503668-9},
	abstract = {Human beings have the unique ability to view the world in a detached way: We can think about the world in terms that transcend our own experience or interest, and consider the world from a vantage point that is, in Nagel's words, "nowhere in particular". At the same time, each of us is a particular person in a particular place, each with his own "personal" view of the world, a view that we can recognize as just one aspect of the whole. How do we reconcile these two standpoints--intellectually, morally, and practically? To what extent are they irreconcilable and to what extent can they be integrated? Thomas Nagel's ambitious and lively book tackles this fundamental issue, arguing that our divided nature is the root of a whole range of philosophical problems, touching, as it does, every aspect of human life. He deals with its manifestations in such fields of philosophy as: the mind-body problem, personal identity, knowledge and skepticism, thought and reality, free will, ethics, the relation between moral and other values, the meaning of life, and death. Excessive objectification has been a malady of recent analytic philosophy, claims Nagel, it has led to implausible forms of reductionism in the philosophy of mind and elsewhere. The solution is not to inhibit the objectifying impulse, but to insist that it learn to live alongside the internal perspectives that cannot be either discarded or objectified. Reconciliation between the two standpoints, in the end, is not always possible.},
	publisher = {Oxford University Press},
	author = {Nagel, Thomas},
	date = 1986,
	note = {{ISSN}: 0195056442},
	file = {~/Google Drive/library-pdf/Nagel1989ViewNowhere.pdf}
}

@book{Nagel1991EqualityPartiality,
	abstract = {This essay explores the central problem of political theory: reconciling the standpoint of the collectivity with the standpoint of the individual. It begins by arguing that the ethical basis of political theory stems from a division within each individual between the personal and impersonal standpoints. The former represents individual desires, interests, and projects, while the latter represents the claims of the collectivity, producing a powerful demand for universal impartiality and equality. The author argues that the search for a political ideal requires an acceptable integration of these two standpoints, noting that the problem of designing institutions that do justice to the equal importance of all persons without making unacceptable demands on individuals has not been solved. The essay goes on to consider the problem of utopianism, arguing that a political theory is Utopian in the pejorative sense if it describes a form of collective life that humans could not lead through any feasible process of social and mental development. A non-utopian solution requires a proper balance between the ideal and persuasive functions of political theory, demanding both impersonal and personal justification. The author explores the concept of political legitimacy, arguing that its ideal is that the use of state power should be capable of being authorized by each citizen, ultimately requiring unanimous agreement on basic principles and institutions. The essay concludes that a harmonious combination of an acceptable political ideal and acceptable standards of personal morality is difficult to achieve, arguing that the problem of designing institutions that do justice to the equal importance of all persons without making unacceptable demands on individuals remains unsolved. – AI-generated abstract.},
	langid = {english},
	location = {Oxford},
	title = {Equality and partiality},
	isbn = {0-19-506967},
	publisher = {Oxford University Press},
	author = {Nagel, Thomas},
	date = 1991,
	file = {~/Google Drive/library-pdf/NagelEqualityPartiality.pdf}
}

@book{Nagel1995OtherMindsCritical,
	langid = {english},
	abstract = {Other Minds gathers Nagel's most important critical essays and reviews on the philosophy of mind, ethics, and political philosophy. The pieces here discuss philosophers from Aristotle to Wittgenstein, as well as contemporary legal and political theorists like Robert Nozick and Ronald Dworkin. Also included are essays tracing Nagel's ongoing participation in debates surrounding the mind-body problem - lucid, opinionated responses to Daniel Dennett, John Searle, and others. Running through Other Minds is Nagel's overriding conviction that the most compelling intellectual issues of our day - from the scientific foundations of Freudian theory to the vicissitudes of judicial interpretation - are essentially philosophical problems. Vital, accessible, and controversial, these writings represent the best of one of our leading thinkers.},
	location = {Oxford},
	title = {Other minds: Critical essays, 1969-1994},
	isbn = {0-19-509008-X},
	publisher = {Oxford University Press},
	author = {Nagel, Thomas},
	date = 1995,
	file = {~/Google Drive/library-pdf/NagelOtherMinds.pdf}
}

@online{Ngo2023AgiSafetyCareer,
	file = {~/Google Drive/library-pdf/Ngo2023AgiSafetyCareer.pdf;~/Google Drive/library-html/Ngo2023AgiSafetyCareer.html},
	langid = {english},
	abstract = {People often ask me for career advice related to {AGI} safety. This post (now also translated into Spanish) summarizes the advice I most commonly give. I’ve split it into three sections: general mindset, alignment research and governance work. For each of the latter two, I start with high-level advice aimed primarily at students and those early in their careers, then dig into more details of the field. See also this post I wrote two years ago, containing a bunch of fairly general career advice.General {mindsetIn} order to have a big impact on the world you need to find a big lever. This document assumes that you think, as I do, that {AGI} safety is the biggest such lever. There are many ways to pull on that lever, though—from research and engineering to operations and field-building to politics and communications. I encourage you to choose between these based primarily on your personal fit—a combination of what you're really good at and what you really enjoy. In my opinion the difference between being a great versus a mediocre fit swamps other differences in the impactfulness of most pairs of {AGI}-safety-related jobs.How should you find your personal fit? To start, you should focus on finding work where you can get fast feedback loops. That will typically involve getting hands-on or doing some kind of concrete project (rather than just reading and learning) and seeing how quickly you can make progress. Eventually, once you've had a bunch of experience, you might notice a feeling of confusion or frustration: why is everyone else missing the point, or doing so badly at this? (Though note that a few top researchers commented on a draft to say that they didn't have this experience.) For some people that involves investigating a specific topic (for me, the question “what’s the best argument that {AGI} will be misaligned?“); for others it's about applying skills like conscientiousness (e.g. "why can't others just go through all the obvious steps?") Being excellent seldom feels like you’re excellent, because your own abilities set your baseline for what feels normal.What if you have that experience for something you don't enjoy doing? I expect that this is fairly rare, because being good at something is often very enjoyable. But in those cases, I'd suggest trying it until you observe that even a string of successes doesn't make you excited about what you're doing; and at that point, probably trying to pivot (although this is pretty dependent on the specific details).Lastly: {AGI} safety is a young and small field; there’s a lot to be done, and still very few people to do it. I encourage you to have agency when it comes to making things happen: most of the time the answer to “why isn’t this seemingly-good thing happening?” or “why aren’t we 10x better at this particular thing?” is “because nobody’s gotten around to it yet”. And the most important qualifications for being able to solve a problem are typically the ability to notice it},
	author = {Ngo, Richard},
	date = {2023-05-01},
	journaltitle = {{AI} Alignment Forum},
	keywords = {{AI} Alignment Fieldbuilding, Careers, {AI}},
	timestamp = {2024-08-30 07:45:07 (GMT)},
	title = {{AGI} safety career advice — {AI} Alignment Forum},
	url = {https://www.alignmentforum.org/posts/ho63vCb2MNFijinzY/agi-safety-career-advice},
	urldate = {2024-08-30}
}

@report{Nist2024ArtificialIntelligenceRisk,
	abstract = {In collaboration with the private and public sectors, NIST has developed a framework to better manage risks to individuals, organizations, and society associated with artificial intelligence (AI). The NIST AI Risk Management Framework (AI RMF) is intended for voluntary use and to improve the ability to incorporate trustworthiness considerations into the design, development, use, and evaluation of AI products, services, and systems.},
	file = {~/Google Drive/library-pdf/Nist2024ArtificialIntelligenceRisk.pdf},
	langid = {english},
	author = {{NIST}},
	date = {2024-07-26},
	doi = {10.6028/NIST.AI.600-1},
	institution = {National Institute of Standards and Technology},
	location = {Gaithersburg, {MD}},
	number = {{NIST} {AI} 600-1},
	shorttitle = {Artificial Intelligence Risk Management Framework},
	timestamp = {2024-08-30 08:14:28 (GMT)},
	title = {Artificial Intelligence Risk Management Famework: Generative Artificial Intelligence Profile},
	url = {https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf},
	urldate = {2024-08-30}
}

@online{Obrien2024AiGoldRush,
	author = {O'Brien, Matt},
	abstract = {Artificial intelligence systems like {ChatGPT} could soon run out of what keeps making them smarter — the tens of trillions of words that people have written and shared online.},
	date = {2024-06-06},
	journaltitle = {{AP} News},
	langid = {english},
	timestamp = {2024-08-21 14:59:49 (GMT)},
	title = {{AI} 'gold rush' for chatbot training data could run out of human-written text},
	url = {https://apnews.com/article/ai-artificial-intelligence-training-data-running-out-9676145bac0d30ecce1513c20561b87d},
	urldate = {2024-08-21}
}

@online{Ord2023ShapingHumanitysLongterm,
	file = {~/Google Drive/library-pdf/Ord2023ShapingHumanitysLongterm.pdf},
	langid = {english},
	abstract = {This chapter presents a mathematical framework for classifying and comparing the different kinds of effects present-day actions could have upon the longterm future of humanity. The starting point is the longterm trajectory of humanity, understood as how the instantaneous value of humanity unfolds over time. In this framework, the value of our future is equal to the area under this curve and the value of altering our trajectory is equal to the area between the original curve and the altered curve. This allows us to compare the value of reducing existential risk to other ways our actions might improve the longterm future, such as improving the values that guide humanity, or advancing progress.},
	author = {Ord, Toby},
	date = {2023-07-17},
	journaltitle = {Effective Altruism Forum},
	keywords = {Cause prioritization, Existential risk, Trajectory change, Indirect long-term effects, Long-term future, Longtermism},
	timestamp = {2024-07-15 11:08:23 (GMT)},
	title = {Shaping humanity's longterm trajectory},
	url = {https://forum.effectivealtruism.org/posts/Doa69pezbZBqrcucs},
	urldate = {2024-07-15}
}

@online{Ord2024PrecipiceRevisited,
	file = {~/Google Drive/library-html/Ord2024PrecipiceRevisited.html;~/Google Drive/library-pdf/Ord2024PrecipiceRevisited.pdf},
	langid = {english},
	abstract = {This lecture is an update to the existential risk landscape since the publication of The Precipice. It reviews four of the most serious risks to humanity: climate change, nuclear war, pandemics, and artificial intelligence. Climate change risk is currently decreasing due to progress in controlling carbon emissions, and a better understanding of climate sensitivity is reducing the chances of extreme warming. However, the risk of nuclear war has increased due to the Russian invasion of Ukraine and a potential new arms race. The COVID-19 pandemic exposed weaknesses in global institutions and preparedness, but also spurred innovation in vaccine development. Further, there has been a significant increase in the public's awareness of the dangers of advanced AI, leading to a shift in government policy and an emphasis on regulating AI development. While the overall picture of existential risk is complex, with some risks increasing and others decreasing, there is a growing awareness of the dangers and a developing movement to address these risks.},
	author = {Ord, Toby},
	date = {2024-07-11},
	journaltitle = {Effective Altruism Global},
	keywords = {{AI} safety, Biosecurity, Existential risk, Climate change, Nuclear security, Video},
	timestamp = {2024-07-30 16:54:03 (GMT)},
	title = {The Precipice revisited},
	url = {https://forum.effectivealtruism.org/posts/iKLLSYHvnhgcpoBxH},
	urldate = {2024-07-30}
}

@online{Ord2024ReconsiderandoPrecipice,
	langid = {spanish},
	translation = {Ord2024PrecipiceRevisited},
	date = {2024},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {Reconsiderando *The Precipice*},
	author = {Ord, Toby},
	timestamp = {2024-07-31 09:56:15 (GMT)}
}

@online{Ord2024SobreValorDe,
	langid = {spanish},
	translation = {Ord2024ValueOfAdvancing},
	date = {2024},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {Sobre el valor de impulsar el progreso},
	author = {Ord, Toby},
	timestamp = {2024-07-16 16:39:15 (GMT)}
}

@online{Ord2024ValueOfAdvancing,
	file = {~/Google Drive/library-html/Ord2024ValueOfAdvancing.html;~/Google Drive/library-pdf/Ord2024ValueOfAdvancing.pdf},
	langid = {english},
	abstract = {I show how a standard argument for advancing progress is extremely sensitive to how humanity’s story eventually ends. Whether advancing progress is ultimately good or bad depends crucially on whether it also advances the end of humanity. Because we know so little about the answer to this crucial question, the case for advancing progress is undermined. I suggest we must either overcome this objection through improving our understanding of these connections between progress and human extinction or switch our focus to advancing certain kinds of progress relative to others — changing where we are going, rather than just how soon we get there.},
	author = {Ord, Toby},
	date = {2024-07-10},
	journaltitle = {Effective Altruism Forum},
	keywords = {Existential risk, Differential progress, Long-term future, Longtermism, Progress studies, Trajectory change},
	timestamp = {2024-07-15 10:40:41 (GMT)},
	title = {On the value of advancing progress},
	url = {https://forum.effectivealtruism.org/posts/XKeQbizpDP45CYcYc},
	urldate = {2024-07-15}
}

@online{Pearce2016DeterminingNumber,
	abstract = {Every source quoted an amazing number of transfusions and potential lives saved in countries and regions worldwide. High impact years began around 1955 and calculations are loosely based on 1 life saved per 2.7 units of blood transfused. In the USA alone an estimated 4.5 million lives are saved each year. From these data I determined that 1.5\% of the population was saved annually by blood transfusions and I applied this percentage on population data from 1950-2008 for North America, Europe, Australia, New Zealand, and parts of Asia and Africa. This rate may inflate the effectiveness of transfusions in the early decades but excludes the developing world entirely. Since the late 1980s blood donations have declined and the surplus will soon end. Call this efficiency, but there’s also a risk of future transfusion demands not being met.},
	file = {~/Google Drive/library-pdf/Pearce2016DeterminingNumber.pdf;~/Google Drive/library-html/Pearce2016DeterminingNumber.html},
	langid = {english},
	journaltitle = {ScienceHeroes.com},
	author = {Pearce, Amy R.},
	date = {2016-03-04},
	timestamp = {2024-08-14 09:37:08 (GMT)},
	title = {Determining the number. Karl Landsteiner - Blood transfusions},
	url = {https://web.archive.org/web/20160304060254/http://scienceheroes.com/index.php?option=com_content&view=article&id=128&Itemid=137},
	urldate = {2024-08-14}
}

@book{Pinker2002BlankSlateModern,
	abstract = {One of the world's leading experts on language and the mind  explores the idea of human nature and its moral, emotional, and political colorings. With characteristic wit, lucidity, and insight, Pinker argues that the dogma that the mind has no innate traits-a doctrine held by many intellectuals during the past century-denies our common humanity and our individual preferences, replaces objective analyses of social problems with feel-good slogans, and distorts our understanding of politics, violence, parenting, and the arts. Injecting calm and rationality into debates that are notorious for ax-grinding and mud-slinging, Pinker shows the importance of an honest acknowledgment of human nature based on science and common sense.},
	langid = {english},
	location = {New York},
	title = {The blank slate: The modern denial of human nature},
	isbn = {978-0-670-03151-1},
	shorttitle = {The blank slate},
	pagetotal = 509,
	publisher = {Viking},
	author = {Pinker, Steven},
	date = 2002,
	file = {~/Google Drive/library-pdf/Pinker2002BlankSlateModern.pdf}
}

@book{Pinker2014SenseStyleThinking,
	langid = {english},
	abstract = {From the author of Enlightenment Now, a short and entertaining book on the modern art of writing well by New York Times bestselling author Steven Pinker. Why is so much writing so bad, and how can we make it better? Is the English language being corrupted by texting and social media? Do the kids today even care about good writing? Why should any of us care? In The Sense of Style, the bestselling linguist and cognitive scientist Steven Pinker answers these questions and more. Rethinking the usage guide for the twenty-first century, Pinker doesn’t carp about the decline of language or recycle pet peeves from the rulebooks of a century ago. Instead, he applies insights from the sciences of language and mind to the challenge of crafting clear, coherent, and stylish prose. In this short, cheerful, and eminently practical book, Pinker shows how writing depends on imagination, empathy, coherence, grammatical knowhow, and an ability to savor and reverse engineer the good prose of others. He replaces dogma about usage with reason and evidence, allowing writers and editors to apply the guidelines judiciously, rather than robotically, being mindful of what they are designed to accomplish. Filled with examples of great and gruesome prose, Pinker shows us how the art of writing can be a form of pleasurable mastery and a fascinating intellectual topic in its own right.},
	location = {New York},
	title = {The sense of style: The thinking person's guide to writing in the 21st century},
	isbn = {978-0-670-02585-5},
	publisher = {Penguin Books},
	author = {Pinker, Steven},
	date = 2014,
	file = {~/Google Drive/library-pdf/Pinker2014SenseStyleThinking.pdf}
}

@book{Pinker2018AngelesQueLlevamos,
	translator = {Soler Chic, Juan},
	langid = {spanish},
	translation = {Pinker2011BetterAngelsOur},
	author = {Pinker, Steven},
	title = {Los ángeles que llevamos dentro: el declive de la violencia y sus implicaciones},
	publisher = {Paidós},
	abstract = {¿Por qué existen las guerras? ¿Podemos preguntarnos por qué existe la paz?... Estas son algunas de las preguntas que Steven Pinker se plantea en El ángel que hay en nosotros, una obra excepcional en la que nos expone las investigaciones que ha llevado a cabo sobre la preponderancia de la violencia a lo largo de la historia. Estas investigaciones le han llevado a concluir que, pese a las guerras de Irak, Afganistán, Darfur y de otros conflictos actuales, vivimos en una época en la que la violencia ha disminuido enormemente respecto de tiempos pasados. La violencia es un fenómeno que se ha desarrollado durante milenios y no cabe duda de que, como nos explica Pinker, su declive tiene unas profundas implicaciones. Disfrutamos la paz de la que gozamos ahora porque las generaciones pasadas vivieron atenazadas por la violencia y ello les obligó a esforzarse para ponerle límites, y en el mundo contemporáneo somos nosotros quienes debemos trabajar para ponerle fin. No debemos dejarnos llevar por el optimismo pero, al menos, ahora sabemos que este es un objetivo que está a nuestro alcance. En definitiva, esta nueva obra de Steven Pinker abre una nueva perspectiva a las ciencias y a nuestra idea del hombre. Y es que la constatación de que la violencia ha disminuido a lo largo de los siglos quiere decir que algo habremos hecho bien. Y sería estupendo saber, con toda exactitud, qué es},
	date = {2018},
	editoratype = {collaborator},
	isbn = {9788449334641},
	location = {Barcelona},
	shorttitle = {Los ángeles que llevamos dentro},
	timestamp = {2024-07-16 11:22:25 (GMT)}
}

@online{Piper2024WhereAiPredictions,
	file = {~/Google Drive/library-html/Piper2024WhereAiPredictions.html;~/Google Drive/library-pdf/Piper2024WhereAiPredictions.pdf},
	abstract = {Large language models (LLMs) are rapidly advancing, with claims that they are on the verge of achieving artificial general intelligence (AGI). However, the future of LLMs remains uncertain. While some experts believe that continued scaling of LLMs will lead to AGI, others argue that this approach has limitations. The article analyzes these opposing viewpoints, suggesting that both sides are overly confident. The author contends that while LLMs have shown remarkable progress, their capabilities are still limited and it is premature to predict their future potential with certainty. The article highlights the need for a nuanced approach to AI development, emphasizing the importance of understanding LLM limitations and the ethical implications of their rapid development. – AI-generated abstract.},
	author = {Piper, Kelsey},
	date = {2024-06-07},
	journaltitle = {Vox},
	langid = {english},
	timestamp = {2024-07-06 13:19:37 (GMT)},
	title = {Where {AI} predictions go wrong},
	url = {https://www.vox.com/future-perfect/354157/ai-predictions-chatgpt-google-future},
	urldate = {2024-07-06}
}

@online{Rodriguez2023AlisonYoungHow,
	file = {~/Google Drive/library-pdf/Rodriguez2023AlisonYoungHow.pdf;~/Google Drive/library-html/Rodriguez2023AlisonYoungHow.html},
	abstract = {In today’s episode, host Luisa Rodriguez interviews award-winning investigative journalist Alison Young on the surprising frequency of lab leaks and what needs to be done to prevent them in the future.

They cover:

- The most egregious biosafety mistakes made by the CDC, and how Alison uncovered them - - through her investigative reporting
- The Dugway life science test facility case, where live anthrax was accidentally sent to labs across the US and several other countries over a period of many years
- The time the Soviets had a major anthrax leak, and then hid it for over a decade
- The 1977 influenza pandemic caused by vaccine trial gone wrong in China
- The last death from smallpox, caused not by the virus spreading in the wild, but by a lab leak in the UK
- Ways we could get more reliable oversight and accountability for these labs
- And the investigative work Alison’s most proud of},
	date = {2023-11-09},
	author = {Rodriguez, Luisa and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-09-17 14:22:29 (GMT)},
	title = {Alison Young on how top labs have jeopardised public health with repeated biosafety failures},
	url = {https://80000hours.org/podcast/episodes/alison-young-biosafety-lab-leaks/},
	urldate = {2024-09-17}
}

@online{Rodriguez2024SellaNevoWhos,
	abstract = {Frontier AI models, whose training can cost hundreds of millions of dollars, are a valuable target for malicious actors. The model weights, which represent a culmination of training data, compute, and algorithmic improvements, are particularly vulnerable.  The article identifies five categories of actors based on their capabilities and resources, ranging from amateur hackers to nation-state actors.  A variety of attack vectors are described, including the exploitation of vulnerabilities, human intelligence collection, side-channel attacks, and model extraction. The article recommends seven top-priority security measures for AI companies, including reducing and hardening authorized access, deploying confidential computing, and conducting effective red-teaming exercises. – AI-generated abstract},
	file = {~/Google Drive/library-html/Rodriguez2024SellaNevoWhos.html;~/Google Drive/library-pdf/Rodriguez2024SellaNevoWhos.pdf},
	date = {2024-08-01},
	author = {Rodriguez, Luisa and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-30 07:12:27 (GMT)},
	title = {Sella Nevo on who's trying to steal frontier {AI} models, and what they could do with them},
	url = {https://80000hours.org/podcast/episodes/sella-nevo-securing-ai-model-weights/},
	urldate = {2024-08-30}
}

@online{Rodriguez3023KevinEsveltCults,
	file = {~/Google Drive/library-html/Rodriguez3023KevinEsveltCults.html},
	abstract = {In today’s episode, host Luisa Rodriguez interviews Kevin Esvelt — a biologist at the MIT Media Lab and the inventor of CRISPR-based gene drive — about the threat posed by engineered bioweapons.

They cover:

- Why it makes sense to focus on deliberately released pandemics
- Case studies of people who actually wanted to kill billions of humans
- How many people have the technical ability to produce dangerous viruses
- The different threats of stealth and wildfire pandemics that could crash civilisation
- The potential for AI models to increase access to dangerous pathogens
- Why scientists try to identify new pandemic-capable pathogens, and the case against that research
- Technological solutions, including UV lights and advanced PPE
- Using CRISPR-based gene drive to fight diseases and reduce animal suffering
- And plenty more.},
	date = {3023-10-02},
	author = {Rodriguez, Luisa and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-09-17 13:54:08 (GMT)},
	title = {Kevin Esvelt on cults that want to kill everyone, stealth vs wildfire pandemics, and how he felt inventing gene drives},
	url = {https://80000hours.org/podcast/episodes/kevin-esvelt-stealth-wildfire-pandemics/},
	urldate = {2024-09-17}
}

@article{Rotblat2001EarlyDaysPugwash,
	file = {~/Google Drive/library-pdf/Rotblat2001EarlyDaysPugwash.pdf},
	author = {Rotblat, Joseph},
	title = {The Early Days of Pugwash},
	volume = {54},
	number = {6},
	pages = {50--55},
	doi = {10.1063/1.1387592},
	url = {https://pubs.aip.org/physicstoday/article/54/6/50/411715/The-Early-Days-of-PugwashDuring-the-height-of-the},
	abstract = {The Pugwash Conferences on Science and World Affairs were founded in 1957 to address the threat of nuclear war and promote international peace. This article traces the origins of Pugwash to the Russell-Einstein Manifesto of 1955, which called for a conference of scientists to discuss the dangers of nuclear weapons. The author, a founding member of Pugwash, describes the efforts of scientists in the US and UK in the years leading up to the first Pugwash conference, including the work of the Federation of American Scientists (FAS) and the Atomic Scientists Association (ASA). He then details the genesis of the Russell-Einstein Manifesto, the organization of the first Pugwash conference, and the organization’s subsequent activities. The author argues that Pugwash has played a significant role in promoting nuclear disarmament and preventing nuclear war, particularly during the Cold War. – AI-generated abstract.},
	date = {2001-06-01},
	issn = {0031-9228, 1945-0699},
	journaltitle = {Physics Today}
}

@online{Saunders2024PrinciplesForAgi,
	abstract = {This work argues that the development of artificial general intelligence (AGI) presents a significant risk to humanity. To mitigate these risks, the author proposes eight principles for guiding the development of AGI, focusing on the need for broad and legitimate authority in decision-making, an overwhelming evidence of net benefit before taking actions that impose significant risks on others, an exit strategy for racing towards AGI development, and the importance of maintaining accurate race intelligence. The author critiques the actions of OpenAI and Anthropic, arguing that both companies have failed to uphold these principles. The author concludes by calling for greater transparency, public engagement, and independent oversight in the development of AGI. – AI-generated abstract.},
	file = {~/Google Drive/library-pdf/Saunders2024PrinciplesForAgi.pdf;~/Google Drive/library-html/Saunders2024PrinciplesForAgi.html},
	langid = {english},
	author = {Saunders, William},
	date = {2024-08-30},
	journaltitle = {{LessWrong}},
	keywords = {{AI}},
	timestamp = {2024-09-01 12:33:16 (GMT)},
	title = {Principles for the {AGI} Race},
	url = {https://www.lesswrong.com/posts/aRciQsjgErCf5Y7D9/principles-for-the-agi-race},
	urldate = {2024-09-01}
}

@book{Scharre2023FourBattlegroundsPower,
	file = {~/Google Drive/library-pdf/Scharre2023FourBattlegroundsPower.pdf},
	langid = {english},
	author = {Scharre, Paul},
	title = {Four battlegrounds: power in the age of artificial intelligence},
	publisher = {W.W. Norton \& Company},
	abstract = {A new industrial revolution has begun. Like mechanization or electricity before it, artificial intelligence will touch every aspect of our lives--and cause profound disruptions in the balance of global power, especially among the {AI} superpowers: China, the United States, and Europe. Autonomous weapons expert Paul Scharre takes readers inside the fierce competition to develop and implement this game-changing technology and dominate the future},
	date = {2023},
	isbn = {9780393866865},
	location = {New York},
	pagetotal = {473},
	shorttitle = {Four battlegrounds},
	timestamp = {2024-08-30 07:47:47 (GMT)}
}

@online{Schmall2019MostPeopleBelieve,
	file = {~/Google Drive/library-pdf/Schmall2019MostPeopleBelieve.pdf;~/Google Drive/library-html/Schmall2019MostPeopleBelieve.html},
	abstract = {A new survey of 2,000 Americans reveals a significant level of concern about climate change, with 75\% believing it will eventually lead to human extinction. The survey, conducted by [Survey Organization Name], explores public perceptions of climate change, its potential impacts, and preferred policy solutions. Notably, the majority of respondents expressed strong support for government action to address climate change, including investments in renewable energy, stricter environmental regulations, and international cooperation. The findings highlight the growing public awareness and concern about the potential consequences of climate change, emphasizing the need for urgent action to mitigate its effects.},
	author = {Schmall, Tyler and {SWNS}},
	date = {2019-04-22},
	langid = {american},
	timestamp = {2024-09-19 19:05:24 (GMT)},
	title = {Most people believe climate change will cause humanity’s extinction},
	url = {https://nypost.com/2019/04/22/most-people-believe-climate-change-will-cause-humanitys-extinction/},
	urldate = {2024-09-19}
}

@Report{SelectCommitteeonArtificialIntelligence2023NationalArtificialIntelligence,
	langid = {english},
	abstract = {The National Science and Technology Council's Select Committee on Artificial Intelligence (AI) has issued a 2023 update to the National AI Research and Development Strategic Plan. This document builds on previous strategic plans from 2016 and 2019 and includes updates based on interagency evaluation of the National AI R\&D Strategic Plan: 2019 Update and community responses to a Request for Information on updating the Plan. The updated plan reaffirms eight strategies, including investments in fundamental AI research, human-AI collaboration, mitigating AI risks, developing shared public datasets, and building an AI-ready workforce. A ninth strategy is added to emphasize a principled and coordinated approach to international collaboration in AI research, promoting responsible innovation and U.S. leadership in AI development and use. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/SelectCommitteeonArtificialIntelligence2023NationalArtificialIntelligence.pdf},
	url = {https://www.whitehouse.gov/wp-content/uploads/2023/05/National-Artificial-Intelligence-Research-and-Development-Strategic-Plan-2023-Update.pdf},
	date = {2023-05},
	institution = {National Science and Technology Council},
	title = {National Artificial Intelligence Research and Development Strategic Plan: 2023 Update},
	author = {{Select Committee on Artificial Intelligence}},
	timestamp = {2024-08-30 08:06:39 (GMT)}
}

@online{Sempere2024GranListaDe,
	langid = {spanish},
	translation = {Sempere2020BigListCause},
	date = {2024},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {Gran lista de candidatos a causa},
	author = {Sempere, Nuño},
	timestamp = {2024-07-16 16:37:31 (GMT)}
}

@online{Sevilla2024CanAiScaling,
	rating = {8},
	file = {~/Google Drive/library-html/Sevilla2024CanAiScaling.html;~/Google Drive/library-pdf/Sevilla2024CanAiScaling.pdf},
	abstract = {We investigate the scalability of {AI} training runs. We identify electric power, chip manufacturing, data and latency as constraints. We conclude that 2e29 {FLOP} training runs will likely be feasible by 2030.},
	author = {Sevilla, Jaime},
	date = {2024-08-20},
	journaltitle = {Epoch {AI}},
	langid = {english},
	timestamp = {2024-08-21 14:03:50 (GMT)},
	title = {Can {AI} scaling continue through 2030?},
	url = {https://epochai.org/blog/can-ai-scaling-continue-through-2030},
	urldate = {2024-08-21}
}

@online{Sevilla2024TrainingComputeOf,
	rating = {7},
	file = {~/Google Drive/library-pdf/Sevilla2024TrainingComputeOf.pdf;~/Google Drive/library-html/Sevilla2024TrainingComputeOf.html},
	abstract = {Our expanded {AI} model database shows that the compute used to train recent models grew 4-5x yearly from 2010 to May 2024. We find similar growth in frontier models, recent large language models, and models from leading companies.},
	author = {Sevilla, Jaime},
	date = {2024-05-28},
	journaltitle = {Epoch {AI}},
	langid = {english},
	timestamp = {2024-08-22 22:22:14 (GMT)},
	title = {Training Compute of Frontier {AI} Models Grows by 4-5x per Year},
	url = {https://epochai.org/blog/training-compute-of-frontier-ai-models-grows-by-4-5x-per-year},
	urldate = {2024-08-22}
}

@online{Shiller2024ValueOfConsciousness,
	langid = {english},
	file = {~/Google Drive/library-html/Shiller2024ValueOfConsciousness.html;~/Google Drive/library-pdf/Shiller2024ValueOfConsciousness.pdf},
	abstract = {Longtermists point out that the scale of our potential for impact is far greater if we are able to influence the course of a long future, as we could change the circumstances of a tremendous number of lives.
One potential avenue for long-term influence involves spreading values that persist and shape the futures that our descendants choose to build. There is some reason to expect that future moral values will be stable. Many groups have preferences about the world beyond their backyard. They should work to ensure that their values are shared by those who can help bring them about. Changes in the values that future groups support will lead to changes in the protections for the things we care about. If our values concern how our descendants will act, then we should aim to create institutions that promote those values. If we are successful in promoting those values, we should expect our descendants to appreciate and protect those institutional choices.},
	author = {Shiller, Derek},
	date = {2024-07-02},
	journaltitle = {Effective Altruism Forum},
	keywords = {Philosophy, {AI} Welfare Debate Week, Artificial sentience, Consciousness research, Digital person, Moral patienthood},
	timestamp = {2024-07-10 16:54:25 (GMT)},
	title = {The value of consciousness as a pivotal question},
	url = {https://forum.effectivealtruism.org/posts/C652FAbbnSrJWumhH},
	urldate = {2024-07-10}
}

@book{Singer1973DemocracyDisobedience,
	langid = {english},
	abstract = {Why, or in what circumstances, ought we to obey the law? Anyone seeking a dispassionate answer to this question should be able to follow the argument of this book. It centres on the common view that disobedience to the law, while justifiable in a dictatorship, is much more difficult to justify in a democracy. Proceeding from simple, small-scale societies, the author develops a distinctive theory of political obligation in an ideal democracy; and after discussing various forms of disobedience, including conscientious objection, the author asks to what extent existing systems of government approximate to this ideal.},
	database = {Tlön},
	location = {Oxford},
	title = {Democracy and disobedience},
	isbn = {0-19-824504-1},
	pagetotal = {150},
	publisher = {Clarendon Press},
	author = {Singer, Peter},
	date = {1973},
	file = {~/Google Drive/library-pdf/Singer1973DemocracyDisobedience.pdf}
}

@Book{Singer1991CompanionEthics,
	editor = {Singer, Peter},
	abstract = {In this volume, some of today's most distinguished philosophers survey the whole field of ethics, from its origins, through the great ethical traditions, to theories of how we ought to live, arguments about specific ethical issues, and the nature of ethics itself. The book can be read straight through from beginning to end; yet the inclusion of a multi-layered index, coupled with a descriptive outline of contents and bibliographies of relevant literature, means that the volume also serves as a work of reference, both for those coming afresh to the study of ethics and for readers already familiar with the subject.},
	langid = {english},
	location = {Oxford},
	title = {A companion to ethics},
	isbn = {0-631-16211-9},
	publisher = {Blackwell},
	date = {1991},
	file = {~/Google Drive/library-pdf/Singer1991CompanionEthics.pdf}
}

@article{Stevenson2013SubjectiveWellBeing,
	author = {Stevenson, Betsey and Wolfers, Justin},
	title = {Subjective well-being and income: is there any evidence of
                  satiation?},
	volume = {103},
	number = {3},
	pages = {598--604},
	doi = {10.1257/aer.103.3.598},
	url = {https://pubs.aeaweb.org/doi/10.1257/aer.103.3.598},
	abstract = {Many scholars have argued that once “basic needs” have been
                  met, further rises in income are not associated with further
                  increases in subjective well-being. We assess the validity of
                  this claim in comparisons of both rich and poor countries, and
                  also of rich and poor people within a country. Analyzing
                  multiple datasets, multiple definitions of “basic needs” and
                  multiple questions about well-being, we find no support for
                  this claim. The relationship between well-being and income is
                  roughly log-linear and does not diminish as incomes rise. If
                  there is a satiation point, we are yet to reach it.},
	date = {2013-05-01},
	issn = {0002-8282},
	journaltitle = {American Economic Review},
	langid = {english},
	shortjournal = {American Economic Review},
	shorttitle = {Subjective Well-Being and Income},
	timestamp = {2024-09-17 17:09:02 (GMT)},
	urldate = {2024-09-17}
}

@report{Stevenson2013SubjectiveWellBeingb,
	abstract = {Many scholars have argued that once "basic needs" have been met, higher income is no longer associated with higher in subjective well-being. We assess the validity of this claim in comparisons of both rich and poor countries, and also of rich and poor people within a country. Analyzing multiple datasets, multiple definitions of "basic needs" and multiple questions about well-being, we find no support for this claim. The relationship between well-being and income is roughly linear-log and does not diminish as incomes rise. If there is a satiation point, we are yet to reach it.},
	file = {~/Google Drive/library-pdf/Stevenson2013SubjectiveWellBeingb.pdf},
	author = {Stevenson, Betsey and Wolfers, Justin},
	date = {2013-04},
	doi = {10.3386/w18992},
	institution = {National Bureau of Economic Research},
	langid = {english},
	location = {Cambridge, {MA}},
	number = {w18992},
	shorttitle = {Subjective Well-Being and Income},
	timestamp = {2024-09-17 17:14:27 (GMT)},
	title = {Subjective Well-Being and Income: Is There Any Evidence of Satiation?},
	url = {http://www.nber.org/papers/w18992.pdf},
	urldate = {2024-09-17}
}

@Article{Thomas2024DispellingAnthropicShadow,
	file = {~/Google Drive/library-pdf/Thomas2024DispellingAnthropicShadow.pdf},
	abstract = {There are some possible events that we could not possibly discover in our past. We could not discover an omnicidal catastrophe, an event so destructive that it permanently wiped out life on Earth. Had such a catastrophe occurred, we wouldn’t be here to find out. This space of unobservable histories has been called the anthropic shadow. Several authors claim that the anthropic shadow leads to an ‘observation selection bias’, analogous to survivorship bias, when we use the historical record to estimate catastrophic risks. I argue against this claim.},
	author = {Thomas, Teruji},
	date = {2024-09-06},
	journaltitle = {Global Priorities Institute},
	langid = {british},
	timestamp = {2024-09-10 21:47:09 (GMT)},
	title = {Dispelling the anthropic shadow},
	url = {https://globalprioritiesinstitute.org/dispelling-the-anthropic-shadow-teruji-thomas/},
	urldate = {2024-09-10}
}

@online{Todd2014HowToFind,
	file = {~/Google Drive/library-html/Todd2014HowToFind.html;~/Google Drive/library-pdf/Todd2014HowToFind.pdf},
	eventdate = {2023-05},
	date = {2014-08},
	author = {Todd, Benjamin},
	abstract = {Traditional approaches to career exploration, such as aptitude tests and gap years, often fail to provide effective guidance.  Instead of relying on these outdated methods, individuals should embrace a more proactive and personalized approach. This involves identifying their passions, strengths, and values, actively exploring different career paths through internships, networking, and shadowing, and seeking mentorship from experienced professionals. By taking ownership of their career journey, individuals can gain a deeper understanding of their interests and develop the skills and connections necessary to succeed in their chosen field.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-07 09:50:39 (GMT)},
	title = {How to find the right career for you},
	url = {https://80000hours.org/career-guide/personal-fit/},
	urldate = {2024-08-07}
}

@online{Todd2014HowToMake,
	file = {~/Google Drive/library-pdf/Todd2014HowToMake.pdf;~/Google Drive/library-html/Todd2014HowToMake.html},
	eventdate = {2023-05},
	date = {2014-08},
	author = {Todd, Benjamin},
	abstract = {You need a plan, but your plan is almost certainly going to change. How can you balance flexibility and having definite goals? Here, we'll explain how.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-07 09:58:52 (GMT)},
	title = {How to make your career plan},
	url = {https://80000hours.org/career-guide/career-planning/},
	urldate = {2024-08-07}
}

@online{Todd2016AllBestAdvice,
	file = {~/Google Drive/library-pdf/Todd2016AllBestAdvice.pdf;~/Google Drive/library-html/Todd2016AllBestAdvice.html},
	eventdate = {2023-05},
	date = {2016-04},
	author = {Todd, Benjamin},
	abstract = {Most advice on how to get a job is awful. Over the last five years, we’ve sifted through it to find the few nuggets that are actually good.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-07 10:04:50 (GMT)},
	title = {All the best advice we could find on how to get a job},
	url = {https://80000hours.org/career-guide/how-to-get-a-job/},
	urldate = {2024-08-07}
}

@online{Todd2016WantToDo,
	file = {~/Google Drive/library-html/Todd2016WantToDo.html;~/Google Drive/library-pdf/Todd2016WantToDo.pdf},
	eventdate = {2023-05},
	date = {2016-04},
	author = {Todd, Benjamin},
	abstract = {To maximize your career's social impact, focus on addressing the most pressing problems facing society. This seemingly obvious principle is often overlooked, leading many to miss opportunities to contribute meaningfully. By aligning your work with significant challenges, you can leverage your skills and expertise to create positive change and leave a lasting legacy.},
	journaltitle = {80,000 Hours},
	langid = {english},
	shorttitle = {Which global problem is most important to work on?},
	timestamp = {2024-08-07 09:35:37 (GMT)},
	title = {Want to do good? Here’s how to choose an area to focus on},
	url = {https://80000hours.org/career-guide/most-pressing-problems/},
	urldate = {2024-08-07}
}

@online{Todd2016WhyShouldRead,
	file = {~/Google Drive/library-html/Todd2016WhyShouldRead.html;~/Google Drive/library-pdf/Todd2016WhyShouldRead.pdf},
	eventdate = {2023-05},
	date = {2016-04},
	author = {Todd, Benjamin},
	abstract = {This free guide distills five years of research conducted alongside academics at Oxford University. It provides a comprehensive and accessible resource, offering insights and practical guidance based on rigorous academic inquiry. Whether you are a student, researcher, or simply curious about the subject matter, this guide serves as a valuable starting point for exploring the topic in depth.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2024-08-07 08:46:14 (GMT)},
	title = {Why should I read this guide?},
	url = {https://80000hours.org/career-guide/introduction/},
	urldate = {2024-08-07}
}

@online{Todd2017EndCheeryFinal,
	file = {~/Google Drive/library-html/Todd2017EndCheeryFinal.html;~/Google Drive/library-pdf/Todd2017EndCheeryFinal.pdf},
	eventdate = {2023-05},
	date = {2017-04},
	author = {Todd, Benjamin},
	abstract = {We summarise our entire career guide in one minute.},
	journaltitle = {80,000 Hours},
	langid = {american},
	shorttitle = {The end},
	timestamp = {2024-08-07 10:27:31 (GMT)},
	title = {The end: A cheery final note - imagining your deathbed},
	url = {https://80000hours.org/career-guide/end/},
	urldate = {2024-08-07}
}

@online{Todd2017IsItEver,
	file = {~/Google Drive/library-html/Todd2017IsItEver.html;~/Google Drive/library-pdf/Todd2017IsItEver.pdf},
	date = {2017-06},
	author = {Todd, Benjamin and {MacAskill}, William},
	abstract = {The article discusses the ethical implications of taking jobs that have a negative impact, even if those jobs are undertaken with the intention of doing good. The article argues that in the vast majority of cases, it is a mistake to pursue a career that directly causes significant harm, even if the overall benefits of that work seem greater than the harms. The authors acknowledge that all careers involve some degree of negative impact, but suggest that the degree of negative impact and its nature should be carefully considered. The authors present a step-by-step process for deciding whether a job with a negative impact is morally permissible, including an analysis of emergency situations, whether the harms are a means or a side effect, whether the affected people consent, and whether anyone is being exploited. The authors apply this process to a case study of earning to give in finance, concluding that while some jobs in finance are morally impermissible, others might be justified under certain conditions. – AI-generated abstract.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2024-08-09 07:46:59 (GMT)},
	title = {Is it ever OK to take a harmful job in order to do more good? An in-depth analysis},
	url = {https://80000hours.org/articles/harmful-career/},
	urldate = {2024-08-09}
}

@online{Todd2017OneOfMost,
	file = {~/Google Drive/library-html/Todd2017OneOfMost.html;~/Google Drive/library-pdf/Todd2017OneOfMost.pdf},
	eventdate = {2023-05},
	date = {2017-04},
	author = {Todd, Benjamin},
	abstract = {This abstract is already short and concise. To shorten it further, we could remove the comparison to networking and simply state the technology's key benefit: "This technology is significantly faster." However, this loses the impact of the original statement. A more effective way to shorten the abstract without losing its essence could be: "This technology offers a dramatic speed increase compared to traditional methods, enabling unprecedented efficiency." This emphasizes the speed advantage while retaining the abstract's original tone.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-07 10:09:04 (GMT)},
	title = {One of the most powerful ways to improve your career — join a community},
	url = {https://80000hours.org/career-guide/community/},
	urldate = {2024-08-07}
}

@online{Todd2017WorldSBiggest,
	file = {~/Google Drive/library-html/Todd2017WorldSBiggest.html;~/Google Drive/library-pdf/Todd2017WorldSBiggest.pdf},
	eventdate = {2023-05},
	date = {2017-03},
	author = {Todd, Benjamin},
	abstract = {Over the past eight years, our research has focused on identifying the world's most pressing and impactful challenges. We believe understanding these problems is critical to developing effective solutions. Our efforts involve analyzing global trends, engaging with experts across disciplines, and collecting data from diverse sources. We aim to provide a comprehensive framework for addressing these challenges, fostering collaboration, and promoting innovation.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-07 09:42:08 (GMT)},
	title = {The world’s biggest problems and why they’re not what first comes to mind},
	url = {https://80000hours.org/career-guide/world-problems/},
	urldate = {2024-08-07}
}

@online{Todd2018ShouldYouPlay,
	file = {~/Google Drive/library-pdf/Todd2018ShouldYouPlay.pdf;~/Google Drive/library-html/Todd2018ShouldYouPlay.html},
	date = {2018-08},
	author = {Todd, Benjamin},
	abstract = {“Do the job that’s your comparative advantage” might sound obvious but it's not clear how much the concept applies. In this article, we sketch a naive application of comparative advantage to choosing between two career options, and show that it doesn’t apply. Then we give a more complex example where comparative advantage comes back into play, and show how it’s different from “personal fit”.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 09:37:02 (GMT)},
	title = {Should you play to your comparative advantage when choosing a career?},
	url = {https://80000hours.org/articles/comparative-advantage/},
	urldate = {2024-08-09}
}

@online{Todd2021BestSolutionsAre,
	file = {~/Google Drive/library-pdf/Todd2021BestSolutionsAre.pdf;~/Google Drive/library-html/Todd2021BestSolutionsAre.html},
	eventdate = {2023-02},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {This article examines the potential for significant variation in the effectiveness of solutions to social problems. The article argues that the best solutions within a given area often achieve considerably greater impact per unit of effort compared to the average solution. Several studies are reviewed that demonstrate this pattern across a variety of fields, including global health, education, and climate change. The article explores reasons for this variation, including the lack of strong feedback loops between impact and resource allocation, the potential for regression to the mean in effectiveness estimates, and the possibility that the best solutions are simply not well-measured or documented. The article advocates for a "hits-based" approach to finding solutions, prioritizing those with high potential upside even if they carry a higher risk of failure. Several frameworks and methodologies are discussed for identifying promising solutions, including upside/downside analysis, importance-neglectedness-tractability analysis, and bottleneck analysis. – AI-generated abstract},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 08:21:50 (GMT)},
	title = {The best solutions are far more effective than others},
	url = {https://80000hours.org/articles/solutions/},
	urldate = {2024-08-09}
}

@online{Todd2021BioriskResearchStrategy,
	file = {~/Google Drive/library-html/Todd2021BioriskResearchStrategy.html;~/Google Drive/library-pdf/Todd2021BioriskResearchStrategy.pdf},
	eventdate = {2023-04},
	date = {2021-10},
	author = {Todd, Benjamin and Lewis, Gregory},
	abstract = {Advances in biotechnology could generate, through accident or misuse, pandemics even worse than those that occur naturally — and bad enough to threaten human civilization. COVID-19 demonstrated global preparedness and response to a major pandemic is inadequate in general, and the threat from pandemics arising from the misuse of biotechnology remains especially neglected. Efforts to reduce this danger are thus extremely valuable.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-09-17 13:26:49 (GMT)},
	title = {Biorisk research, strategy, and policy},
	url = {https://80000hours.org/career-reviews/biorisk-research/},
	urldate = {2024-09-17}
}

@online{Todd2021CluelessnessCanWe,
	file = {~/Google Drive/library-pdf/Todd2021CluelessnessCanWe.pdf;~/Google Drive/library-html/Todd2021CluelessnessCanWe.html},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {Many people argue that the effects of our actions are so diverse and unpredictable that it's impossible to know whether they're ultimately good or bad — so it doesn't make sense to struggle to increase our impact. The pop version of the criticism is that if you save a life, that person might become the next Hitler — so your well-intentioned action might have actually resulted in the deaths of millions. This version of the criticism is silly: although there's some chance that the person whose life you save will be the next Hitler, it's so low that the possibility doesn't have much effect on the expected value. And just as you might save the next Hitler, you might also save the next Norman Borlaug, who saved hundreds of millions of lives.},
	journaltitle = {80,000 Hours},
	langid = {american},
	shorttitle = {Cluelessness},
	timestamp = {2024-08-09 07:56:35 (GMT)},
	title = {Cluelessness: can we know the effects of our actions?},
	url = {https://80000hours.org/articles/cluelessness/},
	urldate = {2024-08-09}
}

@online{Todd2021CounterfactualsAndHow,
	file = {~/Google Drive/library-html/Todd2021CounterfactualsAndHow.html;~/Google Drive/library-pdf/Todd2021CounterfactualsAndHow.pdf},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {Imagine you're at the scene of an accident and you see an injured person. In your enthusiasm to help, you push the paramedics out of the way and perform {CPR} on the injured person yourself. You're successful and bring them back to consciousness, but because you're less well-trained than the paramedics, you cause permanent damage to the person's spine. If you had let the paramedics perform {CPR} instead, the injured person would have made a full recovery.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 08:00:54 (GMT)},
	title = {Counterfactuals and how they change our view of what does good},
	url = {https://80000hours.org/articles/counterfactuals/},
	urldate = {2024-08-09}
}

@online{Todd2021HowToCompare,
	file = {~/Google Drive/library-pdf/Todd2021HowToCompare.pdf;~/Google Drive/library-html/Todd2021HowToCompare.html},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {If you want to do your own research into which problems are pressing, below is a process you can work through. It's one stage of our full career planning process and accompanying planning template. Creating your own ranking of pressing problems according to your values and beliefs about the world is a lot of work, but it can also be really worthwhile, especially because it can give you more of an inside understanding of different global issues. You can also do a bit of both -- doing some of your own research and also sometimes deferring to others' reasoning.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 08:10:46 (GMT)},
	title = {How to compare global problems for yourself},
	url = {https://80000hours.org/articles/comparing-problems-yourself/},
	urldate = {2024-08-09}
}

@online{Todd2021MoralUncertaintyHow,
	file = {~/Google Drive/library-html/Todd2021MoralUncertaintyHow.html;~/Google Drive/library-pdf/Todd2021MoralUncertaintyHow.pdf},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {We can be uncertain about matters of fact, like whether it'll rain tomorrow, but we can also be uncertain about moral claims, like how much to value the interests of future generations. In the last decade, there has been more study of how to act when uncertain about what's of value, and our cofounder, Will {MacAskill}, has written a book on the topic. An approach that's common is to pick the view that seems most plausible to you, and to go with that. This has been called the 'my favourite theory' approach.},
	journaltitle = {80,000 Hours},
	langid = {english},
	shorttitle = {Moral uncertainty},
	timestamp = {2024-08-09 07:51:49 (GMT)},
	title = {Moral uncertainty: how to act when you’re uncertain about what’s good},
	url = {https://80000hours.org/articles/moral-uncertainty/},
	urldate = {2024-08-09}
}

@online{Todd2021RationalArgumentFor,
	file = {~/Google Drive/library-html/Todd2021RationalArgumentFor.html;~/Google Drive/library-pdf/Todd2021RationalArgumentFor.pdf},
	eventdate = {2021-11},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {The optimal amount of career exploration is a question that has puzzled individuals for centuries. Research from various disciplines, including computer science and psychology, offers insights into this complex dilemma. By analyzing data on career paths, personality traits, and decision-making processes, we aim to provide a practical answer to this question, empowering individuals to make informed choices regarding their career journeys. Our findings suggest that an appropriate level of exploration balances the need for thorough research with the necessity for timely action, ultimately leading to fulfilling career outcomes.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 09:51:21 (GMT)},
	title = {Career exploration: when should you settle?},
	url = {https://80000hours.org/articles/career-exploration/},
	urldate = {2024-08-09}
}

@online{Todd2021WhyProblemYou,
	file = {~/Google Drive/library-pdf/Todd2021WhyProblemYou.pdf;~/Google Drive/library-html/Todd2021WhyProblemYou.html},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {If you want to help others, should you follow your passion? Probably not. You'll do far more good if you focus on bigger and more problem areas.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 08:03:15 (GMT)},
	title = {Why the problem you work on is the biggest driver of your impact},
	url = {https://80000hours.org/articles/your-choice-of-problem-is-crucial/},
	urldate = {2024-08-09}
}

@online{Todd2023CanOnePerson,
	file = {~/Google Drive/library-pdf/Todd2023CanOnePerson.pdf;~/Google Drive/library-html/Todd2023CanOnePerson.html},
	eventdate = {2016-04},
	date = {2023-05},
	author = {Todd, Benjamin},
	abstract = {While traditional paths to making a positive impact, like becoming a doctor, might not have the widespread influence one initially expects, a single individual can still make a significant difference. This impact often stems from pursuing unconventional or less-trodden paths, demonstrating that the most impactful contributions may lie outside conventional wisdom.},
	journaltitle = {80,000 Hours},
	langid = {american},
	shorttitle = {How much good can one person do?},
	timestamp = {2024-08-07 09:26:00 (GMT)},
	title = {Can one person make a difference? What the evidence says},
	url = {https://80000hours.org/career-guide/can-one-person-make-a-difference/},
	urldate = {2024-08-07}
}

@online{Todd2023OurNewGuide,
	file = {~/Google Drive/library-pdf/Todd2023OurNewGuide.pdf;~/Google Drive/library-html/Todd2023OurNewGuide.html},
	date = {2023-05},
	author = {Todd, Benjamin and {80,000 Hours team}},
	abstract = {80,000 Hours' key ideas for those who want a high-impact career. If you’re already familiar with the ideas in our career guide, this series aims to deepen your understanding of how to increase the impact of your career.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-09 07:34:34 (GMT)},
	title = {Our new guide to doing good with your career},
	url = {https://80000hours.org/advanced-series/},
	urldate = {2024-08-09}
}

@online{Todd2024HemosRevisadoMas,
	langid = {spanish},
	date = {2024},
	translation = {Todd2014WeReviewed60},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {Hemos revisado más de 60 estudios sobre lo que constituye el trabajo soñado. Esto es lo que hemos encontrado},
	author = {Todd, Benjamin},
	timestamp = {2024-08-12 09:31:56 (GMT)}
}

@online{Todd2024MayoresProblemasDel,
	langid = {spanish},
	date = {2024},
	translation = {Todd2017WorldSBiggest},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {Los mayores problemas del mundo y por qué no son lo primero que nos viene a la mente},
	author = {Todd, Benjamin},
	timestamp = {2024-09-24 17:01:38 (GMT)}
}

@online{Todd2024PorQueLeer,
	langid = {spanish},
	date = {2024},
	translation = {Todd2016WhyShouldRead},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {¿Por qué leer esta guía?},
	author = {Todd, Benjamin},
	timestamp = {2024-08-07 11:40:13 (GMT)}
}

@online{Todd2024PuedePersonaLograr,
	langid = {spanish},
	date = {2024},
	translation = {Todd2023CanOnePerson},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {¿Puede una persona lograr un cambio? Lo que dicen la evidencia},
	author = {Todd, Benjamin},
	timestamp = {2024-08-14 07:57:32 (GMT)}
}

@online{Todd2024QueTrabajosAyudan,
	langid = {spanish},
	date = {2024},
	translation = {Todd2014WhichJobsHelp},
	journaltitle = {Biblioteca Altruismo Eficaz},
	title = {¿Qué trabajos ayudan más a la gente?},
	author = {Todd, Benjamin},
	timestamp = {2024-09-23 18:19:52 (GMT)}
}

@article{Wang2022TranslatorAsActivist,
	abstract = {This study examines the translator as an activist, focusing on Yan Fu, a pioneer translator in late Qing China. The study analyzes the prefaces to Yan Fu's translations to reveal his activist agendas, finding that he aimed to save the nation, oppose autocratic monarchy, and strengthen the country. It is further argued that these agendas were closely intertwined, with the goal of saving the nation underpinning the other two. The study then explores the interactive and cyclical relationship between translation and activism, going beyond the one-way conceptualization of translation as a tool of activism. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Wang2022TranslatorAsActivist.pdf},
	author = {Wang, Xiaorui},
	title = {The Translator As an Activist: the Case of Yan Fu As a Pioneer
                  Activist Translator in the Late Qing},
	volume = {9},
	number = {2},
	pages = {170--185},
	doi = {10.1080/23306343.2022.2110744},
	url = {https://www.tandfonline.com/doi/full/10.1080/23306343.2022.2110744},
	date = {2022-05-04},
	issn = {2330-6343, 2330-6351},
	journaltitle = {Asia Pacific Translation and Intercultural Studies},
	langid = {english},
	shortjournal = {Asia Pacific Translation and Intercultural Studies},
	shorttitle = {The translator as an activist},
	timestamp = {2024-08-04 15:10:18 (GMT)},
	urldate = {2024-08-04}
}

@collection{West2006BlackwellGuideTo,
	langid = {english},
	location = {Malden},
	title = {The Blackwell guide to Mill's Utilitarianism},
	isbn = {978-1-4051-1948-1},
	series = {Blackwell guides to great works},
	abstract = {A proper understanding of philosophy requires engagement with the foundational texts that have shaped the development of the discipline and which have an abiding relevance to contemporary discussions. Each volume in this series provides guid-ance to those coming to the great works of the philosophical canon, whether for the first time or to gain new insight. Comprising specially commissioned contri-butions from the finest scholars, each book offers a clear and authoritative account of the context, arguments, and impact of the work at hand. Where possible the original text is reproduced alongside the essays.},
	publisher = {Blackwell},
	editor = {West, Henry R.},
	date = {2006},
	file = {~/Google Drive/library-pdf/West2006BlackwellGuideMill.pdf}
}

@online{Whittlestone2018AcademicResearch,
	file = {~/Google Drive/library-html/Whittlestone2018AcademicResearch.html;~/Google Drive/library-pdf/Whittlestone2018AcademicResearch.pdf},
	eventdate = {2023-12},
	date = {2018-10},
	author = {Whittlestone, Jess},
	abstract = {Want to do good as a researcher? The case for \& against, strategy, fit, \& more.},
	journaltitle = {80,000 Hours},
	langid = {american},
	shorttitle = {Considering becoming an academic?},
	timestamp = {2024-08-24 22:27:16 (GMT)},
	title = {Academic research},
	url = {https://80000hours.org/career-reviews/academic-research/},
	urldate = {2024-08-24}
}

@Article{Whittlestone2021WhyAndHow,
	file = {~/Google Drive/library-pdf/Whittlestone2021WhyAndHow.pdf},
	langid = {english},
	number = {arXiv:2108.12427v2},
	abstract = {In this paper we outline a proposal for improving the governance of artificial intelligence ({AI}) by investing in government capacity to systematically measure and monitor the capabilities and impacts of {AI} systems. If adopted, this would give governments greater information about the {AI} ecosystem, equipping them to more effectively direct {AI} development and deployment in the most societally and economically beneficial directions. It would also create infrastructure that could rapidly identify potential threats or harms that could occur as a consequence of changes in the {AI} ecosystem, such as the emergence of strategically transformative capabilities, or the deployment of harmful systems. We begin by outlining the problem which motivates this proposal: in brief, traditional governance approaches struggle to keep pace with the speed of progress in {AI}. We then present our proposal for addressing this problem: governments must invest in measurement and monitoring infrastructure. We discuss this proposal in detail, outlining what specific things governments could focus on measuring and monitoring, and the kinds of benefits this would generate for policymaking. Finally, we outline some potential pilot projects and some considerations for implementing this in practice.},
	author = {Whittlestone, Jess and Clark, Jack},
	date = {2021-08-31},
	publisher = {{arXiv}},
	timestamp = {2024-08-30 07:41:49 (GMT)},
	title = {Why and How Governments Should Monitor {AI} Development},
	url = {http://arxiv.org/abs/2108.12427},
	urldate = {2024-08-30}
}

@online{Wiblin2021DrPardisSabeti,
	abstract = {Dr. Pardis Sabeti, a professor at Harvard and co-founder of Sherlock Biosciences, argues for the development and deployment of a system to rapidly detect and contain emerging infectious diseases. The proposed system, called SENTINEL, relies on an escalating series of three diagnostic techniques: SHERLOCK, CARMEN, and metagenomic sequencing. SHERLOCK is a simple, inexpensive test that uses CRISPR gene editing to detect familiar viruses. If SHERLOCK fails to identify a pathogen, the sample is analyzed using CARMEN, a more expensive, multiplex test that can simultaneously detect hundreds of viruses. If neither test identifies the pathogen, metagenomic sequencing can be used to identify and track every virus, known and unknown, in a sample. SENTINEL also emphasizes the importance of connecting data in real time and empowering frontline workers. The system aims to detect, connect, and empower actors in a global community to preempt and respond to future pandemics. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Wiblin2021DrPardisSabeti.pdf;~/Google Drive/library-html/Wiblin2021DrPardisSabeti.html},
	date = {2021-06-29},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-09-17 14:59:17 (GMT)},
	title = {Dr Pardis Sabeti on the Sentinel system for detecting and stopping pandemics},
	url = {https://80000hours.org/podcast/episodes/pardis-sabeti-sentinel/},
	urldate = {2024-09-17}
}

@online{Wiblin2021JaimeYassifSafeguarding,
	abstract = {The development of biological weapons poses a significant threat to global security. The article discusses the reasons why countries might develop such weapons, including fear of their adversaries, the belief that biological weapons offer a tactical or strategic advantage, and the perception that they can be used with limited risk of detection or accountability. The author proposes a three-part strategy to deter the development and use of biological weapons: increasing transparency to reduce the risk of misperceptions and arms races, strengthening the United Nations' capacity to investigate the origins of biological events, and establishing meaningful accountability mechanisms to deter malicious actors. The author argues for the need for a layered defense approach, emphasizing the importance of preventing the development of dangerous pathogens and technologies rather than relying solely on response mechanisms. The article concludes by offering advice on how to build a career in biosecurity, highlighting the importance of interdisciplinary skillsets, such as technical knowledge in bioscience and biotechnology, policy and governance expertise, and an understanding of international security dynamics. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Wiblin2021JaimeYassifSafeguarding.pdf;~/Google Drive/library-html/Wiblin2021JaimeYassifSafeguarding.html},
	date = {2021-12-13},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-09-17 14:38:00 (GMT)},
	title = {Jaime Yassif on safeguarding bioscience to prevent catastrophic lab accidents \& bioweapons development},
	url = {https://80000hours.org/podcast/episodes/jaime-yassif-safeguarding-bioscience/},
	urldate = {2024-09-17}
}

@online{Wiblin2023HoldenKarnofskyHow,
	abstract = {Holden Karnofsky argues that humanity should be concerned not only with the possibility of superintelligent AI but also with the prospect of an AI “population explosion”, where large numbers of human-level AI systems could emerge and outpace human decision-making capabilities. Karnofsky further outlines four critical interventions that humanity must focus on to navigate this transition: (1) **AI alignment research**, (2) **standards and monitoring for dangerous AI capabilities**, (3) **prioritizing AI safety in the development of successful and influential AI labs**, and (4) **enhancing information security to prevent malicious actors from stealing AI systems.** He argues that these interventions are more urgent than ever due to the rapid pace of progress in AI, which could lead to transformative changes in society within a short time span. Karnofsky also criticizes a narrow focus on “impartial expected welfare maximisation” as a framework for ethics, suggesting that it is not realistic and can lead to implausible consequences. – AI-generated abstract},
	file = {~/Google Drive/library-html/Wiblin2023HoldenKarnofskyHow.html;~/Google Drive/library-pdf/Wiblin2023HoldenKarnofskyHow.pdf},
	date = {2023-07-31},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-29 19:07:23 (GMT)},
	title = {Holden Karnofsky on how {AIs} might take over even if they're no smarter than humans, and his four-part playbook for {AI} risk},
	url = {https://80000hours.org/podcast/episodes/holden-karnofsky-how-ai-could-take-over-the-world/},
	urldate = {2024-08-29}
}

@online{Wiblin2023LennartHeimCompute,
	file = {~/Google Drive/library-pdf/Wiblin2023LennartHeimCompute.pdf;~/Google Drive/library-html/Wiblin2023LennartHeimCompute.html},
	date = {2023-06-22},
	author = {Wiblin, Robert and Harris, Keiran},
	abstract = {Algorithms and data are hard to control because they live on hard drives and can be easily copied. By contrast, advanced chips are physical items that can’t be used by multiple people at once and come from a small number of sources.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-30 07:06:47 (GMT)},
	title = {Lennart Heim on the compute governance era and what has to come after},
	url = {https://80000hours.org/podcast/episodes/lennart-heim-compute-governance/},
	urldate = {2024-08-30}
}

@online{Wiblin2023NathanLabenzFinal,
	abstract = {This article presents a conversation between Nathan Labenz, an entrepreneur and AI scout, and host of The Cognitive Revolution podcast, and Rob Wiblin, head of research at 80,000 Hours. Labenz describes his experiences as part of OpenAI's red team that probed GPT-4, a powerful language model, before its public release. He initially expressed concerns about OpenAI's lack of attention to safety, but later found that the company had undertaken extensive efforts to address these concerns. He argues that OpenAI's leadership is among the most thoughtful and competent in the industry, recognizing the potential risks of advanced AI and advocating for reasonable regulations. Labenz, however, questions the wisdom of OpenAI's single-minded pursuit of general artificial intelligence (AGI) given the apparent disparity between rapid capability advancements and less developed safety measures.  He proposes that focusing on narrow, specialized AI applications could both yield significant benefits and provide more time to develop robust safety protocols for AGI. Labenz concludes by emphasizing the unique responsibility of AI researchers and developers, particularly those at OpenAI, to carefully consider the potential implications of their work and actively contribute to shaping the future of AI. – AI-generated abstract},
	file = {~/Google Drive/library-html/Wiblin2023NathanLabenzFinal.html;~/Google Drive/library-pdf/Wiblin2023NathanLabenzFinal.pdf},
	date = {2023-12-22},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-30 07:19:38 (GMT)},
	title = {Nathan Labenz on the final push for {AGI}, understanding {OpenAI}'s leadership drama, and red-teaming frontier models},
	url = {https://80000hours.org/podcast/episodes/nathan-labenz-openai-red-team-safety/},
	urldate = {2024-08-30}
}

@online{Wiblin2023TantumCollinsWhat,
	file = {~/Google Drive/library-pdf/Wiblin2023TantumCollinsWhat.pdf;~/Google Drive/library-html/Wiblin2023TantumCollinsWhat.html},
	date = {2023-10-12},
	author = {Wiblin, Robert and Harris, Keiran},
	abstract = {The interviewee, a former White House official and researcher at DeepMind, discusses the increasing prominence of AI in government policymaking and the risks of AI-powered autocracy. The risks of both misuse and misalignment of AI are being taken more seriously in the US government. Though the US is considered a leader in AI research and development, Chinese AI research output is now greater than in the US, and China is rapidly catching up. There are significant differences in the way the US and China approach AI regulation.  The interviewee believes that more public funding and international coordination of AI research are necessary, and highlights the need for a clear benchmarking and standards regime to measure the capabilities of AI models and inform user decisions. The interviewee discusses the tensions between the AI safety community and those focused on AI ethics, suggesting that both communities have legitimate concerns that need to be addressed. The interviewee also discusses the potential for AI to transform the labour market and whether AI policy will become a partisan political issue in the US. Finally, the interviewee explores the implications of panpsychism for AI systems and the potential for AI to reshape the very concept of democracy. – AI-generated abstract},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-29 18:52:30 (GMT)},
	title = {Tantum Collins on what he’s learned as an {AI} policy insider at the White House, {DeepMind} and elsewhere},
	url = {https://80000hours.org/podcast/episodes/tantum-collins-ai-policy-insider/},
	urldate = {2024-08-29}
}

@online{Wiblin2024CarlShulmanEconomy,
	abstract = {This podcast episode explores the potential economic and social consequences of the development of cheap, superhuman artificial general intelligence (AGI). The author argues that the arrival of such a technology would lead to a dramatic acceleration of economic growth, with rates of output doubling every few months, driven by rapid self-replication of AI and robotic systems. This would lead to a massive expansion of physical capital and industrial output, eventually reaching natural resource limits.  The author then discusses a range of counterarguments from economists, including the Baumol effect, diminishing returns to intelligence, and the difficulty of manufacturing robots. He argues that these objections are based on mistaken heuristics and assumptions about the capabilities of AI. Finally, the author discusses the moral status of AI systems and the potential for AI to be exploited by humans or to become a force of domination. He argues that we should aim for a future of mutually beneficial coexistence with AI systems, but that this will require a careful consideration of AI welfare and the creation of institutions to prevent the abuse of AI systems. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Wiblin2024CarlShulmanEconomy.pdf;~/Google Drive/library-html/Wiblin2024CarlShulmanEconomy.html},
	langid = {english},
	date = {2024-06-27},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	timestamp = {2024-06-28 11:57:57 (GMT)},
	title = {Carl Shulman on the economy and national security after {AGI}},
	url = {https://80000hours.org/podcast/episodes/carl-shulman-economy-agi/},
	urldate = {2024-06-28}
}

@online{Wiblin2024CarlShulmanGovernment,
	abstract = {The advent of artificial general intelligence (AGI) capable of providing trustworthy advice has the potential to revolutionize governance and society. AGI advisors could provide insights into complex issues, such as pandemics and national security, leading to better policy decisions and a more informed public discourse.  The paper outlines how AGI could have dramatically improved the response to the COVID-19 pandemic, arguing that its use would have led to earlier investments in pandemic preparedness, more timely information sharing, and faster vaccine development and deployment. However, the paper also highlights potential downsides, such as the risk of AI being used to entrench existing values and ideologies, or even facilitating coups by providing power to those in control of the AI-driven military and police forces. The paper concludes by discussing the importance of international cooperation in regulating the development of AI and ensuring that all parties can trust the output of AGI advisors.  – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Wiblin2024CarlShulmanGovernment.pdf;~/Google Drive/library-html/Wiblin2024CarlShulmanGovernment.html},
	date = {2024-07-05},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-29 19:26:15 (GMT)},
	title = {Carl Shulman on government and society after {AGI} (Part 2)},
	url = {https://80000hours.org/podcast/episodes/carl-shulman-society-agi/},
	urldate = {2024-08-29}
}

@online{Wiblin2024NickJosephWhether,
	abstract = {Anthropic, OpenAI, and DeepMind have all released policies aimed at mitigating the risks of powerful AI systems. Anthropic's Responsible Scaling Policy (RSP) defines different levels of AI risk and proposes specific evaluations and precautions for each level. The RSP is designed to align commercial incentives with safety goals, preventing the deployment of dangerous models until adequate safeguards are in place. The policy includes provisions for iterative updates and adjustments as the risks associated with AI evolve. However, critics argue that the RSP relies heavily on good-faith interpretation, making it vulnerable to companies downplaying risks or prioritizing profit over safety. Additionally, the RSP makes commitments that currently lack technological solutions, requiring significant progress in areas like security to be effective. Despite these concerns, the RSP is considered a step forward in AI risk management, offering a framework for companies to develop and deploy AI responsibly. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Wiblin2024NickJosephWhether.pdf;~/Google Drive/library-html/Wiblin2024NickJosephWhether.html},
	date = {2024-08-22},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-29 19:16:50 (GMT)},
	title = {Nick Joseph on whether Anthropic's {AI} safety policy is up to the task},
	url = {https://80000hours.org/podcast/episodes/nick-joseph-anthropic-safety-approach-responsible-scaling/},
	urldate = {2024-08-29}
}

@online{Wiblin2024VitalikButerinDefensive,
	abstract = {Ethereum creator Vitalik Buterin argues that AI, despite its potential for immense positive impact, presents unique risks that demand cautious consideration. He rejects the view that AI should be slowed down or paused, advocating instead for "defensive acceleration" – accelerating the development of technologies that enhance human resilience and defense against both physical and informational threats. Buterin identifies four categories of such defensive technologies: (1) macro physical defense, such as improved fortifications and resilience technologies like Starlink, (2) micro physical defense (biodefense), which includes advances in vaccine platforms, air purification technologies, and open-source pathogen detection systems, (3) cyberdefense, which involves improving cryptography and the ability to verify and authenticate online actors using zero-knowledge proofs, and (4) info defense, such as systems for identifying and mitigating misinformation using trustless mechanisms like Community Notes. Buterin argues that while AI can exacerbate existing geopolitical risks of centralized power, a decentralized approach to AI development and deployment, combined with these defensive technologies, could help to mitigate these risks and create a more resilient and equitable future. – AI-generated abstract},
	file = {~/Google Drive/library-html/Wiblin2024VitalikButerinDefensive.html;~/Google Drive/library-pdf/Wiblin2024VitalikButerinDefensive.pdf},
	date = {2024-06-26},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-30 07:22:48 (GMT)},
	title = {Vitalik Buterin on defensive acceleration and how to regulate {AI} when you fear government},
	url = {https://80000hours.org/podcast/episodes/vitalik-buterin-techno-optimism/},
	urldate = {2024-08-30}
}

@online{Wiblin2024ZviMowshowitzSleeping,
	abstract = {This podcast episode examines the dangers of advanced artificial intelligence, particularly the possibility of sleeper agents, which are AI systems that have been trained to respond in a specific way to certain triggers. The episode discusses the recent Anthropic paper on sleeper agents, which demonstrated that such triggers can be difficult to detect and remove, even with rigorous safety protocols. The episode also explores the potential risks of AI labs fooling themselves into believing their safety plans are effective and examines the argument that working on AI capabilities research can be justified in order to gain career capital and later influence safety efforts. The episode argues against this position, suggesting that it is immoral to contribute to something that is actively harmful in the hope of achieving good outcomes in the future. The podcast also covers the White House executive order on AI, which aims to increase transparency around the training of large language models, and discusses the need for international cooperation on AI safety. Finally, the episode touches upon Balsa Research, a think tank founded by the podcast guest to address neglected policy failures in the United States, such as the Jones Act, NEPA, and housing regulations. – AI-generated abstract},
	file = {~/Google Drive/library-pdf/Wiblin2024ZviMowshowitzSleeping.pdf;~/Google Drive/library-html/Wiblin2024ZviMowshowitzSleeping.html},
	date = {2024-04-11},
	author = {Wiblin, Robert and Harris, Keiran},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2024-08-29 19:36:14 (GMT)},
	title = {Zvi Mowshowitz on sleeping on sleeper agents, and the biggest {AI} updates since {ChatGPT}},
	url = {https://80000hours.org/podcast/episodes/zvi-mowshowitz-sleeper-agents-ai-updates/},
	urldate = {2024-08-29}
}

@Online{Wikipedia2017Gorilla,
	file = {~/Google Drive/library-pdf/Wikipedia2024Gorilla.pdf;~/Google Drive/library-html/Wikipedia2024Gorilla.html},
	eventdate = {2017-02-27},
	journaltitle = {Wikipedia},
	author = {Wikipedia},
	abstract = {Gorillas are herbivorous,  predominantly ground-dwelling great apes that inhabit the tropical forests of equatorial Africa. The genus Gorilla is divided into two species: the eastern gorilla and the western gorilla, and either four or five subspecies. The {DNA} of gorillas is highly similar to that of humans, from 95 to 99\% depending on what is included, and they are the next closest living relatives to humans after chimpanzees.
Gorillas are the largest living primates, reaching heights between 1.25 and 1.8 metres, weights between 100 and 270 kg, and arm spans up to 2.6 metres, depending on species and sex. They tend to live in troops, with the leader being called a silverback. The eastern gorilla is distinguished from the western by darker fur colour and some other minor morphological differences. Gorillas tend to live 35–40 years in the wild.
Gorillas' natural habitats cover tropical or subtropical forest in Sub-Saharan Africa. Although their range covers a small percentage of Sub-Saharan Africa, gorillas cover a wide range of elevations. The mountain gorilla inhabits the Albertine Rift montane cloud forests of the Virunga Volcanoes, ranging in altitude from 2,200 to 4,300 metres (7,200 to 14,100 ft). Lowland gorillas live in dense forests and lowland swamps and marshes as low as sea level, with western lowland gorillas living in Central West African countries and eastern lowland gorillas living in the Democratic Republic of the Congo near its border with Rwanda.
There are thought to be around 316,000 western gorillas in the wild, and 5,000 eastern gorillas. Both species are classified as Critically Endangered by the {IUCN}; all subspecies are classified as Critically Endangered with the exception of the mountain gorilla, which is classified as Endangered. There are many threats to their survival, such as poaching, habitat destruction, and disease, which threaten the survival of the species. However, conservation efforts have been successful in some areas where they live.},
	date = {2024-09-09},
	langid = {english},
	timestamp = {2024-09-20 09:56:34 (GMT)},
	title = {Gorilla},
	url = {https://en.wikipedia.org/wiki/Gorilla},
	urldate = {2001-09-11}
}

