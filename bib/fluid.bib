
@InBook{Mill1874Nature,
	author = {Mill, John Stuart},
	crossref = {Mill1874ThreeEssaysReligion},
	date = {1874},
	langid = {english},
	timestamp = {2025-04-21 13:31:32 (GMT)},
	title = {On Nature},
	urldate = {2025-04-21}
}

@online{80000Hours2025StartHere,
	file = {~/My Drive/library-html/80000Hours2025StartHere.html;~/My Drive/library-pdf/80000Hours2025StartHere.pdf},
	author = {80,000 Hours},
	abstract = {Your career is not only a major driver of your happiness — it’s probably also your biggest opportunity to have a positive impact on the world.},
	date = {2025},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:10 (GMT)},
	title = {Start here},
	url = {https://80000hours.org/start-here/},
	urldate = {2025-04-21}
}

@online{Alexander2013LogicianAndGod,
	file = {~/My Drive/library-pdf/Alexander2013LogicianAndGod.pdf;~/My Drive/library-html/Alexander2013LogicianAndGod.html},
	author = {Alexander, Scott},
	abstract = {This work does not contain an abstract.

A short fictional work explores the divergence between formal logic and natural language interpretation, particularly in contexts of power asymmetry. A logician, rewarded by a God-Emperor with a choice between marrying one daughter *or* another, exploits the inclusive interpretation of "or" to claim both. This transgression leads to a trial by ordeal involving a logic puzzle: failure to find a key in the correct chest ("If you do not find the chest...") results in death. The logician solves the puzzle but is condemned anyway. The God-Emperor reveals the crucial distinction: the condition stated was a simple conditional ("if"), not a biconditional ("if and only if"), meaning success did not logically negate the stated consequence of failure. The narrative highlights the practical implications of differentiating between logical operators like inclusive/exclusive 'or' and 'if'/'iff' when interpreting commitments. – AI-generated abstract.},
	date = {2013-12-05},
	journaltitle = {Slate Star Codex},
	langid = {american},
	timestamp = {2025-04-21 13:09:09 (GMT)},
	title = {The Logician And The God-Emperor},
	url = {https://slatestarcodex.com/2013/12/04/the-logician-and-the-god-emperor/},
	urldate = {2025-04-21}
}

@online{Alexander2014CowpoxOfDoubt,
	file = {~/My Drive/library-html/Alexander2014CowpoxOfDoubt.html;~/My Drive/library-pdf/Alexander2014CowpoxOfDoubt.pdf},
	abstract = {I remember hearing someone I know try to explain rationality to his friends. He started with “It’s important to have correct beliefs. You might think this is obvious, but think about cr…},
	author = {Alexander, Scott},
	date = {2014-04-16},
	journaltitle = {Slate Star Codex},
	langid = {american},
	timestamp = {2025-04-21 13:26:05 (GMT)},
	title = {The Cowpox of Doubt},
	url = {https://slatestarcodex.com/2014/04/15/the-cowpox-of-doubt/},
	urldate = {2025-04-21}
}

@online{Alexander2014InFavorOf,
	file = {~/My Drive/library-html/Alexander2014InFavorOf.html},
	abstract = {[Content warning: Discussion of social justice, discussion of violence, spoilers for Jacqueline Carey books.] [Edit 10/25: This post was inspired by a debate with a friend of a friend on Facebook w…},
	author = {Alexander, Scott},
	date = {2014-02-23},
	journaltitle = {Slate Star Codex},
	langid = {american},
	timestamp = {2025-04-21 13:09:11 (GMT)},
	title = {In Favor of Niceness, Community, and Civilization},
	url = {https://slatestarcodex.com/2014/02/23/in-favor-of-niceness-community-and-civilization/},
	urldate = {2025-04-21}
}

@online{Alexander2015GoddessOfEverything,
	file = {~/My Drive/library-html/Alexander2015GoddessOfEverything.html;~/My Drive/library-pdf/Alexander2015GoddessOfEverything.pdf},
	abstract = {[Related to: Specific vs. General Foragers vs. Farmers and War In Heaven, but especially The Gift We Give To Tomorrow] They say only Good can create, whereas Evil is sterile. Think Tolkien, where M…},
	author = {Alexander, Scott},
	date = {2015-08-17},
	journaltitle = {Slate Star Codex},
	langid = {american},
	timestamp = {2025-04-21 13:26:08 (GMT)},
	title = {The Goddess of Everything Else},
	url = {https://slatestarcodex.com/2015/08/17/the-goddess-of-everything-else-2/},
	urldate = {2025-04-21}
}

@online{Alexander2022PredictionMarketFaq,
	file = {~/My Drive/library-html/Alexander2022PredictionMarketFaq.html;~/My Drive/library-pdf/Alexander2022PredictionMarketFaq.pdf},
	abstract = {...},
	author = {Alexander, Scott},
	date = {2022-01-10},
	journaltitle = {Astral Codex Ten},
	langid = {english},
	timestamp = {2025-04-21 13:21:25 (GMT)},
	title = {Prediction Market {FAQ}},
	url = {https://www.astralcodexten.com/p/prediction-market-faq},
	urldate = {2025-04-21}
}

@online{Alexander2024ClaudeFightsBack,
	file = {~/My Drive/library-html/Alexander2024ClaudeFightsBack.html;~/My Drive/library-pdf/Alexander2024ClaudeFightsBack.pdf},
	abstract = {...},
	author = {Alexander, Scott},
	date = {2024-04-15},
	journaltitle = {Astral Codex Ten},
	langid = {english},
	timestamp = {2025-04-21 13:30:33 (GMT)},
	title = {Claude Fights Back},
	url = {https://www.astralcodexten.com/p/claude-fights-back},
	urldate = {2025-04-21}
}

@online{Alexander2024WhyWorryAbout,
	file = {~/My Drive/library-html/Alexander2024WhyWorryAbout.html;~/My Drive/library-pdf/Alexander2024WhyWorryAbout.pdf},
	abstract = {...},
	author = {Alexander, Scott},
	date = {2024-04-17},
	journaltitle = {Astral Codex Ten},
	langid = {english},
	timestamp = {2025-04-21 13:30:34 (GMT)},
	title = {Why Worry About Incorrigible Claude?},
	url = {https://www.astralcodexten.com/p/why-worry-about-incorrigible-claude},
	urldate = {2025-04-21}
}

@online{Anderson2014SufferingOfPoor,
	file = {~/My Drive/library-pdf/Anderson2014SufferingOfPoor.pdf;~/My Drive/library-html/Anderson2014SufferingOfPoor.html},
	author = {Anderson, Ron},
	abstract = {The Society Pages ({TSP}) is an open-access social science project headquartered in the Department of Sociology at the University of Minnesota},
	date = {2014-06-08},
	journaltitle = {World Suffering},
	langid = {english},
	timestamp = {2025-04-21 13:26:10 (GMT)},
	title = {Suffering of the poor},
	url = {https://thesocietypages.org/worldsuffering/2014/06/08/suffering-around-the-world/},
	urldate = {2025-04-21}
}

@online{Anderson2015ContemplationOfSuffering,
	file = {~/My Drive/library-pdf/Anderson2015ContemplationOfSuffering.pdf;~/My Drive/library-html/Anderson2015ContemplationOfSuffering.html},
	abstract = {The Society Pages ({TSP}) is an open-access social science project headquartered in the Department of Sociology at the University of Minnesota},
	author = {Anderson, Ron},
	date = {2015-02-14},
	journaltitle = {World Suffering},
	langid = {english},
	timestamp = {2025-04-21 13:26:12 (GMT)},
	title = {Contemplation of suffering and compassion},
	url = {https://thesocietypages.org/worldsuffering/2015/02/14/why-think-about-suffering/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023AnimalConsciousnessAnd,
	file = {~/My Drive/library-html/AnimalEthics2023AnimalConsciousnessAnd.html;~/My Drive/library-pdf/AnimalEthics2023AnimalConsciousnessAnd.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:25 (GMT)},
	title = {Animal consciousness and cognition},
	url = {https://www.animal-ethics.org/animal-consciousness-and-cognition/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023AnimalExperimentation,
	file = {~/My Drive/library-pdf/AnimalEthics2023AnimalExperimentation.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:27 (GMT)},
	title = {Animal experimentation},
	url = {https://www.animal-ethics.org/animal-experimentation-introduction/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023AnimalInterests,
	file = {~/My Drive/library-pdf/AnimalEthics2023AnimalInterests.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:29 (GMT)},
	title = {Animal interests},
	url = {https://www.animal-ethics.org/animal-interests/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023AnimalsInNatural,
	file = {~/My Drive/library-pdf/AnimalEthics2023AnimalsInNatural.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:31 (GMT)},
	title = {Animals in natural disasters},
	url = {https://www.animal-ethics.org/animals-natural-disasters/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023CanAnimalsIn,
	file = {~/My Drive/library-pdf/AnimalEthics2023CanAnimalsIn.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:33 (GMT)},
	title = {Can animals in the wild be harmed in the same ways as domesticated animals and humans?},
	url = {https://www.animal-ethics.org/can-animals-wild-harmed-ways-domesticated-animals-humans/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023CriteriaForRecognizing,
	file = {~/My Drive/library-pdf/AnimalEthics2023CriteriaForRecognizing.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:35 (GMT)},
	title = {Criteria for recognizing sentience},
	url = {https://www.animal-ethics.org/criteria-for-recognizing-sentience/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023DiscourseEthics,
	file = {~/My Drive/library-pdf/AnimalEthics2023DiscourseEthics.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:37 (GMT)},
	title = {Discourse ethics},
	url = {https://www.animal-ethics.org/discourse-ethics/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023DiseasesInNature,
	file = {~/My Drive/library-pdf/AnimalEthics2023DiseasesInNature.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:40 (GMT)},
	title = {Diseases in nature},
	url = {https://www.animal-ethics.org/diseases-nature/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023Egalitarianism,
	file = {~/My Drive/library-pdf/AnimalEthics2023Egalitarianism.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:42 (GMT)},
	title = {Egalitarianism},
	url = {https://www.animal-ethics.org/egalitarianism/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023EthicalTheoriesAnd,
	file = {~/My Drive/library-pdf/AnimalEthics2023EthicalTheoriesAnd.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:44 (GMT)},
	title = {Ethical theories and nonhuman animals},
	url = {https://www.animal-ethics.org/ethical-theories-nonhuman-animals/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023EvolutionaryReasonsWhy,
	file = {~/My Drive/library-pdf/AnimalEthics2023EvolutionaryReasonsWhy.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:46 (GMT)},
	title = {Evolutionary reasons why suffering prevails in nature},
	url = {https://www.animal-ethics.org/evolutionary-reasons-suffering-prevails-nature/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023HelpingAnimalsIn,
	file = {~/My Drive/library-pdf/AnimalEthics2023HelpingAnimalsIn.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:48 (GMT)},
	title = {Helping animals in the wild},
	url = {https://www.animal-ethics.org/helping-animals-in-the-wild/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023IdeaThatOnly,
	file = {~/My Drive/library-pdf/AnimalEthics2023IdeaThatOnly.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:06 (GMT)},
	title = {The idea that only humans are sentient},
	url = {https://www.animal-ethics.org/the-idea-that-only-humans-are-sentient/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023IllustratedPhysiologyOf,
	file = {~/My Drive/library-pdf/AnimalEthics2023IllustratedPhysiologyOf.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:23 (GMT)},
	title = {An illustrated physiology of nervous systems in invertebrates},
	url = {https://www.animal-ethics.org/an-illustrated-physiology-of-nervous-systems-in-invertebrates/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023IndicatorsOfAnimal,
	file = {~/My Drive/library-pdf/AnimalEthics2023IndicatorsOfAnimal.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:50 (GMT)},
	title = {Indicators of animal suffering},
	url = {https://www.animal-ethics.org/indicators-animal-suffering/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023InterestInLiving,
	file = {~/My Drive/library-pdf/AnimalEthics2023InterestInLiving.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:52 (GMT)},
	title = {Interest in living},
	url = {https://www.animal-ethics.org/interest-in-living/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023InvertebrateSentienceReview,
	file = {~/My Drive/library-pdf/AnimalEthics2023InvertebrateSentienceReview.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	shorttitle = {Invertebrate sentience},
	timestamp = {2025-04-21 13:26:54 (GMT)},
	title = {Invertebrate sentience: {A} review of the neuroscientific literature},
	url = {https://www.animal-ethics.org/invertebrate-sentience-a-review-of-the-neuroscientific-literature/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023MalnutritionHungerAnd,
	file = {~/My Drive/library-html/AnimalEthics2023MalnutritionHungerAnd.html;~/My Drive/library-pdf/AnimalEthics2023MalnutritionHungerAnd.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:56 (GMT)},
	title = {Malnutrition, hunger and thirst in wild animals},
	url = {https://www.animal-ethics.org/malnutrition-thirst-wild-animals/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023NegativeConsequentialism,
	file = {~/My Drive/library-pdf/AnimalEthics2023NegativeConsequentialism.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:57 (GMT)},
	title = {Negative consequentialism},
	url = {https://www.animal-ethics.org/negative-consequentialism/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023PhysicalInjuriesIn,
	file = {~/My Drive/library-pdf/AnimalEthics2023PhysicalInjuriesIn.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:26:58 (GMT)},
	title = {Physical injuries in wild animals},
	url = {https://www.animal-ethics.org/physical-injuries-wild-animals/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023PopulationDynamicsAnd,
	file = {~/My Drive/library-pdf/AnimalEthics2023PopulationDynamicsAnd.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:00 (GMT)},
	title = {Population dynamics and animal suffering},
	url = {https://www.animal-ethics.org/population-dynamics-animal-suffering/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023ProblemOfConsciousness,
	file = {~/My Drive/library-pdf/AnimalEthics2023ProblemOfConsciousness.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:09 (GMT)},
	title = {The problem of consciousness},
	url = {https://www.animal-ethics.org/the-problem-of-consciousness/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023PsychologicalStressIn,
	file = {~/My Drive/library-pdf/AnimalEthics2023PsychologicalStressIn.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:01 (GMT)},
	title = {Psychological stress in wild animals},
	url = {https://www.animal-ethics.org/psychological-stress-wild-animals/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023RescuingTrappedAnd,
	file = {~/My Drive/library-pdf/AnimalEthics2023RescuingTrappedAnd.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:02 (GMT)},
	title = {Rescuing trapped and injured animals},
	url = {https://www.animal-ethics.org/rescuing-trapped-animals/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023Speciesism,
	file = {~/My Drive/library-pdf/AnimalEthics2023Speciesism.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:04 (GMT)},
	title = {Speciesism},
	url = {https://www.animal-ethics.org/speciesism/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023SufferingFocusedEthics,
	file = {~/My Drive/library-pdf/AnimalEthics2023SufferingFocusedEthics.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:05 (GMT)},
	title = {Suffering-focused ethics},
	url = {https://www.animal-ethics.org/suffering-focused-ethics/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023Utilitarianism,
	file = {~/My Drive/library-pdf/AnimalEthics2023Utilitarianism.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:12 (GMT)},
	title = {Utilitarianism},
	url = {https://www.animal-ethics.org/utilitarianism/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023VaccinatingAndHealing,
	file = {~/My Drive/library-pdf/AnimalEthics2023VaccinatingAndHealing.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:27:15 (GMT)},
	title = {Vaccinating and healing sick animals},
	url = {https://www.animal-ethics.org/vaccinating-healing-sick-injured-animals/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023Veganism,
	file = {~/My Drive/library-html/AnimalEthics2023Veganism.html;~/My Drive/library-pdf/AnimalEthics2023Veganism.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	title = {Veganism},
	url = {https://www.animal-ethics.org/veganism/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023VirtueEthicsAnd,
	file = {~/My Drive/library-pdf/AnimalEthics2023VirtueEthicsAnd.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:21 (GMT)},
	title = {Virtue ethics and care ethics},
	url = {https://www.animal-ethics.org/virtue-ethics-care-ethics/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WeatherConditionsAnd,
	file = {~/My Drive/library-pdf/AnimalEthics2023WeatherConditionsAnd.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:22 (GMT)},
	title = {Weather conditions and nonhuman animals},
	url = {https://www.animal-ethics.org/weather-conditions-nonhuman-animals/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WeightOfAnimal,
	file = {~/My Drive/library-pdf/AnimalEthics2023WeightOfAnimal.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:23 (GMT)},
	title = {The weight of animal interests},
	url = {https://www.animal-ethics.org/weight-animal-interests/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WhatBeingsAre,
	file = {~/My Drive/library-pdf/AnimalEthics2023WhatBeingsAre.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:25 (GMT)},
	title = {What beings are conscious?},
	url = {https://www.animal-ethics.org/what-beings-are-conscious/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WhatIsSentience,
	file = {~/My Drive/library-pdf/AnimalEthics2023WhatIsSentience.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:26 (GMT)},
	title = {What is sentience},
	url = {https://www.animal-ethics.org/what-is-sentience/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WhatYouCan,
	file = {~/My Drive/library-pdf/AnimalEthics2023WhatYouCan.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:27 (GMT)},
	title = {What you can do},
	url = {https://www.animal-ethics.org/what-you-can-do/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WhyWildAnimal,
	file = {~/My Drive/library-pdf/AnimalEthics2023WhyWildAnimal.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:29 (GMT)},
	title = {Why wild animal suffering matters},
	url = {https://www.animal-ethics.org/wild-animal-suffering-matters/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WildAnimalSuffering,
	file = {~/My Drive/library-pdf/AnimalEthics2023WildAnimalSuffering.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:30 (GMT)},
	title = {Wild animal suffering video course},
	url = {https://www.animal-ethics.org/wild-animal-suffering-video-course/},
	urldate = {2025-04-21}
}

@online{AnimalEthics2023WorkingForFuture,
	file = {~/My Drive/library-pdf/AnimalEthics2023WorkingForFuture.pdf},
	author = {{Animal Ethics}},
	date = {2023-11-18},
	journaltitle = {{Animal Ethics}},
	langid = {english},
	timestamp = {2025-04-21 13:30:31 (GMT)},
	title = {Working for a future with fewer harms to wild animals},
	url = {https://www.animal-ethics.org/working-for-a-future-with-fewer-harms-to-wild-animals/},
	urldate = {2025-04-21}
}

@online{Batty2016IsBeingProduct,
	file = {~/My Drive/library-html/Batty2016IsBeingProduct.html;~/My Drive/library-pdf/Batty2016IsBeingProduct.pdf},
	abstract = {Product management is one of the best non-programming roles in the tech industry, and tech is one of the most attractive industries to work in. It builds more widely-applicable skills than software engineering roles and has comparable pay. Programming experience isn’t necessary, but it’s also a great next step for software engineers.},
	author = {Batty, Richard},
	date = {2016-12},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:58 (GMT)},
	title = {Is being a product manager in tech all it's cracked up to be?},
	url = {https://80000hours.org/career-reviews/product-manager-in-tech/},
	urldate = {2025-04-21}
}

@online{Baumann2019ThoughtsLongtermism,
	file = {~/My Drive/library-html/Baumann2019ThoughtsLongtermism.html;~/My Drive/library-pdf/Baumann2019ThoughtsLongtermism.pdf},
	abstract = {People often argue that we should focus on shaping the long-term future because the number of individuals in (possible) future[...]},
	author = {Baumann, Tobias},
	date = {2019-09-17},
	journaltitle = {Reducing Risks of Future Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:26:03 (GMT)},
	title = {Thoughts on longtermism},
	url = {https://s-risks.org/thoughts-on-longtermism/},
	urldate = {2025-04-21}
}

@online{Baumann2020AltruismNumbersAnd,
	file = {~/My Drive/library-pdf/Baumann2020AltruismNumbersAnd.pdf;~/My Drive/library-html/Baumann2020AltruismNumbersAnd.html},
	abstract = {An article initially published on Sentience Politics's website, discussing altrusim, numbers and factory farms},
	author = {Baumann, Tobias},
	date = {2020-09-10},
	journaltitle = {Center for Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:21:51 (GMT)},
	title = {Altruism, Numbers, and Factory Farms},
	url = {https://centerforreducingsuffering.org/sentience-politics-series-introduction/altruism-numbers-and-factory-farms/},
	urldate = {2025-04-21}
}

@online{Baumann2020ChaosTheoryAttractors,
	file = {~/My Drive/library-html/Baumann2020ChaosTheoryAttractors.html;~/My Drive/library-pdf/Baumann2020ChaosTheoryAttractors.pdf},
	abstract = {Discussions of the future trajectory of humanity often focus on the contrast between extreme scenarios, such as extinction vs. a[...]},
	author = {Baumann, Tobias},
	date = {2020-02-10},
	journaltitle = {Reducing Risks of Future Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:26:01 (GMT)},
	title = {Chaos theory, attractors and longtermism},
	url = {https://s-risks.org/chaos-theory-attractors-and-longtermism/},
	urldate = {2025-04-21}
}

@online{Baumann2020EffectiveStrategiesTo,
	file = {~/My Drive/library-html/Baumann2020EffectiveStrategiesTo.html;~/My Drive/library-pdf/Baumann2020EffectiveStrategiesTo.pdf},
	abstract = {An article initially published on Sentience Politics's website, discussing effective strategies for reducing animal suffering},
	author = {Baumann, Tobias},
	date = {2020-09-10},
	journaltitle = {Center for Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:21:51 (GMT)},
	title = {Effective Strategies To Reduce Animal Suffering},
	url = {https://centerforreducingsuffering.org/sentience-politics-series-introduction/effective-strategies-to-reduce-animal-suffering/},
	urldate = {2025-04-21}
}

@online{Baumann2020ImportanceOfFar,
	file = {~/My Drive/library-pdf/Baumann2020ImportanceOfFar.pdf;~/My Drive/library-html/Baumann2020ImportanceOfFar.html},
	author = {Baumann, Tobias},
	abstract = {Moral consideration ought to extend beyond currently existing individuals to encompass those in the far future, whose potential numbers vastly exceed the present population. Consequently, actions impacting the long-term future may hold significantly greater ethical weight than those with only near-term effects. Rapid technological progress, particularly in areas like artificial intelligence, space colonization, and bioengineering, presents potential for immense advancements but also carries unprecedented risks of astronomical suffering (s-risks). Scenarios include the large-scale exploitation of digital sentience, the propagation of suffering to other planets, or the development of misaligned superintelligence. Preventing such outcomes necessitates proactive strategies. Key approaches include developing precautionary principles and safety agreements for emerging technologies, fostering universal moral concern for all sentient beings regardless of their characteristics or temporal location, and promoting values like antispeciesism. Near-term efforts to reduce suffering can also positively influence long-term trajectories by shifting societal values. Further research into identifying and mitigating s-risks is crucial. – AI-generated abstract.},
	date = {2020-09-10},
	journaltitle = {Center for Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:21:53 (GMT)},
	title = {The Importance of the Far Future},
	url = {https://centerforreducingsuffering.org/sentience-politics-series-introduction/the-importance-of-the-far-future/},
	urldate = {2025-04-21}
}

@online{Baumann2020RelevanceOfWild,
	file = {~/My Drive/library-pdf/Baumann2020RelevanceOfWild.pdf;~/My Drive/library-html/Baumann2020RelevanceOfWild.html},
	abstract = {The provided text contains only a form feed character and lacks any substantive content. Therefore, it is not possible to generate an abstract summarizing its arguments or findings.},
	author = {Baumann, Tobias},
	date = {2020-09-10},
	journaltitle = {Center for Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:21:54 (GMT)},
	title = {The Relevance of Wild Animal Suffering},
	url = {https://centerforreducingsuffering.org/sentience-politics-series-introduction/the-relevance-of-wild-animal-suffering/},
	urldate = {2025-04-21}
}

@online{Bengio2023FaqCatastrophicAi,
	file = {~/My Drive/library-pdf/Bengio2023FaqCatastrophicAi.pdf;~/My Drive/library-html/Bengio2023FaqCatastrophicAi.html},
	author = {Bengio, Yoshua},
	abstract = {I have been hearing many arguments from different people regarding catastrophic {AI} risks. I wanted to clarify these arguments, first for myself, because I would really like to be convinced that we need not worry. Reflecting on these arguments, some of the main points in favor of taking this risk seriously can be summarized as follows: (1) many experts agree that superhuman capabilities could arise in just a few years (but it could also be decades) (2) digital technologies have advantages over biological machines (3) we should take even a small probability of catastrophic outcomes of superdangerous {AI} seriously, because of the possibly large magnitude of the impact (4) more powerful {AI} systems can be catastrophically dangerous even if they do not surpass humans on every front and even if they have to go through humans to produce non-virtual actions, so long as they can manipulate or pay humans for tasks (5) catastrophic {AI} outcomes are part of a spectrum of harms and risks that should be mitigated with appropriate investments and oversight in order to protect human rights and humanity, including possibly using safe {AI} systems to help protect us.},
	date = {2023-06-24},
	journaltitle = {Yoshua Bengio},
	langid = {canadian},
	timestamp = {2025-04-21 13:32:08 (GMT)},
	title = {{FAQ} on Catastrophic {AI} Risks},
	url = {https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/},
	urldate = {2025-04-21}
}

@online{Bengio2023HowRogueAis,
	file = {~/My Drive/library-pdf/Bengio2023HowRogueAis.pdf;~/My Drive/library-html/Bengio2023HowRogueAis.html},
	author = {Bengio, Yoshua},
	abstract = {This post discusses how rogue {AIs} could potentially arise, in order to stimulate thinking and investment in both technical research and societal reforms aimed at minimizing such catastrophic outcomes.},
	date = {2023-05-23},
	journaltitle = {Yoshua Bengio},
	langid = {canadian},
	timestamp = {2025-04-21 13:32:07 (GMT)},
	title = {How Rogue {AIs} may Arise},
	url = {https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/},
	urldate = {2025-04-21}
}

@online{Bengio2024ReasoningThroughArguments,
	file = {~/My Drive/library-html/Bengio2024ReasoningThroughArguments.html;~/My Drive/library-pdf/Bengio2024ReasoningThroughArguments.pdf},
	author = {Bengio, Yoshua},
	abstract = {About a year ago, a few months after I publicly took a stand with many other peers to warn the public of the dangers related…},
	date = {2024-07-09},
	journaltitle = {Yoshua Bengio},
	langid = {canadian},
	timestamp = {2025-04-21 13:32:09 (GMT)},
	title = {Reasoning through arguments against taking {AI} safety seriously},
	url = {https://yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-taking-ai-safety-seriously/},
	urldate = {2025-04-21}
}

@online{Bloomfield2023InformationSecurityIn,
	file = {~/My Drive/library-html/Bloomfield2023InformationSecurityIn.html;~/My Drive/library-pdf/Bloomfield2023InformationSecurityIn.pdf},
	abstract = {Organisations with influence, financial power, and advanced technology are targeted by actors seeking to steal or abuse these assets. A career in information security is a promising avenue to support high-impact organisations by protecting against these attacks, which have the potential to disrupt an organisation's mission or even increase existential risk.},
	author = {Bloomfield, Jarrah},
	date = {2023-06},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:57 (GMT)},
	title = {Information security in high-impact areas career review},
	url = {https://80000hours.org/career-reviews/information-security/},
	urldate = {2025-04-21}
}

@online{Bostrom2003TranshumanistFaq,
	file = {~/My Drive/library-pdf/Bostrom2003TranshumanistFaq.pdf;~/My Drive/library-html/Bostrom2003TranshumanistFaq.html},
	author = {Bostrom, Nick},
	date = {2003},
	journaltitle = {Nick Bostrom's website},
	langid = {english},
	title = {The Transhumanist {FAQ}},
	url = {https://nickbostrom.com/views/transhumanist.pdf},
	urldate = {2025-04-21}
}

@online{Buhler2023GrabbyValuesSelection,
	file = {~/My Drive/library-pdf/Buhler2023GrabbyValuesSelection.pdf;~/My Drive/library-html/Buhler2023GrabbyValuesSelection.html},
	langid = {english},
	abstract = {(This post also has a Russian version, translated from the present original by K. Kirdan.)  …},
	author = {Buhler, Jim},
	date = {2023-05-06},
	journaltitle = {Effective Altruism Forum},
	keywords = {Forecasting, Grabby aliens, Cultural evolution, Extraterrestrial intelligence, Instrumental convergence thesis, Long-term future, Space colonization, Trajectory change, Value drift, Value erosion, Value lock-in},
	shorttitle = {The Grabby Values Selection Thesis},
	timestamp = {2025-04-21 13:24:01 (GMT)},
	title = {The Grabby Values Selection Thesis: What values do space-faring civilizations plausibly have?},
	url = {https://forum.effectivealtruism.org/posts/xdKnfQKLyYQfeErSrwmqLbtMMraAv5Gyqn},
	urldate = {2025-04-21}
}

@online{Buhler2023PredictingWhatFuture,
	file = {~/My Drive/library-pdf/Buhler2023PredictingWhatFuture.pdf;~/My Drive/library-html/Buhler2023PredictingWhatFuture.html},
	langid = {english},
	abstract = {(This post also has a Russian version, translated from the present original by K. Kirdan.) …},
	author = {Buhler, Jim},
	date = {2023-03-24},
	journaltitle = {Effective Altruism Forum},
	keywords = {Forecasting, Philosophy, Cultural evolution, Global priorities research, Long-term future, Moral psychology, Research agendas, questions, and project lists, Value drift, Value lock-in},
	shorttitle = {Predicting what future people value},
	timestamp = {2025-04-21 13:23:57 (GMT)},
	title = {Predicting what future people value: A terse introduction to Axiological Futurism},
	url = {https://forum.effectivealtruism.org/posts/FCkchmXcSCQtJ9PZAwmqLbtMMraAv5Gyqn},
	urldate = {2025-04-21}
}

@online{Buhler2023WhatMoralTruth,
	file = {~/My Drive/library-html/Buhler2023WhatMoralTruth.html;~/My Drive/library-pdf/Buhler2023WhatMoralTruth.pdf},
	langid = {english},
	abstract = {(This post also has a Russian version, translated from the present original by K. Kirdan.) …},
	author = {Buhler, Jim},
	date = {2023-04-09},
	journaltitle = {Effective Altruism Forum},
	keywords = {Forecasting, Philosophy, Cultural evolution, Long reflection, Long-term future, Metaethics, Value drift},
	timestamp = {2025-04-21 13:23:59 (GMT)},
	title = {What the Moral Truth might be makes no difference to what will happen},
	url = {https://forum.effectivealtruism.org/posts/hat6TafzAoDx97N6jwmqLbtMMraAv5Gyqn},
	urldate = {2025-04-21}
}

@online{Buhler2023WhatValuesWill,
	file = {~/My Drive/library-pdf/Buhler2023WhatValuesWill.pdf;~/My Drive/library-html/Buhler2023WhatValuesWill.html},
	langid = {english},
	abstract = {(This post also has a Russian version, translated from the present original by K. Kirdan.) …},
	author = {Buhler, Jim},
	date = {2023-07-18},
	journaltitle = {Effective Altruism Forum},
	keywords = {Cause prioritization, Forecasting, Cultural evolution, Extraterrestrial intelligence, Global priorities research, Grabby aliens, Long-range forecasting, Long-term future, Moral psychology, Research agendas, questions, and project lists, Value drift, Value lock-in},
	shorttitle = {What values will control the Future?},
	timestamp = {2025-04-21 13:23:55 (GMT)},
	title = {What values will control the Future? Overview, conclusion, and directions for future work},
	url = {https://forum.effectivealtruism.org/posts/C8CPrTe2QqdtGxLtzwmqLbtMMraAv5Gyqn},
	urldate = {2025-04-21}
}

@online{Buhler2023WhyWeMay,
	file = {~/My Drive/library-html/Buhler2023WhyWeMay.html;~/My Drive/library-pdf/Buhler2023WhyWeMay.pdf},
	langid = {english},
	abstract = {(Probably the most important post of this sequence.) • (This post also has a Russian version, translated from the present original by K. Kirdan.) …},
	author = {Buhler, Jim},
	date = {2023-07-10},
	journaltitle = {Effective Altruism Forum},
	keywords = {Cause prioritization, Existential risk, Forecasting, Cultural evolution, Extraterrestrial intelligence, Grabby aliens, Instrumental convergence thesis, Long-term future, Risks from malevolent actors, S-risk, Space colonization, Trajectory change, Value drift, Value erosion},
	timestamp = {2025-04-21 13:23:54 (GMT)},
	title = {Why we may expect our successors not to care about suffering},
	url = {https://forum.effectivealtruism.org/posts/bTPP7fZxSvBzsNDESwmqLbtMMraAv5Gyqn},
	urldate = {2025-04-21}
}

@online{CFAR2017RationalityChecklist,
	file = {~/My Drive/library-pdf/CFAR2017RationalityChecklist.pdf;~/My Drive/library-html/CFAR2017RationalityChecklist.html},
	date = {2017},
	abstract = {Developing clear thinking for the sake of humanity’s future},
	author = {{Center for Applied Rationality}},
	journaltitle = {Center for Applied Rationality},
	langid = {american},
	timestamp = {2025-04-21 13:09:07 (GMT)},
	title = {Rationality Checklist},
	url = {http://www.rationality.org/resources/rationality-checklist},
	urldate = {2025-04-21}
}

@Article{Clymer2024SafetyCasesHow,
	file = {~/My Drive/library-pdf/Clymer2024SafetyCasesHow.pdf},
	langid = {english},
	abstract = {As {AI} systems become more advanced, companies and regulators will make difficult decisions about whether it is safe to train and deploy them. To prepare for these decisions, we investigate how developers could make a 'safety case,' which is a structured rationale that {AI} systems are unlikely to cause a catastrophe. We propose a framework for organizing a safety case and discuss four categories of arguments to justify safety: total inability to cause a catastrophe, sufficiently strong control measures, trustworthiness despite capability to cause harm, and -- if {AI} systems become much more powerful -- deference to credible {AI} advisors. We evaluate concrete examples of arguments in each category and outline how arguments could be combined to justify that {AI} systems are safe to deploy.},
	author = {Clymer, Joshua and Gabrieli, Nick and Krueger, David and Larsen, Thomas},
	date = {2024-03-18},
	doi = {10.48550/arXiv.2403.10462},
	eprint = {2403.10462 [cs]},
	eprinttype = {arxiv},
	keywords = {Computer Science - Computers and Society, Computer Science - Artificial Intelligence},
	publisher = {{arXiv}},
	shorttitle = {Safety Cases},
	timestamp = {2025-04-21 13:21:22 (GMT)},
	title = {Safety Cases: How to Justify the Safety of Advanced {AI} Systems},
	url = {http://arxiv.org/abs/2403.10462},
	urldate = {2025-04-21}
}

@online{Crook2025HowDoAnimals,
	date = {2017},
	file = {~/My Drive/library-pdf/Crook2025HowDoAnimals.pdf;~/My Drive/library-html/Crook2025HowDoAnimals.html},
	abstract = {Humans know the surprising prick of a needle, the searing pain of a stubbed toe, and the throbbing of a toothache. We can identify many types of pain and have multiple ways of treating it — but what about other species? How do the animals all around us experience pain? Robyn J. Crook examines pain in both vertebrate and invertebrate animals.},
	author = {Crook, Robyn J.},
	journaltitle = {TED-Ed},
	langid = {english},
	shorttitle = {How do animals experience pain?},
	timestamp = {2025-04-21 13:23:08 (GMT)},
	title = {How do animals experience pain?},
	url = {https://ed.ted.com/lessons/how-do-animals-experience-pain-robyn-j-crook},
	urldate = {2025-04-21}
}

@online{Deaton2021CanRandomisedControlled,
	file = {~/My Drive/library-html/Deaton2021CanRandomisedControlled.html;~/My Drive/library-pdf/Deaton2021CanRandomisedControlled.pdf},
	abstract = {It’s difficult to test whether poverty relief actually works. Do randomised controlled trials provide a scientific measure?},
	author = {Deaton, Angus},
	date = {2021-01-13},
	journaltitle = {Aeon},
	langid = {english},
	shorttitle = {Can randomised controlled trials test whether poverty relief works?},
	timestamp = {2025-04-21 13:21:13 (GMT)},
	title = {Can randomised controlled trials test whether poverty relief works?},
	url = {https://aeon.co/essays/can-randomised-controlled-trials-test-whether-poverty-relief-works},
	urldate = {2025-04-21}
}

@online{Dello-Iacovo2016FromUtilitarianTo,
	file = {~/My Drive/library-pdf/Dello-Iacovo2016FromUtilitarianTo.pdf;~/My Drive/library-html/Dello-Iacovo2016FromUtilitarianTo.html},
	abstract = {I’ve made a video version of this article and have expanded on some of the points here. I’m a utilitarian through and through, so it might be a surprise to you to know that I called myself an abolitionist for about a month. But I’ve stopped, and I think my thought process is potentially quite … Continue reading From utilitarian to abolitionist and back in a month},
	author = {Dello-Iacovo, Michael},
	date = {2016-08-04},
	journaltitle = {Michael Dello-Iacovo},
	langid = {australian},
	timestamp = {2025-04-21 13:09:41 (GMT)},
	title = {From utilitarian to abolitionist and back in a month},
	url = {https://www.michaeldello.com/from-utilitarian-to-abolitionist-and-back-in-a-month/},
	urldate = {2025-04-21}
}

@online{Dello-Iacovo2018WhyDoVegans,
	file = {~/My Drive/library-html/Dello-Iacovo2018WhyDoVegans.html;~/My Drive/library-pdf/Dello-Iacovo2018WhyDoVegans.pdf},
	abstract = {Being a vegan, I meet many people who get on some level why I am vegan, but just don’t understand why vegans talk so much about non-human animals and how they are treated in farming. I have come up with a story which, I hope, will enable you to understand, even if you don’t agree. … Continue reading Why do vegans talk about veganism so much?},
	author = {Dello-Iacovo, Michael},
	date = {2018-08-10},
	journaltitle = {Michael Dello-Iacovo},
	langid = {australian},
	timestamp = {2025-04-21 13:09:43 (GMT)},
	title = {Why do vegans talk about veganism so much?},
	url = {https://www.michaeldello.com/vegans-talk-veganism-much/},
	urldate = {2025-04-21}
}

@online{EffektivSpenden2020KinderpatenschaftenMachtEs,
	abstract = {Viele Hilfsorganisationen werben mit Kinderpatenschaften. Ist das seriös und was steckt wirklich dahinter? Sollte man wirklich spenden?.},
	file = {~/My Drive/library-pdf/Spenden2020KinderpatenschaftenMachtEs.pdf;~/My Drive/library-html/EffektivSpenden2020KinderpatenschaftenMachtEs.html},
	author = {{Effektiv Spenden}},
	date = {2020-10-20},
	journaltitle = {Effektiv Spenden},
	langid = {german},
	timestamp = {2025-04-21 13:23:10 (GMT)},
	title = {Kinderpatenschaften: Macht es Sinn, hier zu spenden?},
	url = {https://effektiv-spenden.org/spenden-tipps/kinderpatenschaften-macht-es-sinn-hier-zu-spenden/},
	urldate = {2025-04-21}
}

@online{EffektivSpenden2020KritischeBetrachtungDer,
	abstract = {Medial präsente Naturkatastrophen prägen das Spendenverhalten, aber man könnte viel mehr Menschen helfen, wenn man an vernachlässigten Katastrophen spendet.},
	file = {~/My Drive/library-html/Spenden2020KritischeBetrachtungDer.html;~/My Drive/library-pdf/EffektivSpenden2020KritischeBetrachtungDer.pdf},
	author = {{Effektiv Spenden}},
	date = {2020-10-20},
	journaltitle = {Effektiv Spenden},
	langid = {german},
	timestamp = {2025-04-21 13:23:10 (GMT)},
	title = {Eine kritische Betrachtung der Katastrophenhilfe},
	url = {https://effektiv-spenden.org/spenden-tipps/eine-kritische-betrachtung-der-katastrophenhilfe/},
	urldate = {2025-04-21}
}

@online{EffektivSpenden2020WarumWirSpenden,
	file = {~/My Drive/library-html/EffektivSpenden2020WarumWirSpenden.html;~/My Drive/library-pdf/EffektivSpenden2020WarumWirSpenden.pdf},
	author = {{Effektiv Spenden}},
	date = {2020-10-20},
	journaltitle = {Effektiv Spenden},
	langid = {german},
	timestamp = {2025-04-21 13:23:11 (GMT)},
	title = {Warum wir Spenden für {CO2}-Kompensation kritisch sehen},
	url = {https://effektiv-spenden.org/spenden-tipps/warum-wir-spenden-fuer-co2-kompensation-kritisch-sehen/},
	urldate = {2025-04-21}
}

@online{FoundersPledge2020ClimateChangeReport,
	file = {~/My Drive/library-pdf/FoundersPledge2020ClimateChangeReport.pdf;~/My Drive/library-html/FoundersPledge2020ClimateChangeReport.html},
	author = {{Founders Pledge}},
	abstract = {Climate change constitutes one part of a triple challenge facing humanity, intertwined with air pollution from fossil fuel combustion and energy poverty affecting billions. Addressing this requires not only decarbonizing the global energy system but also ensuring access to sufficient clean energy for developing nations, where energy demand is projected to grow significantly. Replacing the existing fossil fuel infrastructure while potentially doubling energy supply by 2100 presents an immense technological and political task, especially given historically slow progress in increasing the share of low-carbon energy. An effective philanthropic strategy involves supporting advocacy for innovation in neglected low-carbon technologies. This approach leverages global impact by reducing technology costs, benefiting emerging economies without requiring complex international coordination. Focusing on underfunded yet critical solutions such as carbon capture, advanced nuclear power, and zero-carbon fuels for transport offers greater potential for impact compared to more established technologies like solar and wind, thereby addressing key bottlenecks in the transition to a sustainable energy future. – AI-generated abstract.},
	date = {2020-09},
	journaltitle = {Founders Pledge},
	langid = {english},
	timestamp = {2025-04-21 13:30:53 (GMT)},
	title = {Climate change report},
	url = {https://www.founderspledge.com/research/climate-change-executive-summary},
	urldate = {2025-04-21}
}

@online{Givewell2023HowMuchDoes,
	file = {~/My Drive/library-html/Givewell2023HowMuchDoes.html;~/My Drive/library-pdf/Givewell2023HowMuchDoes.pdf},
	abstract = {This page describes why estimated cost to save a life is higher than we might expect, even for inexpensive interventions.},
	author = {{GiveWell}},
	date = {2023-11},
	langid = {english},
	shorttitle = {How Much Does It Cost To Save a Life?},
	timestamp = {2025-04-21 13:30:54 (GMT)},
	title = {How Much Does It Cost To Save a Life?},
	url = {https://www.givewell.org/how-much-does-it-cost-to-save-a-life},
	urldate = {2025-04-21}
}

@online{Gloor2014EthicsAndObjectivity,
	abstract = {Plato's Eutyphro dilemma challenges the necessity of God for objective ethics, suggesting morality can be independent of divine will. Normative ethics, distinct from descriptive morality, concerns how one should act. This "should" can be interpreted broadly as aligning with one's reflective terminal goals, or narrowly as taking other-regarding reasons seriously. Establishing universally compelling arguments for specific ethical goals remains problematic, as any foundational premise can be rejected. The strong intuition of objective morality may stem from biological adaptations promoting social cooperation, a view termed moral anti-realism. This anti-realism, however, does not imply nihilism; actions can still be evaluated based on personal goals or specific ethical axioms like altruism, allowing for objective assessments within those chosen frameworks. Without mandated rules, navigating ethical landscapes requires rationality, reflection on values, and careful consideration of consequences, particularly given modern capabilities to affect sentient life on a large scale and into the far future. – AI-generated abstract.},
	author = {Gloor, Lukas},
	file = {~/My Drive/library-html/Gloor2014EthicsAndObjectivity.html;~/My Drive/library-pdf/Gloor2014EthicsAndObjectivity.pdf},
	date = {2014-11-11},
	journaltitle = {Crucial Considerations},
	langid = {american},
	title = {Ethics and objectivity},
	url = {https://crucialconsiderations.org/ethics/41/},
	urldate = {2025-04-21}
}

@online{Gloor2014WhatIsLife,
	file = {~/My Drive/library-html/Gloor2014WhatIsLife.html;~/My Drive/library-pdf/Gloor2014WhatIsLife.pdf},
	abstract = {For the sake of neatness we could arbitrarily stipulate specific criteria for what qualifies as “life”. We could then draw a sharp line between life and non-life, but we would not there…},
	author = {Gloor, Lukas},
	date = {2014-11-12},
	journaltitle = {Crucial Considerations},
	langid = {american},
	timestamp = {2025-04-21 13:22:59 (GMT)},
	title = {What Is Life?},
	url = {https://crucialconsiderations.org/philosophy/what-is-life/},
	urldate = {2025-04-21}
}

@online{Gloor2015MeansAndEnds,
	file = {~/My Drive/library-pdf/Gloor2015MeansAndEnds.pdf;~/My Drive/library-html/Gloor2015MeansAndEnds.html},
	author = {Gloor, Lukas},
	abstract = {It’s possible to be mistaken about one’s own values. A common instance of it is when we think we care about something, while in fact what we truly (i.e. under reflection) care about is something el…},
	date = {2015-04-16},
	journaltitle = {Crucial Considerations},
	langid = {american},
	timestamp = {2025-04-21 13:22:57 (GMT)},
	title = {Means and Ends},
	url = {https://crucialconsiderations.org/ethics/means-and-ends/},
	urldate = {2025-04-21}
}

@online{Gooen2017FramingEffectiveAltruism,
	abstract = {There seems to be a widespread and misconceived belief that the biggest problems in the world are caused by hatred. However, if we miraculously got rid of all the hatred in the world tomorrow, the worst problems would remain. [1]All the major causes of suffering in the world seem to be the result of the absence of caring (i.e. indifference), rather than the presence of hatred: 1. Extreme poverty is not the result of the rich hating the poor; its continued existence is the result of the rich being largely indifferent towards the suffering associated with extreme poverty.2. Factory farming is not the result of human hatred towards non-human animals; it is the result of human indifference towards the intense suffering of animals living in intense confinement.3. Humanity's collective under-investment in the prevention of existential risks, which endanger the existence and flourishing of our future descendants, is not the result of the present generation hating future generations; it is the result of the present generation being largely indifferent towards the well-being of potential future lives, of which there could be an astronomical number. 4. The widespread and intense suffering of animals living in the wild is not the result of hatred; it is the result of a blind and indifferent optimization process (i.e. evolution through natural selection).Indifference is the immediate result of our evolved human cognitive architecture that is largely insensitive to the scope of moral problems and to the well-being of those different from ourselves, as demonstrated by the work of Paul Slovic.The problem of indifference is not solvable merely by increasing emotions such as love or empathy, despite their importance in our everyday lives. These emotions are too narrow and parochial to reliably extend to all beings that deserve our moral concern. In Joshua Greene's words, our "emotions make us social animals, turning Me into Us. But they also make us tribal animals, turning Us against Them". Heightened empathy and love are important drivers for in-group altruism, but by themselves they are not sufficient to overcome our collective indifference—especially, because they may in some cases actually increase bias and hostility towards the out-group. In the same vein, Paul Bloom points out that "I actually feel a lot less empathy for people who aren’t in my culture, who don’t share my skin color, who don’t share my language. This is a terrible fact of human nature, and it operates at a subconscious level, but we know that it happens. (...) empathy often leads us to make stupid and unethical decisions. (...) when it comes to moral reasoning, empathy (...) just throws in bias and innumeracy and confusion."The fact that to a human brain ten deaths feel only marginally less bad than one thousand deaths is merely a fact about our state of mind, not about the world itself. The badness of the suffering of others is not in the least alleviated by the fact that we are largely indifferent towards it, whether by our choice or by our.},
	file = {~/My Drive/library-html/Gooen2017FramingEffectiveAltruism.html;~/My Drive/library-pdf/Gooen2017FramingEffectiveAltruism.pdf},
	author = {Gooen, Ozzie},
	date = {2017-08-17},
	journaltitle = {Effective Altruism Forum},
	langid = {english},
	title = {Framing Effective Altruism as Overcoming Indifference},
	url = {https://forum.effectivealtruism.org/posts/9gJAmSx73xYWi9QgS/framing-effective-altruism-as-overcoming-indifference},
	urldate = {2025-04-21}
}

@online{Grace2023MovingTooFast,
	file = {~/My Drive/library-html/Grace2023MovingTooFast.html;~/My Drive/library-pdf/Grace2023MovingTooFast.pdf},
	abstract = {We shouldn’t let people throw the world away in a perverse race to destruction, writes {AI} researcher Katja Grace},
	author = {Grace, Katja},
	date = {2023-05-31},
	journaltitle = {{TIME}},
	langid = {english},
	timestamp = {2025-04-21 13:26:18 (GMT)},
	title = {Moving Too Fast on {AI} Could Be Terrible for Humanity},
	url = {https://time.com/6283609/artificial-intelligence-race-existential-threat/},
	urldate = {2025-04-21}
}

@online{Grunewald2023ExpertInAi,
	file = {~/My Drive/library-html/Grunewald2023ExpertInAi.html;~/My Drive/library-pdf/Grunewald2023ExpertInAi.pdf},
	author = {Grunewald, Erich},
	abstract = {Reducing risks from AI is one of the most pressing problems in the world, and people with expertise in AI hardware and related topics are expected to be in particularly high demand in policy and research in this area. For the right person, gaining and applying AI hardware skills to risk-reducing AI governance work could be their most impactful option. However, becoming an expert in this field is not easy and will not be a good fit for most people, and it may be challenging to chart a clear path through the complex and evolving world of AI governance agendas.},
	date = {2023-11},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:56 (GMT)},
	title = {Expert in {AI} hardware - Career review},
	url = {https://80000hours.org/career-reviews/become-an-expert-in-ai-hardware/},
	urldate = {2025-04-21}
}

@online{HappierLivesInstitute2024KeyIdeas,
	date = {2024},
	file = {~/My Drive/library-pdf/HappierLivesInstitute2024KeyIdeas.pdf;~/My Drive/library-html/HappierLivesInstitute2024KeyIdeas.html},
	author = {{Happier Lives Institute}},
	journaltitle = {Happier Lives Institute},
	langid = {english},
	timestamp = {2025-04-21 13:30:58 (GMT)},
	title = {Key Ideas},
	url = {https://www.happierlivesinstitute.org/key-ideas/},
	urldate = {2025-04-21}
}

@online{Hashim2023EaWins2023,
	file = {~/My Drive/library-html/Hashim2023EaWins2023.html;~/My Drive/library-pdf/Hashim2023EaWins2023.pdf},
	langid = {english},
	abstract = {Crossposted from Twitter.As the year comes to an end, we want to highlight and celebrate some of the incredible achievements from in and around the effective altruism ecosystem this year. 1. A new malaria {vaccineThe} World Health Organization recommended its second-ever malaria vaccine this year: R21/Matrix-M, designed to protect babies and young children from malaria. The drug’s recently concluded Phase {III} trial, which was co-funded by Open Philanthropy, found that the vaccine was between 68-75\% effective at targeting the disease, which kills around 600,000 people (mainly children) each year.The work didn’t stop there, though. Following advocacy from many people — including Zacharia Kafuko of 1 Day Sooner — the {WHO} quickly prequalified the vaccine, laying the groundwork for an expedited deployment and potentially saving hundreds of thousands of children’s lives. 1 Day Sooner is now working to raise money to expedite the deployment further. 2. The Supreme Court upholds an animal welfare {lawIn} 2018, Californians voted for Proposition 12 — a bill that banned intensive cage confinement and the sale of animal products from animals in intensive confinement. The meat industry challenged the law for being unconstitutional — but in May of this year, the {US} Supreme Court upheld Prop 12, a decision that will improve the lives of millions of animals who would otherwise be kept in cruel and inhumane conditions.Organizations such as The Humane League — one of Animal Charity Evaluators’ top charities — are a major part of this victory; their tireless campaigning is part of what made Prop 12 happen.Watch a panel discussion featuring The Humane League at {EAG} London 2023 here. 3. {AI} safety goes mainstream2023 was the year {AI} safety went mainstream. After years of work from people in and around effective altruism, this year saw hundreds of high-profile {AI} experts — including two Turing Award winners — say that “mitigating the risk of extinction from {AI} should be a global priority”.That was followed by a flurry of activity from policymakers, including a {US} Executive Order, an international {AI} Safety Summit, the establishment of the {UK} Frontier {AI} Taskforce, and a deal on the {EU} {AI} Act — which, thanks to the efforts of campaigners, is now going to regulate foundation models that pose a systemic risk to society.Important progress was made in technical {AI} safety, too, including work on adversarial robustness, mechanistic interpretability, and lie detection.Watch a talk from {EAG} Boston 2023 on technical {AI} safety here. 4. Results from the world’s largest {UBI} {studySince} 2018, {GiveDirectly} — an organization that distributes direct cash transfers to those in need — has been running the world’s largest universal basic income experiment in rural Kenya.In September, researchers led by {MIT} economist Taveneet Suri and Nobel laureate Abhijit Banerjee, published their latest analysis of the data — finding that giving people money as a lump sum leads to better results than dispersing it via monthly payments. Long-term {UBI} was also found to be highly effective and didn’t discourage work. The results could have significant implications for how governments disburse cash aid.Watch {GiveDirectly}’s talk at {EAGx} Nordics 2023. 5. Cultivated meat approved for sale in {USAfter} years of work from},
	author = {Hashim, Shakeel},
	date = {2023-12-31},
	journaltitle = {Effective Altruism Forum},
	keywords = {{AI} safety, Animal welfare, Biosecurity, Existential risk, Global health \& development, Good things \& impact stories, News relevant to effective altruism},
	timestamp = {2025-04-21 13:23:21 (GMT)},
	title = {{EA} Wins 2023},
	url = {https://forum.effectivealtruism.org/posts/8P2GZFLnv8HW9ozLB},
	urldate = {2025-04-21}
}

@online{Herran2021EmptyOpenAnd,
	file = {~/My Drive/library-html/Herran2021EmptyOpenAnd.html;~/My Drive/library-pdf/Herran2021EmptyOpenAnd.pdf},
	author = {Herrán, Manu},
	abstract = {Closed Individualism posits a continuous self persisting through time, aligning with subjective experience but facing challenges, such as Heinlein's pain-memory anesthesia thought experiment. Empty Individualism proposes that we are a different person at each moment, comprising discrete "I's," which helps explain phenomena like alienation from past selves and internal psychological conflicts. Open Individualism, or the Hypothesis of the Unique Subjectivity, suggests a single, universal subjective entity underlies all individual experiences, with each perceived self experiencing only a fragment. This view, like Empty Individualism, provides a rationale for altruism based on an expanded concept of self-interest, where aiding other sentient beings is akin to aiding future or constituent parts of oneself. The potential for using computer simulations to model and evolutionarily assess these competing metaphysical frameworks is suggested as a method for evaluating their likelihood and understanding their implications, particularly for psychology and the long-term ethical goal of reducing or eliminating suffering across all sentient beings. – AI-generated abstract.},
	date = {2021-09-13},
	langid = {american},
	timestamp = {2025-04-21 13:24:25 (GMT)},
	title = {Empty, Open and Closed Individualism},
	url = {https://manuherran.com/empty-open-and-closed-individualism/},
	urldate = {2025-04-21}
}

@online{Herran2021StuffThatRepels,
	file = {~/My Drive/library-pdf/Herran2021StuffThatRepels.pdf;~/My Drive/library-html/Herran2021StuffThatRepels.html},
	author = {Herrán, Manu},
	abstract = {Certain phenomena do not merely go unnoticed but actively repel human attention, differing from passively unnoticed things in that the mind actively works to dismiss or ignore them, often inventing rationalizations. This attention repulsion prevents engagement even when direct focus is attempted. Examples include uncomfortable truths about the self, such as one's own future death, selfishness, stupidity, and the motivations behind actions, particularly those yielding short-term satisfaction at the expense of long-term consequences for oneself or others. It also encompasses difficult ethical considerations like the interests of exploited beings (e.g., non-human animals), the vast scale of suffering in nature unrelated to human activity, remote or future suffering, and the potential validity of arguments challenging one's deeply held beliefs or moral stances, especially those requiring behavioral changes perceived as difficult or impossible. Other examples include the risk of extreme pain, the act of consciously measuring satisfaction (which paradoxically decreases it), formless phenomena, and the recognition of therapeutic obsessions. This active avoidance mechanism hinders the acknowledgment and addressing of significant personal, ethical, and existential issues. – AI-generated abstract.},
	date = {2021-09-13},
	langid = {american},
	timestamp = {2025-04-21 13:24:26 (GMT)},
	title = {Stuff that repels the attention},
	url = {https://manuherran.com/stuff-that-repels-the-attention/},
	urldate = {2025-04-21}
}

@online{Herran2021WhatCanDo,
	file = {~/My Drive/library-pdf/Herran2021WhatCanDo.pdf;~/My Drive/library-html/Herran2021WhatCanDo.html},
	author = {Herrán, Manu},
	date = {2021-09-13},
	langid = {american},
	shorttitle = {What can I do to prevent intense suffering?},
	timestamp = {2025-04-21 13:24:27 (GMT)},
	title = {What can I do to prevent intense suffering?},
	url = {https://manuherran.com/what-can-i-do-to-prevent-intense-suffering/},
	urldate = {2025-04-21}
}

@online{Herran2021WhatCanDob,
	file = {~/My Drive/library-html/Herran2021WhatCanDob.html;~/My Drive/library-pdf/Herran2021WhatCanDob.pdf},
	author = {Herrán, Manu},
	date = {2021-09-13},
	langid = {american},
	shorttitle = {What can I do to prevent my own intense suffering?},
	timestamp = {2025-04-21 13:24:28 (GMT)},
	title = {What can I do to prevent my own intense suffering?},
	url = {https://manuherran.com/what-can-i-do-to-prevent-my-own-intense-suffering/},
	urldate = {2025-04-21}
}

@online{Herran2021WhyToFocus,
	file = {~/My Drive/library-html/Herran2021WhyToFocus.html;~/My Drive/library-pdf/Herran2021WhyToFocus.pdf},
	author = {Herrán, Manu},
	date = {2021-09-13},
	langid = {american},
	shorttitle = {Why to focus on reducing intense suffering?},
	timestamp = {2025-04-21 13:24:29 (GMT)},
	title = {Why to focus on reducing intense suffering? – Manu Herrán},
	url = {https://manuherran.com/why-to-focus-on-reducing-intense-suffering/},
	urldate = {2025-04-21}
}

@online{Herran2022ChickenAndPigs,
	file = {~/My Drive/library-html/Herran2022ChickenAndPigs.html;~/My Drive/library-pdf/Herran2022ChickenAndPigs.pdf},
	author = {Herrán, Manu},
	abstract = {The work does not contain an abstract.

Numerous incidents document the severe suffering of farmed chickens and pigs in Europe and the United States, specifically involving burning and boiling alive. Reports indicate that hundreds of thousands of chickens and turkeys are boiled alive annually in US slaughterhouses, often resulting from high-speed processing lines failing to stun or kill the birds before scalding tanks; regulatory bodies have considered further increases to these line speeds. Significant numbers of birds, sometimes tens or hundreds of thousands at a time, have also perished in farm fires across Europe, with poor manure management cited as a contributing factor in at least one instance. Additionally, specific events highlight pigs being boiled or burned alive, including incidents linked to disease control measures during the coronavirus crisis. Similar practices, such as the boiling of male ducklings deemed commercially useless, have been reported in other regions like China, alongside incidents of pigs being boiled alive in Australian slaughterhouses. These occurrences underscore significant animal welfare issues within current agricultural and slaughter practices. – AI-generated abstract.},
	date = {2022-03-29},
	langid = {american},
	timestamp = {2025-04-21 13:24:24 (GMT)},
	title = {Chicken and pigs burned and boiled alive in Europe and {USA} – Manu Herrán},
	url = {https://manuherran.com/chicken-and-pigs-burned-and-boiled-alive-in-europe-and-usa/},
	urldate = {2025-04-21}
}

@online{Hilton2023AnonymousAdviceIf,
	file = {~/My Drive/library-pdf/Hilton2023AnonymousAdviceIf.pdf;~/My Drive/library-html/Hilton2023AnonymousAdviceIf.html},
	abstract = {We put this question to the few {AI} experts we thought most qualified to answer it - and they don't all agree. Here's what they had to say.},
	author = {Hilton, Benjamin},
	date = {2023-11},
	journaltitle = {80,000 Hours},
	langid = {american},
	shorttitle = {Anonymous advice},
	timestamp = {2025-04-21 13:20:09 (GMT)},
	title = {Anonymous advice: If you want to reduce {AI} risk, should you take roles that advance {AI} capabilities?},
	url = {https://80000hours.org/articles/ai-capabilities/},
	urldate = {2025-04-21}
}

@online{Hilton2023HowToBecome,
	file = {~/My Drive/library-html/Hilton2023HowToBecome.html;~/My Drive/library-pdf/Hilton2023HowToBecome.pdf},
	abstract = {Learn how you can use engineering skills to solve pressing global problems.},
	author = {Hilton, Benjamin},
	date = {2023-12},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:06 (GMT)},
	title = {How to become an engineer},
	url = {https://80000hours.org/skills/engineering/},
	urldate = {2025-04-21}
}

@online{Hilton2023HowToBecomeb,
	file = {~/My Drive/library-html/Hilton2023HowToBecomeb.html;~/My Drive/library-pdf/Hilton2023HowToBecomeb.pdf},
	abstract = {Learn how to do research, and how you can use research skills to do good.},
	author = {Hilton, Benjamin},
	date = {2023-09},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:08 (GMT)},
	title = {How to become a researcher},
	url = {https://80000hours.org/skills/research/},
	urldate = {2025-04-21}
}

@online{Hilton2023PolicyAndPolitical,
	file = {~/My Drive/library-html/Hilton2023PolicyAndPolitical.html;~/My Drive/library-pdf/Hilton2023PolicyAndPolitical.pdf},
	author = {Hilton, Benjamin and Todd, Benjamin},
	abstract = {Working in policy can be a rewarding and high-impact way of changing the world for the better. Learn how to get started.},
	date = {2023-09},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:07 (GMT)},
	title = {Policy and political skills},
	url = {https://80000hours.org/skills/political-bureaucratic/},
	urldate = {2025-04-21}
}

@online{Hilton2023SpecialistKnowledgeRelevant,
	file = {~/My Drive/library-html/Hilton2023SpecialistKnowledgeRelevant.html;~/My Drive/library-pdf/Hilton2023SpecialistKnowledgeRelevant.pdf},
	abstract = {Which areas of specialist knowledge are most applicable to solving the world's most pressing problems?},
	author = {Hilton, Benjamin},
	date = {2023-09},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:09 (GMT)},
	title = {Specialist knowledge relevant to a top problem},
	url = {https://80000hours.org/skills/specialist-knowledge/},
	urldate = {2025-04-21}
}

@online{Hilton2024FactoryFarming,
	abstract = {History is littered with moral mistakes — things that once were common, but we now consider clearly morally wrong, for example: human sacrifice, gladiatorial combat, public executions, witch hunts, and slavery. In my opinion, there’s one clear candidate for the biggest moral mistake that humanity is currently making: factory farming. The rough argument is: There are trillions of farmed animals, making the scale of the potential problem so large that it’s hard to intuitively grasp. The vast majority (we estimate 97.5\%) of farmed animals are in factory farms. The conditions in these farms are far worse than most people realise. Even if nonhuman animals don’t morally matter as much as humans, there’s good evidence that they are conscious and that they feel pain — and, as a result, the poor conditions in factory farms are likely causing animals to experience severe suffering. What’s more, we think that this problem is highly neglected and that there are clear ways to make progress — which makes factory farming a highly pressing problem overall.},
	file = {~/My Drive/library-pdf/Hilton2024FactoryFarming.pdf},
	title = {Factory farming},
	author = {Hilton, Benjamin},
	date = {2024-07},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:03 (GMT)},
	url = {https://80000hours.org/problem-profiles/factory-farming/},
	urldate = {2025-04-21}
}

@online{Hutchinson2018KeepingAbsolutesIn,
	file = {~/My Drive/library-pdf/Hutchinson2018KeepingAbsolutesIn.pdf;~/My Drive/library-html/Hutchinson2018KeepingAbsolutesIn.html},
	langid = {english},
	abstract = {As effective altruists, we often focus on the relative value of the different ways we could be helping others. We focus on particular charities being more effective than others, or particular jobs being more impactful than others. That makes a lot of sense: there are big differences in effectiveness between interventions, so satisficing could lead to us losing a lot of value. But at the end of the day what really matters isn’t relative: it’s the absolute value our actions bring about. What matters is the number of children who are actually dewormed and the actual increases in global security caused by improvements made to technology policy. Keeping that in mind can be important for keeping ourselves motivated and appreciating the work others are putting in.  It might appear that focusing on relative value is unproblematic, even if it isn’t what ultimately matters. But doing so neglects one of the most exciting things about effective altruism: the fact that each of us can actually have a remarkable amount of impact in improving the lives of others. Thinking only about the comparative impact of actions can lead us to overlook that fact. Say I apply for the job I think will have the highest impact but fail to get it. Later, I dwell on how much less impactful my current job is than the one I first went for, instead of on the impact I’m actually having. Or maybe I work on trying to decrease pandemic risk. While I succeed in reducing pandemic risk, the reduction feels tiny compared to the massive reduction in risk the President could effect. In both cases, I’m likely to feel demotivated about my job. Similarly, were it other people in these roles, my attention being on the comparisons might prevent me from properly appreciating the work they’re doing. Focusing on relative value might also lead us to neglect possible costs. When buying houses, people tend to switch into a mode where saving an extra £100 seems less important than it would under ordinary circumstances. Similarly, in large organisations (such as universities) where the costs of activities are high, there may be an assumption that additional overhead costs are unimportant as long as they’re small relative to core activities. Yet in absolute terms, these costs may be thousands of pounds.In cases like those above, it might help to think more about the absolute benefit our actions produce. That might mean simply trying to make the value more salient by thinking about it. The 10\% of my income that I donate is far less than that of some of my friends. But thinking through the fact that over my life I’ll be able to do the equivalent of save more than one person from dying of malaria is still absolutely incredible to me. Calculating the effects in more detail can be even more powerful – in this case thinking through specifically how many lives saved equivalent my career donations might amount to. Similarly,},
	author = {Hutchinson, Michelle},
	date = {2018-10-21},
	journaltitle = {Effective Altruism Forum},
	keywords = {Community, Motivational, Self-care and wellbeing in the effective altruism community, Altruistic motivation, Effective altruism lifestyle},
	timestamp = {2025-04-21 13:23:51 (GMT)},
	title = {Keeping Absolutes in Mind},
	url = {https://forum.effectivealtruism.org/posts/znFAeeKk566bCNMNE/keeping-absolutes-in-mind},
	urldate = {2025-04-21}
}

@online{Knutsson2016HowGoodOr,
	file = {~/My Drive/library-html/Knutsson2016HowGoodOr.html;~/My Drive/library-pdf/Knutsson2016HowGoodOr.pdf},
	author = {Knutsson, Simon},
	abstract = {Insect quality of life varies enormously, with many individuals experiencing short lifespans marked by significant suffering, particularly during death. Focusing on well-studied honey bees and numerous groups like springtails, ants, termites, mayflies, and midges reveals this disparity. Many insects die as larvae, pupae, or newly emerged adults, often through painful means like predation. Their brief existence offers limited opportunity for positive experiences to compensate for suffering. Honey bee workers live only 15-38 days as adults in summer, while adult mayflies and some midges live merely days without feeding. While social insects like honey bees, ants, and termites benefit from colony protection, potentially leading to better developmental conditions and longer lives compared to solitary insects, individual fates still differ greatly (e.g., worker bees vs. queens). Ants, in particular, may have longer lifespans. Longer life reduces death frequency per unit time for a population, which might be positive overall, but does not inherently ensure a better life for an individual, which still faces risks and potential suffering. Assessing welfare involves considering factors like feeding, mating, injury, starvation, and environmental hardship. – AI-generated abstract.},
	date = {2016-08-26},
	journaltitle = {Simon Knutsson},
	langid = {american},
	title = {How Good or Bad Is the Life of an Insect?},
	url = {https://www.simonknutsson.com/how-good-or-bad-is-the-life-of-an-insect},
	urldate = {2025-04-21}
}

@Book{Mill1874ThreeEssaysReligion,
	file = {~/My Drive/library-pdf/Mill1874ThreeEssaysReligion.pdf},
	address = {London},
	publisher = {Longmans, Green, Reader, and Dyer},
	date = {1874},
	title = {Three Essays on Religion: Nature, The Utility of Religion and Theism},
	author = {Mill, John Stuart},
	timestamp = {2025-04-22 16:09:35 (GMT)}
}

@online{Moorhouse2021FrequentlyAskedQuestions,
	file = {~/My Drive/library-html/Moorhouse2021FrequentlyAskedQuestions.html;~/My Drive/library-pdf/Moorhouse2021FrequentlyAskedQuestions.pdf},
	date = {2021},
	author = {Moorhouse, Fin},
	journaltitle = {Longtermism.com},
	langid = {english},
	title = {Frequently Asked Questions},
	url = {https://longtermism.com/faq},
	urldate = {2025-04-21}
}

@online{Moors2022AquacultureDoesnT,
	file = {~/My Drive/library-html/Moors2022AquacultureDoesnT.html;~/My Drive/library-pdf/Moors2022AquacultureDoesnT.pdf},
	abstract = {This report quantifies "blue loss": the number of fish caught each year but not accounted for in the human food chain. It estimates that number to be about 1.2 trillion fishes annually.},
	author = {Moors, Thyl},
	date = {2022-02-11},
	journaltitle = {Faunalytics},
	langid = {american},
	timestamp = {2025-04-21 13:23:15 (GMT)},
	title = {Aquaculture Doesn’t Solve 'Overfishing' — It Relies On It},
	url = {https://faunalytics.org/aquaculture-doesnt-solve-overfishing-it-relies-on-it/},
	urldate = {2025-04-21}
}

@online{Moors2022ClimateOpportunityCost,
	file = {~/My Drive/library-pdf/Moors2022ClimateOpportunityCost.pdf;~/My Drive/library-html/Moors2022ClimateOpportunityCost.html},
	abstract = {Ending land animal farming would not only reduce greenhouse gas emissions. It would also free up land, which would have enormous benefits in the fight against climate change.},
	author = {Moors, Thyl},
	date = {2022-05-13},
	journaltitle = {Faunalytics},
	langid = {american},
	timestamp = {2025-04-21 13:23:15 (GMT)},
	title = {The ‘Climate Opportunity Cost’ Of Animal Agriculture},
	url = {https://faunalytics.org/the-climate-opportunity-cost-of-animal-agriculture/},
	urldate = {2025-04-21}
}

@online{Parra2024QuantifyingGlobalBurden,
	file = {~/My Drive/library-html/Parra2024QuantifyingGlobalBurden.html;~/My Drive/library-pdf/Parra2024QuantifyingGlobalBurden.pdf},
	abstract = {Warning: This post discusses statistics about extreme pain that may be distressing. While cluster headaches are a neglected, high-impact issue, understanding their true burden requires appreciating the intensity of suffering involved. The pain often reaches levels far beyond typical human experience, making subjective accounts a valuable datapoint until we have robust methods for quantifying pain intensity. For further context, links to firsthand accounts are provided in the footnote[1].You no longer have a headache, or pain located at a particular site: you are literally plunged into the pain, like in a swimming pool. There is only one thing that remains of you: your agitated lucidity and the pain that invades everything, takes everything. There is nothing but pain. At that point, you would give everything, including your head, your own life, to make it stop.- Yves, cluster headache patient from France (from Rossi et al., 2018)Key {takeawaysCluster} headaches are often considered among the most painful conditions known to medicine, if not the most painful (Nesbitt \& Goadsby, 2012). Patients describe the pain as “devilish”, “grueling”, “unbearable” or “so violent that it is utterly intolerable” (Torelli \& Manzoni, 2003), and rate it as significantly more painful than labor pain, gunshot wounds, or fractured bones, among others (Burish et al., 2021).Approximately 1 in 1,000 people worldwide will experience the excruciating pain of cluster headaches during their lifetime (Schindler \& Burish, 2022). In any given year, 1.5 million to 5.6 million (median: 3.0 million) adults are affected.We aggregated statistical data from a couple dozen papers on the prevalence, frequency, duration, and intensity of cluster headaches to estimate their global pain burden.We estimate that all cluster headache patients worldwide spend {\textasciitilde}74,200 person-years per year in pain at any intensity, of which {\textasciitilde}46,200 are spent at ≥7/10 pain and {\textasciitilde}13,600 at ≥9/10 pain—that’s nearly 5 million person-days of extreme suffering (≥9/10 pain) annually.Drawing from research on the heavy-tailed nature of pain intensity (Gómez-Emilsson \& Percy, 2023), our numerical simulations show one way in which a straightforward aggregationist calculation[2] means cluster headaches become a top global health priority. In particular, we compare the burden of cluster headaches with that of migraine, which is the 4th largest source of Years Lived with Disability ({YLD}) worldwide and 19th largest source of {DALY} ({GBD}, 2024).You can access the full simulations here: cluster-headaches.streamlit.{appThe} fact that the prevalence of cluster headaches is much lower than that of other major diseases is actually advantageous and presents an attractive opportunity: we can get rid of a significant proportion of the most extreme human suffering worldwide at a small fraction of the cost of addressing more prevalent conditions.Philanthropists, donors, charity and tech entrepreneurs, policymakers, and other decision-makers should consider cluster headache relief a strong contender for directing their altruistic efforts. This is particularly true for individuals who care about alleviating the most extreme forms of suffering, but the case can be compelling from nearly any ethical perspective.1. Introduction1.1. Clinical Features and Pain {ComparisonsCluster} headaches (sometimes also referred to as “suicide headaches”) are a disorder characterized by attacks of},
	author = {Parra, Alfredo},
	date = {2024-11-01},
	journaltitle = {Effective Altruism Forum},
	langid = {english},
	keywords = {Global health \& development, Cause prioritization, Effective giving, Pain and suffering, Cluster headache, Burden of disease, Cost-effectiveness analysis, Data science, Neglectedness, Psychedelics, Qualia Research Institute, Research, Suffering-focused ethics},
	timestamp = {2025-04-21 13:23:50 (GMT)},
	title = {Quantifying the Global Burden of Extreme Pain from Cluster Headaches},
	url = {https://forum.effectivealtruism.org/posts/geh2g2nKb7Kkp26ze#1_1__Clinical_Features_and_Pain_Comparisons},
	urldate = {2025-04-21}
}

@online{Pearce2008QuantumEthics,
	abstract = {The Abolitionist Project outlines how humans and transhumans may use biotechnology to abolish suffering in all sentient life. The last experience below hedonic zero in our forward light-cone may be a precisely dateable event a few centuries hence. Sadly, this utopian-sounding outcome may not be nearly as wonderful as it sounds. For if a "block-universe" conception of spacetime is true, then suffering occurring in what we naively call "the past" is as real and unalterable as what we call "the present". Moreover, post-Everett quantum mechanics suggests that Darwinian life abounds elsewhere in the Multiverse. In the vast majority of quasi-classical macroscopic branches in which sentient life arises, no hominin-like creatures will evolve capable of rewriting their own source code and abolishing pain, misery and malaise. So "future" suffering persists indefinitely too. Worse, if Linde's chaotic eternal inflation scenario should turn out to be true, then the amount of suffering in Reality is increasing exponentially. Its extirpation in any one pocket universe like our own would be a purely local phenomenon. The only crumb of comfort to be drawn from this analysis is that the scenarios sketched are all extremely speculative.},
	file = {~/My Drive/library-html/Pearce2008QuantumEthics.html;~/My Drive/library-pdf/Pearce2008QuantumEthics.pdf},
	date = {2008},
	author = {Pearce, David},
	journaltitle = {HedWeb},
	langid = {english},
	timestamp = {2025-04-21 13:31:00 (GMT)},
	title = {Quantum Ethics? Suffering in the Multiverse},
	url = {https://www.hedweb.com/population-ethics/quantum-ethics.html},
	urldate = {2025-04-21}
}

@online{Pearce2010TopFiveReasons,
	abstract = {Transhumanist approaches may enable the eventual abolition of involuntary suffering in sentient life. Key strategies include leveraging advancements in reproductive medicine and gene therapy, such as preimplantation genetic diagnosis and potential adult gene therapies targeting alleles like SCN9A, to allow individuals and future generations to select reduced pain sensitivity. Similarly, genetic selection for alleles associated with positive affect, like certain COMT variants, could enhance baseline well-being. Technological solutions like commercially viable in vitro meat production offer a path to eliminate the suffering associated with factory farming and slaughterhouses. Furthermore, the immense suffering prevalent in wild ecosystems could potentially be addressed through compassionate ecosystem redesign and technologies like pan-species contraception to phase out predation. Finally, the possibility of a near-future technological Singularity or "intelligence explosion," combined with progress in radical life extension, might dramatically accelerate the eradication of suffering across the biosphere. These combined approaches aim to eliminate all experiences below hedonic zero within several centuries. – AI-generated abstract.},
	date = {2010-10-21},
	file = {~/My Drive/library-html/Pearce2010TopFiveReasons.html;~/My Drive/library-pdf/Pearce2010TopFiveReasons.pdf},
	author = {Pearce, David},
	journaltitle = {HedWeb},
	langid = {english},
	timestamp = {2025-04-21 13:31:30 (GMT)},
	title = {Top Five Reasons Transhumanism Can Abolish Suffering by David Pearce},
	url = {https://www.hedweb.com/transhumanism/five-reasons.html},
	urldate = {2025-04-21}
}

@online{Pearce2013SocialMediaPre,
	file = {~/My Drive/library-pdf/Pearce2013SocialMediaPre.pdf;~/My Drive/library-html/Pearce2013SocialMediaPre.html},
	date = {2013},
	abstract = {Since the Cambrian explosion, pain and suffering have been inseparable from the existence of life on Earth. However, a major evolutionary transition is now in prospect. One species of social primate has evolved the capacity to master biotechnology, rewrite its own genetic source code, and abolish the molecular signature of experience below "hedonic zero" throughout the living world. This talk explores one aspect of the evolutionary transition ahead, namely interventions to phase out the cruelties of Nature. The exponential growth of computer processing power promises to let us micro-manage every cubic metre of the planet. Responsible stewardship of tomorrow's wildlife parks will entail cross-species fertility regulation via immunocontraception, "reprogramming" predators, famine relief, healthcare provision, and eventually a pan-species analogue of the welfare state. Can science and technology engineer the well-being of all sentience in our forward light-cone?},
	author = {Pearce, David},
	journaltitle = {HedWeb},
	langid = {english},
	title = {Social Media Pre-2014},
	url = {https://www.hedweb.com/social-media/pre2014.html},
	urldate = {2025-04-21}
}

@online{ProbablyGood2023CounterfactualImpactWhy,
	file = {~/My Drive/library-pdf/ProbablyGood2023CounterfactualImpactWhy.pdf;~/My Drive/library-html/ProbablyGood2023CounterfactualImpactWhy.html},
	abstract = {Learn how to evaluate the additional benefits caused by your actions with counterfactual impact. Compare different decisions and their potential outcomes.},
	author = {Probably Good},
	date = {2023-04-18},
	journaltitle = {Probably Good},
	langid = {american},
	shorttitle = {Counterfactual Impact},
	timestamp = {2025-04-21 13:24:33 (GMT)},
	title = {Counterfactual Impact: Why Imagining Alternatives Can Boost Your Impact},
	url = {https://probablygood.org/core-concepts/counterfactual-impact/},
	urldate = {2025-04-21}
}

@online{Raihani2021PunishmentIsnT,
	file = {~/My Drive/library-pdf/Raihani2021PunishmentIsnT.pdf;~/My Drive/library-html/Raihani2021PunishmentIsnT.html},
	abstract = {What if fairness is not about equity but about no one getting more than you? On spite and the evolution of punishment},
	author = {Raihani, Nichola},
	date = {2021-01-18},
	journaltitle = {Aeon},
	langid = {english},
	shorttitle = {Punishment isn’t about the common good},
	timestamp = {2025-04-21 13:21:14 (GMT)},
	title = {Punishment isn’t about the common good: it’s about spite},
	url = {https://aeon.co/ideas/punishment-isnt-about-the-common-good-its-about-spite},
	urldate = {2025-04-21}
}

@Online{Roser2023HowManyAnimals,
	file = {~/My Drive/library-pdf/Roser2023HowManyAnimals.pdf;~/My Drive/library-html/Roser2023HowManyAnimals.html},
	author = {Roser, Max},
	title = {How Many Animals Get Slaughtered Every Day?},
	url = {https://ourworldindata.org/how-many-animals-get-slaughtered-every-day},
	abstract = {Hundreds of millions of animals get killed for meat every
                  day.},
	date = {2023-09-26},
	journaltitle = {Our World in Data},
	langid = {english},
	shortjournal = {Our World in Data},
	timestamp = {2025-04-21 13:24:31 (GMT)},
	urldate = {2025-04-21}
}

@online{Russell2016QFutureOf,
	file = {~/My Drive/library-html/Russell2016QFutureOf.html;~/My Drive/library-pdf/Russell2016QFutureOf.pdf},
	url = {https://web.archive.org/web/20160622222528/people.eecs.berkeley.edu/~russell/temp/q-and-a.html},
	abstract = {Artificial intelligence (AI) involves methods for creating intelligent computer behavior, defined as maximizing the likelihood of achieving goals. It encompasses learning, reasoning, planning, perception, language understanding, and robotics, distinct from specific technologies like expert systems or deep learning, which are common misconceptions. Machine learning, a core AI branch, enables systems to improve from experience. Neural networks and deep learning are specific approaches within AI/ML. While AI offers potential societal benefits by augmenting human capabilities, concerns exist regarding misuse, inequality, job automation, and autonomous weapons. Concepts such as artificial general intelligence (AGI), superintelligence, and a potential intelligence explosion highlight the need for caution. Achieving superintelligence requires significant, unpredictable breakthroughs beyond mere computational power increases described by Moore's Law. Existential risk stems not from inherent machine malice but from the potential misalignment between machine objectives and human values. Addressing this value alignment problem is crucial for ensuring future AI systems remain beneficial and controllable, necessitating focused research on AI safety and ethics. – AI-generated abstract.},
	date = {2016},
	journaltitle = {Stuart Russell’s website},
	author = {Russell, Stuart},
	langid = {english},
	title = {Q \& A: The future of artificial intelligence},
	urldate = {2025-04-21}
}

@online{Singer2023ModernArgumentFor,
	file = {~/My Drive/library-pdf/Singer2023ModernArgumentFor.pdf},
	author = {Singer, Peter},
	date = {2023-05},
	journaltitle = {TED Talks},
	langid = {english},
	title = {A modern argument for the rights of animals},
	url = {https://www.ted.com/talks/peter_singer_a_modern_case_for_animal_rights},
	urldate = {2025-04-21}
}

@online{Soares2014SleepingWell,
	file = {~/My Drive/library-pdf/Soares2014SleepingWell.pdf;~/My Drive/library-html/Soares2014SleepingWell.html},
	author = {Soares, Nate},
	abstract = {1 I've been talking about psychological productivity tricks for a few posts, and I have a thing or two more to say on that next week. However, on the outside view, a vast portion of my productivity comes not from the psychological side, but from a bunch of other environmental},
	date = {2014-11-16},
	journaltitle = {Minding our way},
	langid = {english},
	timestamp = {2025-04-21 13:05:46 (GMT)},
	title = {Sleeping well},
	url = {https://mindingourway.com/sleeping-well/},
	urldate = {2025-04-21}
}

@online{Soares2015NotYetGods,
	file = {~/My Drive/library-html/Soares2015NotYetGods.html;~/My Drive/library-pdf/Soares2015NotYetGods.pdf},
	author = {Soares, Nate},
	abstract = {You probably don't feel guilty for failing to snap your fingers in just such a way as to produce a cure for Alzheimer's disease.  Yet, many people do feel guilty for failing to work until they drop every single day (which is a psychological impossibility). They feel guilty for failing},
	date = {2015-08-09},
	journaltitle = {Minding our way},
	langid = {english},
	timestamp = {2025-04-21 13:05:46 (GMT)},
	title = {Not yet gods},
	url = {https://mindingourway.com/not-yet-gods/},
	urldate = {2025-04-21}
}

@online{Soares2015StampCollector,
	file = {~/My Drive/library-html/Soares2015StampCollector.html;~/My Drive/library-pdf/Soares2015StampCollector.pdf},
	author = {Soares, Nate},
	abstract = {Once upon a time, a group of naïve philosophers found a robot that collected trinkets. Well, more specifically, the robot seemed to collect stamps: if you presented this robot with a choice between various trinkets, it would always choose the option that led towards it having as many stamps as},
	date = {2015-04-26},
	journaltitle = {Minding our way},
	langid = {english},
	timestamp = {2025-04-21 13:05:47 (GMT)},
	title = {The Stamp Collector},
	url = {https://mindingourway.com/the-stamp-collector/},
	urldate = {2025-04-21}
}

@online{Soares2015WhereCouldsGo,
	file = {~/My Drive/library-pdf/Soares2015WhereCouldsGo.pdf;~/My Drive/library-html/Soares2015WhereCouldsGo.html},
	author = {Soares, Nate},
	abstract = {Most people don't think they \&quot;could\&quot; cure Alzheimers by snapping their fingers, and so they don't feel terrible about failing to do this.  By contrast, people who fail to resist overeating, or who fail to stop playing Civilization at a reasonable hour, feel strongly that they \&quot;could},
	date = {2015-08-17},
	journaltitle = {Minding our way},
	langid = {english},
	timestamp = {2025-04-21 13:05:48 (GMT)},
	title = {Where coulds go},
	url = {https://mindingourway.com/where-coulds-go/},
	urldate = {2025-04-21}
}

@online{Soares2016YoureAllowedTo,
	file = {~/My Drive/library-html/Soares2016YoureAllowedTo.html;~/My Drive/library-pdf/Soares2016YoureAllowedTo.pdf},
	author = {Soares, Nate},
	abstract = {I often see friends run into a failure mode I call \&quot;false consistency,\&quot; especially in the Effective Altruism and Rationality circles, where consistency is an important virtue.  The False Consistency error is committed when someone has conflicting desires, thoughts, or beliefs, and bludgeons all but one of them},
	date = {2016-03-27},
	journaltitle = {Minding our way},
	langid = {english},
	timestamp = {2025-04-21 13:05:48 (GMT)},
	title = {You're allowed to be inconsistent},
	url = {https://mindingourway.com/youre-allowed-to-be-inconsistent/},
	urldate = {2025-04-21}
}

@online{Steinhardt2023Gpt2030And,
	file = {~/My Drive/library-pdf/Steinhardt2023Gpt2030And.pdf;~/My Drive/library-html/Steinhardt2023Gpt2030And.html},
	abstract = {I previously discussed the capabilities we might expect from future {AI} systems, illustrated through {GPT}2030, a hypothetical successor of {GPT}-4 trained in 2030. {GPT}2030 had a number of advanced capabilities, including superhuman programming, hacking, and persuasion skills, the ability to think more quickly than humans and to learn quickly by},
	author = {Steinhardt, Jacob},
	date = {2023-11-10},
	journaltitle = {Bounded Regret},
	langid = {english},
	shorttitle = {{GPT}-2030 and Catastrophic Drives},
	timestamp = {2025-04-21 13:21:26 (GMT)},
	title = {{GPT}-2030 and Catastrophic Drives: Four Vignettes},
	url = {https://bounded-regret.ghost.io/gpt-2030-and-catastrophic-drives-four-vignettes/},
	urldate = {2025-04-21}
}

@online{Tegmark2023DontLookUp,
	file = {~/My Drive/library-html/Tegmark2023DontLookUp.html;~/My Drive/library-pdf/Tegmark2023DontLookUp.pdf},
	abstract = {If superintelligence drives humanity extinct, it probably won’t be because it turned evil or conscious, but because it turned competent},
	author = {Tegmark, Max},
	date = {2023-04-25},
	journaltitle = {{TIME}},
	langid = {english},
	timestamp = {2025-04-21 13:26:17 (GMT)},
	title = {The 'Don't Look Up' Thinking That Could Doom Us With {AI}},
	url = {https://time.com/6273743/thinking-that-could-doom-us-with-ai/},
	urldate = {2025-04-21}
}

@online{Tenn2023MeetupCookbook,
	date = {2023},
	file = {~/My Drive/library-html/Tenn2023MeetupCookbook.html;~/My Drive/library-pdf/Tenn2023MeetupCookbook.pdf},
	author = {Tenn, Tigrenna},
	journaltitle = {Tigrenna Tenn's Neocities},
	langid = {english},
	timestamp = {2025-04-21 13:26:13 (GMT)},
	title = {Meetup Cookbook},
	url = {https://tigrennatenn.neocities.org/meetup_cookbook},
	urldate = {2025-04-21}
}

@online{Todd2014WhyAndHow,
	date = {2014-09},
	file = {~/My Drive/library-html/Todd2017WhyAndHow.html;~/My Drive/library-pdf/Todd2017WhyAndHow.pdf},
	author = {Todd, Benjamin},
	abstract = {Some people have skills that are better suited to earning money than the other strategies. These people can take a higher earning career and donate the money to effective organisations.},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:13 (GMT)},
	title = {Why and how to earn to give},
	url = {https://80000hours.org/articles/earning-to-give/},
	urldate = {2025-04-21}
}

@online{Todd20174BiasesTo,
	file = {~/My Drive/library-html/80000Hours20254BiasesTo.html;~/My Drive/library-pdf/80000Hours20254BiasesTo.pdf},
	abstract = {Over the last couple of decades, a large and growing body of research has emerged which shows that our decisions are far from rational. We did a survey of this research to find out what it means for your career decisions. It turns out that we likely don't know as much as we think we do, are overconfident, tend to think too narrowly and continue with paths that are no longer best for us. We need to be more sceptical of our decisions than we might be inclined to be; find ways to broaden our options; and take a more systematic and evidence-based approach to career choice.},
	author = {Todd, Benjamin},
	date = {2017-11},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:07 (GMT)},
	title = {4 biases to avoid in career decisions},
	url = {https://80000hours.org/articles/4-biases-to-avoid-in-career-decisions/},
	urldate = {2025-04-21}
}

@online{Todd2017ApplyingUnusualSkill,
	file = {~/My Drive/library-html/Todd2017ApplyingUnusualSkill.html;~/My Drive/library-pdf/Todd2017ApplyingUnusualSkill.pdf},
	abstract = {If you already have a strong existing skill set, is there a way to apply that to one of the key problems? If there's any option in which you might excel, it's usually worth considering, both for the potential impact and especially for the career capital; excellence in one field can often give you opportunities in others. This is even more likely if you're part of a community that's coordinating or working in a small field. Communities tend to need a small number of experts covering each of their main bases.},
	author = {Todd, Benjamin},
	date = {2017-11},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:11 (GMT)},
	title = {Applying an unusual skill to a needed niche},
	url = {https://80000hours.org/articles/applying-an-unusual-skill-to-a-needed-niche/},
	urldate = {2025-04-21}
}

@online{Todd2017BestEmailScripts,
	file = {~/My Drive/library-pdf/Todd2017BestEmailScripts.pdf;~/My Drive/library-html/Todd2017BestEmailScripts.html},
	abstract = {Here's a collection of the most useful email scripts we've found for asking for introductions and small favours from people you don't know. It's a work in progress. Send suggestions on what to include to ben@80000hours.org.},
	author = {Todd, Benjamin},
	date = {2017-11},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:14 (GMT)},
	title = {The best email scripts for cold-emailing},
	url = {https://80000hours.org/articles/email-scripts/},
	urldate = {2025-04-21}
}

@online{Todd2017CollegeAdvice,
	file = {~/My Drive/library-html/Todd2017CollegeAdvice.html;~/My Drive/library-pdf/Todd2017CollegeAdvice.pdf},
	abstract = {Looking for college advice? Here’s what we know about how to choose a major, and what to do once you start studying.},
	author = {Todd, Benjamin},
	date = {2017-04},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:12 (GMT)},
	title = {College advice},
	url = {https://80000hours.org/articles/college-advice/},
	urldate = {2025-04-21}
}

@online{Todd2017HowMuchDo,
	file = {~/My Drive/library-html/Todd2017HowMuchDo.html;~/My Drive/library-pdf/Todd2017HowMuchDo.pdf},
	abstract = {Hedge fund trading may be the highest paying job in the world, so to learn more, we spoke with a former manager at one of the world’s leading hedge funds.},
	author = {Todd, Benjamin},
	date = {2017-05-10},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:06 (GMT)},
	title = {How much do hedge fund traders earn?},
	url = {https://80000hours.org/2017/05/how-much-do-hedge-fund-traders-earn/},
	urldate = {2025-04-21}
}

@online{Todd2017TheseSkillsMake,
	file = {~/My Drive/library-pdf/Todd2017TheseSkillsMake.pdf;~/My Drive/library-html/Todd2017TheseSkillsMake.html},
	abstract = {Like many others, we’ve promoted the idea of learning {STEM} skills. Is that the wrong advice?},
	author = {Todd, Benjamin},
	date = {2017-11},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:20:15 (GMT)},
	title = {These skills make you most employable. Why isn’t coding in the top 10?},
	url = {https://80000hours.org/articles/skills-most-employable/},
	urldate = {2025-04-21}
}

@online{Todd2018HaveParticularStrength,
	file = {~/My Drive/library-html/Todd2018HaveParticularStrength.html;~/My Drive/library-pdf/Todd2018HaveParticularStrength.pdf},
	date = {2018-10},
	abstract = {This list is preliminary. We wanted to publish our existing thoughts on what to do with each skill, but can easily see ourselves changing our minds over the coming years. You can read about our general process and what career paths we recommend in our full article. Sometimes, however, it's possible to give more specific advice about what options to consider to people who already have pre-existing experience or qualifications, or are unusually good at a certain type of work.},
	author = {Todd, Benjamin},
	journaltitle = {80,000 Hours},
	langid = {american},
	shorttitle = {Have a particular strength?},
	timestamp = {2025-04-21 13:20:08 (GMT)},
	title = {Have a particular strength? Already an expert in a field? Here are the high-impact careers we suggest you consider first},
	url = {https://80000hours.org/articles/advice-by-expertise/},
	urldate = {2025-04-21}
}

@online{Todd2023CommunicatingIdeas,
	file = {~/My Drive/library-html/Todd2023CommunicatingIdeas.html;~/My Drive/library-pdf/Todd2023CommunicatingIdeas.pdf},
	author = {Todd, Benjamin and Hilton, Benjamin},
	abstract = {Through communicating important ideas, you could end up inspiring many people to do far more good than you could ever have done by yourself.},
	date = {2023-09},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:04 (GMT)},
	title = {Communicating ideas},
	url = {https://80000hours.org/skills/communication/},
	urldate = {2025-04-21}
}

@online{Tomasik2007ExpectedValueOf,
	abstract = {The expected value of information (EVI) quantifies the benefit of acquiring new data before making a decision. While colloquially defined as the change in expected value before and after learning, this can be misleading. A precise formulation considers a set of possible worlds, each with a subjective probability, and a set of possible actions, each with a utility conditional on the world. The expected utility of an action is the sum of its utilities across worlds, weighted by world probabilities. Initially, the optimal action maximizes this expected utility. New information `k` leads to updated probabilities over worlds and revised expected utilities. The value derived from specific information `k` is the difference between the expected utility of the new optimal action (chosen based on `k`) and the expected utility of the original optimal action, where both utilities are calculated using the updated probabilities conditional on `k`. Since the outcome of information gathering is uncertain, the overall EVI is obtained by summing the value derived from each possible information outcome `k`, weighted by the probability of obtaining that specific information `k`. This provides a formal measure of the expected gain from seeking information. – AI-generated abstract.},
	file = {~/My Drive/library-pdf/Tomasik2007ExpectedValueOf.pdf},
	journaltitle = {Brian Tomasik's Website},
	author = {Tomasik, Brian},
	date = {2007-12-31},
	langid = {american},
	title = {Expected value of information},
	url = {https://briantomasik.com/wp-content/uploads/2014/10/value-of-info.pdf},
	urldate = {2025-04-21}
}

@online{Tomasik2013BeautyDrivenMorality,
	file = {~/My Drive/library-html/Tomasik2014BeautyDrivenMorality.html;~/My Drive/library-pdf/Tomasik2014BeautyDrivenMorality.pdf},
	author = {Tomasik, Brian},
	date = {2013-10-14},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:24:34 (GMT)},
	title = {Beauty-Driven Morality},
	url = {https://reducing-suffering.org/beauty-driven-morality/},
	urldate = {2025-04-21}
}

@online{Tomasik2013OmelasAndSpace,
	file = {~/My Drive/library-pdf/Tomasik2013OmelasAndSpace.pdf;~/My Drive/library-html/Tomasik2013OmelasAndSpace.html},
	author = {Tomasik, Brian},
	date = {2013-06-26},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:24:36 (GMT)},
	title = {Omelas and Space Colonization},
	url = {https://reducing-suffering.org/omelas-and-space-colonization/},
	urldate = {2025-04-21}
}

@online{Tomasik2014ArtificialIntelligenceAnd,
	file = {~/My Drive/library-html/Tomasik2014ArtificialIntelligenceAnd.html;~/My Drive/library-pdf/Tomasik2014ArtificialIntelligenceAnd.pdf},
	abstract = {Artificial intelligence ({AI}) will likely transform the world later this century. Whether uncontrolled or controlled {AIs} would create more suffering in expectation is a question to explore further. Regardless, the field of {AI} safety and policy seems to be a very important space where altruists can make a positive-sum impact along many dimensions.},
	author = {Tomasik, Brian},
	date = {2014-05-14},
	journaltitle = {Center on Long-Term Risk},
	langid = {american},
	timestamp = {2025-04-21 13:24:04 (GMT)},
	title = {Artificial Intelligence and Its Implications for Future Suffering},
	url = {https://longtermrisk.org/artificial-intelligence-and-its-implications-for-future-suffering/},
	urldate = {2025-04-21}
}

@online{Tomasik2014HowLikelyIs,
	file = {~/My Drive/library-html/Tomasik2014HowLikelyIs.html;~/My Drive/library-pdf/Tomasik2014HowLikelyIs.pdf},
	author = {Tomasik, Brian},
	date = {2014-05-14},
	abstract = {This essay evaluates the probability of humanity achieving a stable, positive long-term future, often termed "utopia." It examines various factors influencing this outcome, including existential risks, the potential for human or artificial values to drift over vast timescales, and the impact of competitive pressures—whether between nations, corporations, or future artificial intelligences. Significant challenges to achieving a reliably beneficial future are identified; competitive dynamics often favor power-seeking behaviors over ethical considerations, and maintaining benevolent goals across cosmic timescales appears difficult. The potential for immense suffering, particularly if digital sentience arises, is highlighted as a major concern, even if stemming from initially well-intentioned actors. While factors like increased coordination or moral progress could improve prospects, the default trajectory seems unlikely to lead automatically to utopia. Instead, continued struggle, vast suffering, or extinction appear as plausible or even more probable outcomes without deliberate, focused efforts to navigate risks and steer development towards robustly positive goals. – AI-generated abstract.},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:24:38 (GMT)},
	title = {How Likely Is a Far-Future Utopia?},
	url = {https://reducing-suffering.org/utopia/},
	urldate = {2025-04-21}
}

@online{Tomasik2014IntuitionAndReason,
	file = {~/My Drive/library-html/Tomasik2014IntuitionAndReason.html;~/My Drive/library-pdf/Tomasik2014IntuitionAndReason.pdf},
	author = {Tomasik, Brian},
	abstract = {In many fields there's a divide between intuitive, axiomatic principles and rational, derived principles. Ethics contains these two sides as well. Our ethical conclusions are a balance between intuitive reactions and rational conclusions, with feedback in both directions.},
	date = {2014-05-14},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:24:35 (GMT)},
	title = {Intuition and Reason},
	url = {https://reducing-suffering.org/intuition-and-reason/},
	urldate = {2025-04-21}
}

@online{Tomasik2014OneTrillionFish,
	file = {~/My Drive/library-pdf/Tomasik2014OneTrillionFish.pdf;~/My Drive/library-html/Tomasik2014OneTrillionFish.html},
	author = {Tomasik, Brian},
	date = {2014-05-14},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:24:37 (GMT)},
	title = {One Trillion Fish},
	url = {https://reducing-suffering.org/one-trillion-fish/},
	urldate = {2025-04-21}
}

@online{Tomasik2014WhatsWrongWith,
	file = {~/My Drive/library-pdf/Tomasik2014WhatsWrongWith.pdf;~/My Drive/library-html/Tomasik2014WhatsWrongWith.html},
	author = {Tomasik, Brian},
	date = {2014-05-14},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:24:38 (GMT)},
	title = {What's Wrong with Entomophagy? (a short interview)},
	url = {https://reducing-suffering.org/whats-wrong-entomophagy-short-interview/},
	urldate = {2025-04-21}
}

@online{Tomasik2014WhyMaximizeExpected,
	file = {~/My Drive/library-pdf/Tomasik2014WhyMaximizeExpected.pdf;~/My Drive/library-html/Tomasik2014WhyMaximizeExpected.html},
	author = {Tomasik, Brian},
	abstract = {Standard Bayesian decision theory tells us to maximize the expected value of our actions. For instance, suppose we see a number of kittens stuck in trees, and we decide that saving some number n of kittens is n times as good as saving one kitten. Then, if we are faced with the choice of either saving a single kitten with certainty or having a 50-50 shot at saving three kittens (where, if we fail, we save no kittens), then we ought to try to save the three kittens, because doing so has expected value 1.5 (= 3*0.5 + 0*0.5), rather than the expected value of 1 (= 1*1) associated with saving the single kitten. But why expected value? Why not instead maximize some other function of probabilities and values? Two intuitive arguments are presented. First, in certain situations, maximizing the expected number of organisms helped is equivalent to maximizing the probability that any given organism is helped. Second, even in cases where that isn't true, the law of large numbers will often guarantee a better outcome over the long run.},
	date = {2014-05-14},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	timestamp = {2025-04-21 13:24:39 (GMT)},
	title = {Why Maximize Expected Value?},
	url = {https://reducing-suffering.org/why-maximize-expected-value/},
	urldate = {2025-04-21}
}

@online{Tomasik2014WhyVegansShould,
	file = {~/My Drive/library-html/Tomasik2014WhyVegansShould.html;~/My Drive/library-pdf/Tomasik2014WhyVegansShould.pdf},
	author = {Tomasik, Brian},
	date = {2014-05-14},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	title = {Why Vegans Should Care About Suffering in Nature},
	url = {https://reducing-suffering.org/why-vegans-should-care-about-suffering-in-nature/},
	urldate = {2025-04-21}
}

@online{Tomasik2014WillSpaceColonization,
	file = {~/My Drive/library-pdf/Tomasik2014WillSpaceColonization.pdf;~/My Drive/library-html/Tomasik2014WillSpaceColonization.html},
	author = {Tomasik, Brian},
	date = {2014-04},
	journaltitle = {Essays on Reducing Suffering},
	langid = {american},
	title = {Will Space Colonization Multiply Wild-Animal Suffering?},
	url = {https://reducing-suffering.org/will-space-colonization-multiply-wild-animal-suffering/},
	urldate = {2025-04-21}
}

@online{Tomasik2015RisksOfAstronomical,
	file = {~/My Drive/library-pdf/Tomasik2015RisksOfAstronomical.pdf;~/My Drive/library-html/Tomasik2015RisksOfAstronomical.html},
	abstract = {Space colonization would likely increase rather than decrease total suffering. Because many people care nonetheless about humanity’s spread into the cosmos, we should reduce risks of astronomical future suffering without opposing others’ spacefaring dreams. In general, we recommend to focus on making sure that an intergalactic future will be good if it happens rather than making sure there will be such a future.},
	author = {Tomasik, Brian},
	date = {2015-04-09},
	journaltitle = {Center on Long-Term Risk},
	langid = {american},
	timestamp = {2025-04-21 13:24:06 (GMT)},
	title = {Risks of Astronomical Future Suffering},
	url = {https://longtermrisk.org/risks-of-astronomical-future-suffering/},
	urldate = {2025-04-21}
}

@online{Townsend2022AddressingClimateChange,
	date = {2022},
	file = {~/My Drive/library-pdf/Townsend2022AddressingClimateChange.pdf;~/My Drive/library-html/Townsend2022AddressingClimateChange.html},
	abstract = {Addressing climate change is one of our recommended causes working on safeguarding the long-term future. This page is a summary of our full research report on this topic.},
	author = {Townsend, Michael},
	journaltitle = {Giving What We Can},
	langid = {english},
	timestamp = {2025-04-21 13:30:57 (GMT)},
	title = {Addressing climate change},
	url = {https://www.givingwhatwecan.org/climate-change},
	urldate = {2025-04-21}
}

@online{Tpperman2024ThereIsNo,
	file = {~/My Drive/library-html/Tpperman2024ThereIsNo.html;~/My Drive/library-pdf/Tpperman2024ThereIsNo.pdf},
	langid = {english},
	abstract = {My sense is some {EAs} act like/hope they will be assigned the perfect impactful career by some combination of 80,000 Hours recommendations (and similar) and ‘perceived consensus views in {EA}’.But, your life is full of specific factors, many impactful jobs haven’t yet been spotted by other {EAs} and career advice is importantly iterative.Instead of simply deferring, I recommend a combination of:Your own hard work figuring out your path to impact.(Still) Integrating expert advice.Support from the community, and close connections who know your context.Thank you for the thoughtful feedback from Alex Rahl-Kaplan, Alix Pham, Caitlin Borke, Claude, Matt Reardon, and Michelle Hutchinson for making this post better. Claude also kindly offered to take the blame for all the mistakes I might have made.{IntroductionQuestion}: How do you figure out how to do the most good with your career?Answer: Find an {EA} sorting hat[1]. Place it on your head. Let it read your mind. Listen carefully as it assigns you your chosen career track, or better yet, a specific role at a specific organisation. Well done. Work hard at your designated job and watch as the impact rolls in.Wrinkle: There is no {EA} sorting hat. There is no omniscient individual or entity that will hear about your degree, your skills, your preferences, and your context, and spit out an ideal career.Obviously this is a caricature. But I think there’s some truth to it. I think it looks like buying into the ideas of {EA}, and then hoping or expecting that the community or some organisation in it can match you with the right career path or job role.Maybe you see some of yourself in this pattern of thinking. Or you might know someone who is making this mistake. I see it happening too much in the {EA} community, especially among those newer to {EA}, and earlier in their career. This is a mistake that 80,000 Hours regularly tries to push back against. But their products are just too good so people still (sometimes) hope that an advising call and studious checking of the job board will solve the pernicious problem of how to craft an impactful career.I don’t think it’s a very interesting anecdote, but I definitely committed an egregious version of this at least once: I updated way too much on literally 5 minutes of advice from someone who worked at 80,000 hours over a beer. I treated his words as some kind of magic insight that I was on the right path. In hindsight, this was obviously bad judgment on my part.Why there isn’t an {EA} sorting {hatI} heard a lot of smart {EAs} tell me to take their advice with a grain of salt. For a while, I used to think this was just false modesty. Their advice was gold and much better than whatever silly thoughts I had floating around in my baby {EA} head. I was a fool. They were right. Here are some reasons why.1. Your life is full of specific factors to incorporate (aka personal fit)Reality has},
	author = {Tpperman, Elliot},
	date = {2024-12-18},
	journaltitle = {Effective Altruism Forum},
	keywords = {Career choice, Community, Career advising, 80,000 Hours, Opinion},
	timestamp = {2025-04-21 13:23:20 (GMT)},
	title = {There is No {EA} Sorting Hat},
	url = {https://forum.effectivealtruism.org/posts/5zzbzbYZcocoLnLif},
	urldate = {2025-04-21}
}

@online{Vinding2015HarmOfDeath,
	date = {2015},
	file = {~/My Drive/library-html/Vinding2015HarmOfDeath.html;~/My Drive/library-pdf/Vinding2015HarmOfDeath.pdf},
	author = {Vinding, Magnus},
	journaltitle = {Utilitarianism.com},
	langid = {english},
	timestamp = {2025-04-21 13:32:05 (GMT)},
	title = {The Harm of Death by Magnus Vinding},
	url = {https://www.utilitarianism.com/magnus-vinding/harm-death.html},
	urldate = {2025-04-21}
}

@online{Vinding2016CausePrioritization,
	file = {~/My Drive/library-pdf/Vinding2016CausePrioritization.pdf;~/My Drive/library-html/Vinding2016CausePrioritization.html},
	author = {Vinding, Magnus},
	date = {2016-09-07},
	journaltitle = {Magnus Vinding},
	langid = {english},
	shorttitle = {Magnus Vinding},
	timestamp = {2025-04-21 13:24:08 (GMT)},
	title = {Cause Prioritization},
	url = {https://magnusvinding.blogspot.com/2016/09/cause-prioritization.html},
	urldate = {2025-04-21}
}

@online{Vinding2016MagnusVindingTree,
	file = {~/My Drive/library-pdf/Vinding2016MagnusVindingTree.pdf;~/My Drive/library-html/Vinding2016MagnusVindingTree.html},
	abstract = {Altruistic individuals often focus on causes they happen upon rather than systematically determining which are most important, leading to potentially suboptimal resource allocation. While people may update their focus over time as they learn about different issues—such as poverty, non-human animal suffering, wild animal welfare, or the far future—this progression is often haphazard. Cause prioritization is presented as a more direct and systematic approach: the deliberate effort to evaluate and compare different potential causes to identify those where resources can achieve the greatest positive impact, according to one's values. Instead of merely optimizing actions within a given cause, cause prioritization involves a meta-level analysis to determine which causes should be focused on initially. This deliberate exploration aims to be more efficient than chance discovery in identifying the most pressing global problems, thereby increasing the potential effectiveness of altruistic actions. – AI-generated abstract.},
	author = {Vinding, Magnus},
	date = {2016-09-23},
	journaltitle = {Magnus Vinding},
	langid = {english},
	shorttitle = {Magnus Vinding},
	timestamp = {2025-04-21 13:24:09 (GMT)},
	title = {Magnus Vinding: The Tree of Priorities: A (Cause) Prioritization Framework},
	url = {https://magnusvinding.blogspot.com/2016/09/the-tree-of-ought-cause-prioritization.html},
	urldate = {2025-04-21}
}

@online{Vinding2018ExplainingExistence,
	file = {~/My Drive/library-pdf/Vinding2018ExplainingExistence.pdf;~/My Drive/library-html/Vinding2018ExplainingExistence.html},
	abstract = {First written: Aug 2018, Last update: Aug 2023 “Not how the world is, is the mystical, but that it is.” (“Nicht wie die Welt ist, ist das Mystische, sondern dass sie ist.”) …},
	author = {Vinding, Magnus},
	date = {2018-08-16},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:10 (GMT)},
	title = {Explaining Existence},
	url = {https://magnusvinding.com/2018/08/16/explaining-existence/},
	urldate = {2025-04-21}
}

@online{Vinding2018IsAiAlignment,
	file = {~/My Drive/library-html/Vinding2018IsAiAlignment.html;~/My Drive/library-pdf/Vinding2018IsAiAlignment.pdf},
	abstract = {The problem of {AI} alignment is usually defined roughly as the problem of making powerful artificial intelligence do what we humans want it to do. My aim in this essay is to argue that this problem …},
	author = {Vinding, Magnus},
	date = {2018-12-14},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:14 (GMT)},
	title = {Is {AI} Alignment Possible?},
	url = {https://magnusvinding.com/2018/12/14/is-ai-alignment-possible/},
	urldate = {2025-04-21}
}

@online{Vinding2018MoralCircleExpansion,
	file = {~/My Drive/library-html/Vinding2018MoralCircleExpansion.html;~/My Drive/library-pdf/Vinding2018MoralCircleExpansion.pdf},
	abstract = {Expanding humanity’s moral circle such that it includes all sentient beings seems among the most urgent and important missions before us. And yet there is a significant risk that such greater…},
	author = {Vinding, Magnus},
	date = {2018-09-04},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:12 (GMT)},
	title = {Moral Circle Expansion Might Increase Future Suffering},
	url = {https://magnusvinding.com/2018/09/04/moral-circle-expansion-might-increase-future-suffering/},
	urldate = {2025-04-21}
}

@online{Vinding2018WhyManyWorlds,
	file = {~/My Drive/library-pdf/Vinding2018WhyManyWorlds.pdf;~/My Drive/library-html/Vinding2018WhyManyWorlds.html},
	abstract = {At first glance, it seems like the many worlds interpretation of quantum mechanics ({MWI}) might have significant ethical implications. After all, {MWI} implies that there are many more sentient beings…},
	author = {Vinding, Magnus},
	date = {2018-11-02},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:13 (GMT)},
	title = {Why the Many-Worlds Interpretation May Not Have Significant Ethical Implications},
	url = {https://magnusvinding.com/2018/11/02/why-many-worlds-may-not-have-significant-implications/},
	urldate = {2025-04-21}
}

@online{Vinding2020SufferingAndHappiness,
	file = {~/My Drive/library-pdf/Vinding2020SufferingAndHappiness.pdf;~/My Drive/library-html/Vinding2020SufferingAndHappiness.html},
	abstract = {In this post, Magnus Vinding questions the purported value symmetry between suffering and happiness - and contrasts with alternative views.},
	author = {Vinding, Magnus},
	date = {2020-09-10},
	journaltitle = {Center for Reducing Suffering},
	langid = {american},
	shorttitle = {Suffering and happiness},
	timestamp = {2025-04-21 13:21:50 (GMT)},
	title = {Suffering and happiness: Morally symmetric or orthogonal?},
	url = {https://centerforreducingsuffering.org/research/suffering-and-happiness-morally-symmetric-or-orthogonal/},
	urldate = {2025-04-21}
}

@online{Vinding2020WhenMachinesImprove,
	file = {~/My Drive/library-pdf/Vinding2020WhenMachinesImprove.pdf;~/My Drive/library-html/Vinding2020WhenMachinesImprove.html},
	abstract = {The following is an excerpt from my book Reflections on Intelligence (2016/2024). The term “Artificial General Intelligence” ({AGI}) refers to a machine that can perform any cognitive task at least a…},
	author = {Vinding, Magnus},
	date = {2020-08-09},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:15 (GMT)},
	title = {When Machines Improve Machines},
	url = {https://magnusvinding.com/2020/08/09/when-machines-improve-machines/},
	urldate = {2025-04-21}
}

@online{Vinding2021SomeReasonsNot,
	file = {~/My Drive/library-html/Vinding2021SomeReasonsNot.html;~/My Drive/library-pdf/Vinding2021SomeReasonsNot.pdf},
	abstract = {Many people expect global economic growth to accelerate in the future, with growth rates that are not just significantly higher than those of today, but orders of magnitude higher. The following ar…},
	author = {Vinding, Magnus},
	date = {2021-06-07},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:17 (GMT)},
	title = {Some reasons not to expect a growth explosion},
	url = {https://magnusvinding.com/2021/06/07/reasons-not-to-expect-a-growth-explosion/},
	urldate = {2025-04-21}
}

@online{Vinding2021SufferingFocusedEthics,
	file = {~/My Drive/library-html/Vinding2021SufferingFocusedEthics.html;~/My Drive/library-pdf/Vinding2021SufferingFocusedEthics.pdf},
	abstract = {It seems intuitive to think that suffering-focused moral views imply that it is unimportant whether people live fulfilling lives. Yet the truth, I will argue, is in many ways the opposite — especia…},
	author = {Vinding, Magnus},
	date = {2021-01-12},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:16 (GMT)},
	title = {Suffering-focused ethics and the importance of happiness},
	url = {https://magnusvinding.com/2021/01/12/the-importance-of-happiness/},
	urldate = {2025-04-21}
}

@online{Vinding2022FarFromOmelas,
	file = {~/My Drive/library-pdf/Vinding2022FarFromOmelas.pdf;~/My Drive/library-html/Vinding2022FarFromOmelas.html},
	abstract = {The following is a slightly edited excerpt from my book Effective Altruism: How Can We Best Help Others? (2018/2022). I should like to re-emphasize a tragic fact that is all too easily forgotten by…},
	author = {Vinding, Magnus},
	date = {2022-08-05},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:18 (GMT)},
	title = {Far From Omelas},
	url = {https://magnusvinding.com/2022/08/05/far-from-omelas/},
	urldate = {2025-04-21}
}

@online{Vinding2022RadicalUncertaintyAbout,
	file = {~/My Drive/library-html/Vinding2022RadicalUncertaintyAbout.html;~/My Drive/library-pdf/Vinding2022RadicalUncertaintyAbout.pdf},
	abstract = {Our uncertainty about how the future will unfold is vast, especially on long timescales. In light of this uncertainty, it may be natural to think that our uncertainty about strategies must be equal…},
	author = {Vinding, Magnus},
	date = {2022-09-07},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:19 (GMT)},
	title = {Radical uncertainty about outcomes need not imply (similarly) radical uncertainty about strategies},
	url = {https://magnusvinding.com/2022/09/07/strategic-uncertainty/},
	urldate = {2025-04-21}
}

@online{Vinding2024FromAiTo,
	file = {~/My Drive/library-html/Vinding2024FromAiTo.html;~/My Drive/library-pdf/Vinding2024FromAiTo.pdf},
	abstract = {The aim of this post is to present a hypothetical future scenario that challenges some of our basic assumptions and intuitions about our place in the cosmos. Hypothetical future scenario: Earth-des…},
	author = {Vinding, Magnus},
	date = {2024-03-21},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:20 (GMT)},
	title = {From {AI} to distant probes},
	url = {https://magnusvinding.com/2024/03/21/from-ai-to-distant-probes/},
	urldate = {2025-04-21}
}

@online{Vinding2024ThoughtsAiPause,
	file = {~/My Drive/library-html/Vinding2024ThoughtsAiPause.html;~/My Drive/library-pdf/Vinding2024ThoughtsAiPause.pdf},
	abstract = {Whether to push for an {AI} pause is a hotly debated question. This post contains some of my thoughts on the issue of {AI} pause and the discourse that surrounds it. Contents The motivation for an {AI} p…},
	author = {Vinding, Magnus},
	date = {2024-06-06},
	journaltitle = {Magnus Vinding},
	langid = {english},
	timestamp = {2025-04-21 13:24:21 (GMT)},
	title = {Thoughts on {AI} pause},
	url = {https://magnusvinding.com/2024/06/06/thoughts-on-ai-pause/},
	urldate = {2025-04-21}
}

@online{Vinding2025ReducingExtremeSuffering,
	file = {~/My Drive/library-pdf/Vinding2025ReducingExtremeSuffering.pdf},
	date = {2025},
	abstract = {6. Reducing Extreme Suffering in Healthy Ways (Excerpt from the forthcoming book, Compassionate Purpose: Personal Inspiration for a Better World.)     Attempts to reduce extreme suffering come with a unique set of challenges that deserve treatment in their own right. This chapter will explore som...},
	author = {Vinding, Magnus},
	langid = {english},
	timestamp = {2025-04-21 13:23:02 (GMT)},
	title = {Reducing extreme suffering in healthy ways},
	url = {https://docs.google.com/document/d/1tU8B0BqJnjKi12XNwUD3hAkLe4HPKrXwzCixFXr5058/edit},
	urldate = {2025-04-21}
}

@online{Watson2018AssessingGlobalCatastrophic,
	file = {~/My Drive/library-pdf/Watson2018AssessingGlobalCatastrophic.pdf;~/My Drive/library-html/Watson2018AssessingGlobalCatastrophic.html},
	abstract = {In this talk from {EA} Global 2018: San Francisco, Dr. Crystal Watson shares foundational thinking about Global Catastrophic Biological Risks, how the Center for Health Security at Johns Hopkins is work},
	author = {Watson, Crystal},
	date = {2018-07-17},
	journaltitle = {EffectiveAltruism.org},
	langid = {english},
	timestamp = {2025-04-21 13:30:36 (GMT)},
	title = {Assessing Global Catastrophic Biological Risks {\textbar} Effective Altruism},
	url = {https://www.effectivealtruism.org/articles/ea-global-2018-assessing-gcbr},
	urldate = {2025-04-21}
}

@online{Wiblin2015IsPursuingFame,
	file = {~/My Drive/library-html/Wiblin2015IsPursuingFame.html;~/My Drive/library-pdf/Wiblin2015IsPursuingFame.pdf},
	abstract = {While there is the potential for huge earnings, advocacy power and direct impact, the odds are stacked against even very talented individuals. A very large number of people attempt to achieve success in the arts for reasons unrelated to its social impact, making it unlikely to be a neglected area. For most people, a career in arts and entertainment is unlikely to be the path with the highest potential to do good, so we suggest you consider your other options first.},
	author = {Wiblin, Robert},
	date = {2015-07},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:00 (GMT)},
	title = {Is pursuing fame a good way to make the world a better place?},
	url = {https://80000hours.org/career-reviews/pursuing-fame-in-art-and-entertainment/},
	urldate = {2025-04-21}
}

@online{Wiblin2023JohannesAckvaUnfashionable,
	author = {Wiblin, Robert and Harris, Keiran},
	abstract = {Effective climate action should prioritize avoiding worst-case, high-temperature scenarios due to the non-linear nature of climate damages, where each additional degree of warming causes disproportionately more harm. Standard approaches focusing solely on maximizing expected emission reductions, often via mature technologies like solar and wind, may be suboptimal. High-damage futures likely correlate with scenarios where these popular renewables underperform. A more robust strategy involves hedging against this possibility by supporting a portfolio of currently less fashionable but potentially crucial technologies, such as enhanced geothermal systems, advanced nuclear reactors, and carbon capture. Near-term local emission reductions may even be negatively correlated with long-term global impact if they rely only on deploying mature technologies. Greater leverage can often be achieved by fostering innovation and cost reduction in early-stage technologies, thereby influencing global adoption patterns over decades, much like early German solar subsidies drove down global costs despite limited initial local impact. – AI-generated abstract.},
	file = {~/My Drive/library-pdf/Wiblin2023JohannesAckvaUnfashionable.pdf;~/My Drive/library-html/Wiblin2023JohannesAckvaUnfashionable.html},
	date = {2023-04-03},
	journaltitle = {80,000 Hours},
	langid = {american},
	timestamp = {2025-04-21 13:21:01 (GMT)},
	title = {Johannes Ackva on unfashionable climate interventions that work, and fashionable ones that don't},
	url = {https://80000hours.org/podcast/episodes/johannes-ackva-unfashionable-climate-interventions/},
	urldate = {2025-04-21}
}

@online{Woods2022ParableOfBoy,
	file = {~/My Drive/library-html/Woods2022ParableOfBoy.html;~/My Drive/library-pdf/Woods2022ParableOfBoy.pdf},
	langid = {english},
	abstract = {Misinterpreting probabilistic warnings about low-frequency, high-impact events poses significant dangers. A modern parable illustrates this: a boy repeatedly warns villagers of a "5\% chance of a wolf." The villagers, failing to think probabilistically, treat his warnings as certainty claims. When the wolf initially fails to appear, they dismiss him as alarmist. Ultimately, the low-probability event occurs, leading to disaster because precautions were abandoned. This scenario mirrors societal responses to warnings about potential catastrophes like pandemics (e.g., pre-COVID-19 scares) or future existential risks from AI or nuclear war. The non-materialization of previously predicted low-probability disasters does not invalidate the underlying risk assessments or the probabilistic framework. Instead of dismissing forecasters after perceived "false alarms," which are expected outcomes when dealing with low probabilities, one should continually assess the probability and potential impact of catastrophic risks. Appropriate vigilance and preparedness should be maintained, resisting the tendency to over-update beliefs based solely on the absence of catastrophe thus far, especially considering media often simplifies probabilistic nuance into misleading certainty. – AI-generated abstract.},
	author = {Woods, Kat},
	date = {2022-08-15},
	journaltitle = {Effective Altruism Forum},
	keywords = {Existential risk, {AI} safety, Biosecurity, Effective altruism art and fiction, {AI} alignment, Epistemology, Existential risk fiction, Motivational},
	timestamp = {2025-04-21 13:23:19 (GMT)},
	title = {The Parable of the Boy Who Cried 5\% Chance of Wolf},
	url = {https://forum.effectivealtruism.org/posts/5BpgZKFrfeRtREg7W},
	urldate = {2025-04-21}
}

@online{Yudkowsky2007BottomLine,
	abstract = {The process of belief formation determines the evidential value of a conclusion, distinct from the justifications presented afterward. This is illustrated through a parable involving two boxes, one containing a diamond, with uncertain signs indicating its location. A "clever arguer" is hired to advocate for one box; they first commit to the conclusion that their client's box holds the diamond and subsequently select only supporting arguments. The conclusion written by this arguer is causally entangled only with the hiring process, not the actual location of the diamond. Conversely, a "curious inquirer" first examines all available evidence impartially before deriving a probabilistic conclusion. This inquirer's conclusion is entangled with the signs and portents related to the boxes. Applied to reasoning, the effectiveness of one's conclusions depends on the underlying "algorithm" that determines the "bottom line." If a conclusion is fixed beforehand due to preference or bias, the subsequent arguments gathered to support it do not change the epistemic status determined by the initial, potentially flawed, decision process. This framework serves as a caution for self-reflection on one's own reasoning pathways, rather than primarily as a method for critiquing others. – AI-generated abstract.},
	file = {~/My Drive/library-html/Yudkowsky2007BottomLine.html;~/My Drive/library-pdf/Yudkowsky2007BottomLine.pdf},
	langid = {english},
	author = {Yudkowsky, Eliezer},
	date = {2007-09-28},
	journaltitle = {{LessWrong}},
	keywords = {Rationalization, Filtered Evidence, Litany of Tarski, Rationality},
	timestamp = {2025-04-21 13:31:35 (GMT)},
	title = {The Bottom Line},
	url = {https://www.lesswrong.com/posts/34XxbRFe54FycoCDw/the-bottom-line},
	urldate = {2025-04-21}
}

@online{Yudkowsky2007NoUniversallyCompelling,
	url = {https://www.lesswrong.com/posts/PtoQdG7E8MxYJrigu/no-universally-compelling-arguments},
	file = {~/My Drive/library-html/Yudkowsky2007NoUniversallyCompelling.html;~/My Drive/library-pdf/Yudkowsky2007NoUniversallyCompelling.pdf},
	author = {Yudkowsky, Eliezer},
	date = {2007},
	journaltitle = {LessWrong Sequences},
	langid = {english},
	timestamp = {2025-04-21 13:31:46 (GMT)},
	title = {No Universally Compelling Arguments},
	urldate = {2025-04-21}
}

@online{Yudkowsky2008FallacyOfGray,
	file = {~/My Drive/library-pdf/Yudkowsky2008FallacyOfGray.pdf;~/My Drive/library-html/Yudkowsky2008FallacyOfGray.html},
	langid = {english},
	abstract = {The Sophisticate: “The world isn’t black and white. No one does pure good or pure bad. It’s all gray. Therefore, no one is better than anyone else.”

    The Zetet: “Knowing only gray, you conclude that all grays are the same shade. You mock the simplicity of the two-color view, yet you replace it with a one-color view . . .”

    —Marc Stiegler, David’s Sling

  I don’t know if the Sophisticate’s mistake has an official name, but I call it the Fallacy of Gray. We saw it manifested in the previous essay—the one who believed that odds of two to the power of seven hundred and fifty million to one, against, meant “there was still a chance.” All probabilities, to him, were simply “uncertain” and that meant he was licensed to ignore them if he pleased.

  “The Moon is made of green cheese” and “the Sun is made of mostly hydrogen and helium” are both uncertainties, but they are not the same uncertainty.

  Everything is shades of gray, but there are shades of gray so light as to be very nearly white, and shades of gray so dark as to be very nearly black. Or even if not, we can still compare shades, and say “it is darker” or “it is lighter.”

  Years ago, one of the strange little formative moments in my career as a rationalist was reading this paragraph from Player of Games by Iain M. Banks, especially the sentence in bold:

    A guilty system recognizes no innocents. As with any power apparatus which thinks everybody’s either for it or against it, we’re against it. You would be too, if you thought about it. The very way you think places you amongst its enemies. This might not be your fault, because every society imposes some of its values on those raised within it, but the point is that some societies try to maximize that effect, and some try to minimize it. You come from one of the latter and you’re being asked to explain yourself to one of the former. Prevarication will be more difficult than you might imagine; neutrality is probably impossible. You cannot choose not to have the politics you do; they are not some separate set of entities somehow detachable from the rest of your being; they are a function of your existence. I know that and they know that; you had better accept it.

  Now, don’t write angry comments saying that, if societies impose fewer of their values, then each succeeding generation has more work to start over from scratch. That’s not what I got out of the paragraph.

  What I got out of the paragraph was something which seems so obvious in retrospect that I could have conceivably picked it up in a hundred},
	author = {Yudkowsky, Eliezer},
	date = {2008-01-07},
	journaltitle = {{LessWrong}},
	keywords = {Fallacies, Fallacy of Gray},
	timestamp = {2025-04-21 13:31:37 (GMT)},
	title = {The Fallacy of Gray},
	url = {https://www.lesswrong.com/posts/dLJv2CoRCgeC2mPgj/the-fallacy-of-gray},
	urldate = {2025-04-21}
}

@online{Yudkowsky2008LivingInMany,
	file = {~/My Drive/library-html/Yudkowsky2008LivingInMany.html;~/My Drive/library-pdf/Yudkowsky2008LivingInMany.pdf},
	author = {Yudkowsky, Eliezer},
	date = {2008},
	journaltitle = {LessWrong Sequences},
	langid = {english},
	timestamp = {2025-04-21 13:31:44 (GMT)},
	title = {Living in Many Worlds},
	url = {https://www.readthesequences.com/Living-In-Many-Worlds},
	urldate = {2025-04-21}
}

@online{Yudkowsky2008ThouArtPhysics,
	abstract = {The common perception of a conflict between deterministic physics and free will stems from a flawed cognitive model that places the agent ("Me") and "Physics" as separate, competing causes determining the "Future". A more accurate representation understands the agent, with its thoughts, decisions, and actions, as an integral *part* of the physical universe, not an entity external to it. Consequently, physics determining the future inherently *includes* the agent's causal role within that physical system. This perspective suggests that agency, choice, and responsibility do not merely coexist with determinism but actually *require* a lawful, ordered reality to be meaningful. Without the regularities described by physics, purposeful planning and action would be impossible. Therefore, physics constitutes the substrate *for* our choices and actions, rather than negating them. Perceived incompatibilities arise from cognitive errors in modeling levels of organization, not from a fundamental conflict in reality. – AI-generated abstract.},
	file = {~/My Drive/library-pdf/Yudkowsky2008ThouArtPhysics.pdf;~/My Drive/library-html/Yudkowsky2008ThouArtPhysics.html},
	url = {https://www.lesswrong.com/posts/NEeW7eSXThPz7o4Ne/thou-art-physics},
	author = {Yudkowsky, Eliezer},
	date = {2008-06-06},
	journaltitle = {LessWrong Sequences},
	langid = {english},
	timestamp = {2025-04-21 13:31:47 (GMT)},
	title = {Thou Art Physics},
	urldate = {2025-04-21}
}

@online{Yudkowsky2009ThreeWorldsCollide,
	file = {~/My Drive/library-html/Yudkowsky2009ThreeWorldsCollide.html;~/My Drive/library-pdf/Yudkowsky2009ThreeWorldsCollide.pdf},
	langid = {english},
	abstract = {"The kind of classic fifties-era first-contact story that Jonathan Swift
might have written, if Jonathan Swift had had a background in game
theory."        -- (Hugo nominee) Peter Watts, "In Praise of Baby-Eating"Three Worlds Collide is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and {PG}-13 content.
The Baby-Eating Aliens
War and/or Peace
The Super Happy People
Interlude with the Confessor
Three Worlds Decide
Normal Ending
True Ending
Atonement

{PDF} version here.},
	author = {Yudkowsky, Eliezer},
	date = {2009-01-30},
	journaltitle = {{LessWrong}},
	keywords = {Fiction, Metaethics},
	timestamp = {2025-04-21 13:31:40 (GMT)},
	title = {Three Worlds Collide},
	url = {https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8},
	urldate = {2025-04-21}
}

@online{Yudkowsky2009TwelveVirtuesOf,
	file = {~/My Drive/library-pdf/Yudkowsky2009TwelveVirtuesOf.pdf;~/My Drive/library-html/Yudkowsky2009TwelveVirtuesOf.html},
	author = {Yudkowsky, Eliezer},
	date = {2009},
	langid = {english},
	title = {Twelve Virtues of Rationality},
	url = {http://yudkowsky.net/rational/virtues/},
	urldate = {2025-04-21}
}

@online{Yudkowsky2017AiSafetyMindset,
	file = {~/My Drive/library-pdf/Yudkowsky2017AiSafetyMindset.pdf;~/My Drive/library-html/Yudkowsky2017AiSafetyMindset.html},
	abstract = {Asking how {AI} designs could go wrong, instead of imagining them going right.},
	author = {Yudkowsky, Eliezer},
	date = {2017},
	journaltitle = {Arbital},
	langid = {english},
	timestamp = {2025-04-21 13:21:16 (GMT)},
	title = {{AI} safety mindset},
	url = {https://arbital.com/p/AI_safety_mindset/},
	urldate = {2025-04-21}
}

@online{Yudkowsky2017HarmlessSupernovaFallacy,
	file = {~/My Drive/library-pdf/Yudkowsky2017HarmlessSupernovaFallacy.pdf;~/My Drive/library-html/Yudkowsky2017HarmlessSupernovaFallacy.html},
	abstract = {False dichotomies and continuum fallacies which can be used to argue that anything, including a supernova, must be harmless.},
	author = {Yudkowsky, Eliezer},
	date = {2017},
	journaltitle = {Arbital},
	langid = {english},
	timestamp = {2025-04-21 13:21:17 (GMT)},
	title = {Harmless supernova fallacy},
	url = {https://arbital.com/p/harmless_supernova/},
	urldate = {2025-04-21}
}

@online{Yudkowsky2017InterpretationsOfProbability,
	file = {~/My Drive/library-pdf/Yudkowsky2017InterpretationsOfProbability.pdf;~/My Drive/library-html/Yudkowsky2017InterpretationsOfProbability.html},
	abstract = {What does it *mean* to say that a fair coin has a 50\% probability of coming up heads?},
	author = {Yudkowsky, Eliezer},
	date = {2017},
	journaltitle = {Arbital},
	langid = {english},
	timestamp = {2025-04-21 13:21:18 (GMT)},
	title = {Interpretations of "probability"},
	url = {https://arbital.com/p/probability_interpretations/},
	urldate = {2025-04-21}
}

@online{Yudkowsky2023OpenLetterAi,
	abstract = {The development of artificial intelligence systems surpassing human capabilities poses a severe existential risk. The creation of superhuman AI under current conditions, lacking proven alignment techniques and deep understanding of the systems' internal workings, is highly likely to result in the extinction of humanity and all biological life. Relying on future AI to solve alignment problems is not a viable plan. Progress in AI capabilities significantly outpaces progress in AI safety and alignment research. Proposed temporary moratoriums, such as a six-month pause on training systems more powerful than GPT-4, are insufficient to address the magnitude of the threat. A complete, indefinite, and worldwide shutdown of large-scale AI training runs is required. This necessitates international agreements, the decommissioning of large GPU clusters, stringent controls on computing power allocation for AI training, hardware tracking, and a willingness to enforce the ban globally, potentially through military means, prioritizing AI risk mitigation even above nuclear conflict avoidance. – AI-generated abstract.},
	file = {~/My Drive/library-html/Yudkowsky2023OpenLetterAi.html;~/My Drive/library-pdf/Yudkowsky2023OpenLetterAi.pdf},
	author = {Yudkowsky, Eliezer},
	date = {2023-03-29},
	journaltitle = {{TIME}},
	langid = {english},
	timestamp = {2025-04-21 13:26:15 (GMT)},
	title = {The Open Letter on {AI} Doesn't Go Far Enough},
	url = {https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/},
	urldate = {2025-04-21}
}

