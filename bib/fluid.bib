
@online{Daniel2024PercheRischiDi,
	journaltitle = {Biblioteca Altrusimo Efficace},
	langid = {english},
	date = {2024},
	translator = {Tlön},
	title = {Perché i rischi di sofferenza sono i rischi esistenziali peggiori e come possiamo prevenirli},
	langid = {italian},
	database = {Tlön},
	author = {Daniel, Max},
	translation = {Daniel2017SrisksWhyThey},
	timestamp = {2024-05-27 09:47:37 (GMT)}
}

@online{Macaskill2024ProgressoMoraleE,
	journaltitle = {Biblioteca Altrusimo Efficace},
	date = {2024},
	translator = {Tlön},
	title = {Progresso morale e causa X},
	langid = {italian},
	database = {Tlön},
	author = {{MacAskill}, William},
	translation = {MacAskill2016MoralProgressCause},
	timestamp = {2024-05-27 09:49:18 (GMT)}
}

@online{Murphy2011GalacticScaleEnergy,
	file = {~/Google Drive/library-pdf/Murphy2011GalacticScaleEnergy.pdf;~/Google Drive/library-html/Murphy2011GalacticScaleEnergy.html},
	date = {2011-07-12},
	journaltitle = {Do the Math},
	author = {Murphy, Tom},
	langid = {american},
	timestamp = {2024-05-22 12:32:34 (GMT)},
	title = {Galactic-scale energy},
	url = {https://dothemath.ucsd.edu/2011/07/galactic-scale-energy/},
	urldate = {2024-05-22}
}

@online{Openai2021ImprovingLanguageModel,
	file = {~/Google Drive/library-pdf/Openai2021ImprovingLanguageModel.pdf;~/Google Drive/library-html/Openai2021ImprovingLanguageModel.html},
	url = {https://openai.com/index/improving-language-model-behavior/},
	date = {2021-06-10},
	journaltitle = {OpenAI},
	title = {Improving language model behavior by training on a curated dataset},
	author = {{OpenAI}},
	timestamp = {2024-05-22 16:30:21 (GMT)}
}

@online{Ortiz-Ospina2024SaluteGlobale,
	journaltitle = {Biblioteca Altrusimo Efficace},
	date = {2024},
	translator = {Tlön},
	title = {Salute globale},
	langid = {italian},
	database = {Tlön},
	author = {Ortiz-Ospina, Esteban},
	translation = {Ortiz-Ospina2016GlobalHealth},
	timestamp = {2024-05-27 09:50:01 (GMT)}
}

@online{Roser2024OurWorldIn,
	journaltitle = {Biblioteca Altrusimo Efficace},
	date = {2024},
	translator = {Tlön},
	title = {[{Our World in Data}] Tempistiche di sviluppo dell'IA: Cosa si aspettano gli esperti di intelligenza artificiale per il futuro},
	langid = {italian},
	database = {Tlön},
	author = {Roser, Max},
	translation = {Roser2023OurWorldIn},
	timestamp = {2024-05-27 09:40:44 (GMT)}
}

@collection{Schubert2024EffectiveAltruismAnd,
	file = {~/Google Drive/library-pdf/Schubert2024EffectiveAltruismAnd.pdf},
	langid = {english},
	abstract = {"Humans are more altruistic than one might think. Many of us want to have a positive impact on the world. We donate to charity, volunteer for a good cause, or choose a career to make a difference. Annual {US} donations sum to \$500 billion-about 2\% of {GDP}-and no less than 25\% of Americans volunteer for a good cause. People make real altruistic sacrifices on a scale that's often underappreciated."--},
	date = {2024},
	editor = {Schubert, Stefan and Caviola, Lucius},
	isbn = {9780197757406 9780197757390},
	keywords = {Altruism, Helping behavior},
	location = {New York, {NY}},
	pagetotal = {1},
	publisher = {Oxford University Press},
	shorttitle = {Effective altruism and the human mind},
	timestamp = {2024-06-11 01:04:52 (GMT)},
	title = {Effective altruism and the human mind: the clash between impact and intuition}
}

@book{Sweigart2020AutomateBoringStuff,
	location = {San Francisco},
	title = {Automate the boring stuff with python: Practical programming for total beginners},
	isbn = {978-1-59327-992-9},
	publisher = {No Starch Press},
	author = {Sweigart, Al},
	date = {2020},
	file = {~/Google Drive/library-pdf/Sweigart2020AutomateBoringStuff.pdf}
}

@online{Todd2024PercheEImportante,
	journaltitle = {Biblioteca Altrusimo Efficace},
	date = {2024},
	translator = {Tlön},
	title = {Perché è importante ridurre il rischio esistenziale},
	langid = {italian},
	database = {Tlön},
	author = {Todd, Benjamin},
	translation = {Todd2017CaseReducingExistential},
	timestamp = {2024-05-27 09:44:15 (GMT)}
}

@online{Villalobos2024WillWeRun,
	file = {~/Google Drive/library-pdf/Villalobos2024WillWeRun.pdf;~/Google Drive/library-html/Villalobos2024WillWeRun.html},
	abstract = {We estimate the stock of human-generated public text at around 300 trillion tokens. If trends continue, language models will fully utilize this stock between 2026 and 2032, or even earlier if intensely overtrained.},
	author = {Villalobos, Pablo and Ho, Anson and Sevilla, Jaime and Besiroglu, Tamay and Heim, Lennart and Hobbhahn, Marius},
	date = {2024-06-06},
	journaltitle = {Epoch {AI}},
	langid = {english},
	shorttitle = {Will We Run Out of Data?},
	timestamp = {2024-06-10 21:24:59 (GMT)},
	title = {Will We Run Out of Data? Limits of {LLM} Scaling Based on Human-Generated Data},
	url = {https://epochai.org/blog/will-we-run-out-of-data-limits-of-llm-scaling-based-on-human-generated-data},
	urldate = {2024-06-10}
}

@online{Wiblin2022richardngolarge,
	date = {2022-12-13},
	file = {~/Google Drive/library-html/Wiblin2022richardngolarge.html;~/Google Drive/library-pdf/Wiblin2022richardngolarge.pdf},
	author = {Wiblin, Robert and Harris, Keiran},
	langid = {american},
	timestamp = {2022-12-14 11:05:56 (CET)},
	title = {Richard Ngo on large language models, {OpenAI}, and striving to make the future go well},
	journaltitle = {80,000 Hours},
	url = {https://80000hours.org/podcast/episodes/richard-ngo-large-language-models/},
	urldate = {2022-12-14}
}

