
@InCollection{Todd201580000Hours,
	abstract = {80,000 Hours addresses the gap between students wanting meaningful careers and lacking guidance on maximizing impact. Through Oxford-based research, one-on-one coaching, and community building, they help graduates identify high-impact career opportunities. Their evidence-based approach aims to systematically direct talent toward solving the world's most pressing problems effectively.},
	pages = {120--124},
	crossref = {Carey2015EffectiveAltruismHandbook},
	title = {80,000 Hours},
	author = {Todd, Benjamin},
	timestamp = {2025-06-23 10:24:26 (GMT)}
}

@article{Acosta2023GlobalEstimatesOf,
	author = {Acosta, Enrique},
	title = {Global estimates of excess deaths from {COVID}-19},
	volume = {613},
	number = {7942},
	pages = {31--33},
	doi = {10.1038/d41586-022-04138-w},
	abstract = {Estimating the number of deaths attributable to COVID-19 around the world is a complex task — as highlighted by one attempt to measure global excess mortality in 2020 and 2021.},
	date = {2023-01},
	journaltitle = {Nature},
	keywords = {Epidemiology, {SARS}-{CoV}-2},
	langid = {english},
	rights = {2022 Springer Nature Limited},
	timestamp = {2025-07-03 14:07:20 (GMT)},
	urldate = {2025-07-03}
}

@Report{Adalja2018CharacteristicsOfPandemic,
	langid = {english},
	file = {~/My Drive/library-pdf/Adalja2018CharacteristicsOfPandemic.pdf},
	abstract = {A global catastrophic biological risk (GCBR) constitutes a sudden, widespread disaster beyond the control of governments and the private sector.  Several microbial characteristics, including efficient human-to-human transmission, a significant case fatality rate, lack of effective countermeasures, a largely immunologically naïve population, immune evasion mechanisms, and respiratory spread, heighten the risk of a GCBR.  Although any microbe could theoretically evolve into a GCBR-level threat, RNA viruses, with their high mutability and lack of broad-spectrum antivirals, pose the greatest danger.  Current efforts to catalog viral species, while scientifically valuable, may not translate directly into improved pandemic preparedness.  A more effective approach involves enhanced surveillance of respiratory RNA viruses, coupled with aggressive diagnostic testing of infectious disease syndromes in strategic locations. This, combined with increased vaccine and antiviral research specifically targeting RNA respiratory viruses and clinical research to optimize treatment protocols, would strengthen pandemic preparedness. Human factors, such as infrastructure limitations and flawed decision-making, can exacerbate outbreaks and elevate pathogens to GCBR status. – AI-generated abstract.},
	url = {https://centerforhealthsecurity.org/sites/default/files/2022-12/180510-pandemic-pathogens-report.pdf},
	date = {2018},
	institution = {The Johns Hopkins Center for Health Security},
	author = {Adalja, Amesh A. and Watson, Matthew and Toner, Eric S. and Cicero, Anita and Inglesby, Thomas V.},
	title = {The characteristics of pandemic pathogens},
	timestamp = {2025-07-04 15:23:53 (GMT)}
}

@article{Adalja2019BroadSpectrumAntiviral,
	file = {~/My Drive/library-pdf/Adalja2019BroadSpectrumAntiviral.pdf},
	author = {Adalja, Amesh and Inglesby, Thomas},
	abstract = {Viral infections pose the greatest pandemic threat due to viral replication rates, transmissibility, and a lack of broad-spectrum antiviral agents.  Antiviral strategies must selectively target viruses without harming host cells, limiting the number of viable targets.  Existing antivirals are typically narrow-spectrum, targeting specific viruses or viral families, like acyclovir for herpesviruses and anti-HIV medications for HIV. Some antivirals exhibit broader activity. Favipiravir inhibits RNA-dependent RNA polymerase in influenza and other RNA viruses. Cidofovir targets DNA viruses, while its derivative, brincidofovir, has shown in vitro activity against some RNA viruses.  Ribavirin inhibits viral polymerase enzymes in various RNA and DNA viruses.  Repurposing existing antivirals offers another avenue for expanding their spectrum, as seen with ganciclovir and tenofovir. However, broad-spectrum activity can correlate with host toxicity, particularly with nucleoside analogs.  A comprehensive antiviral strategy should include systematic testing of existing and developing antivirals against a wider range of viruses, along with targeted therapies like monoclonal antibodies. This approach is crucial for pandemic preparedness, given that current antiviral development primarily focuses on specific viruses rather than viral families or broader groups. – AI-generated abstract.},
	title = {Broad-spectrum antiviral agents: a crucial pandemic tool},
	volume = {17},
	number = {7},
	pages = {467--470},
	doi = {10.1080/14787210.2019.1635009},
	date = {2019-07-03},
	issn = {1478-7210, 1744-8336},
	journaltitle = {Expert Review of Anti-infective Therapy},
	langid = {english},
	timestamp = {2025-07-04 16:44:17 (GMT)},
	urldate = {2025-07-04}
}

@online{Amodei2025UrgencyOfInterpretability,
	file = {~/My Drive/library-html/Amodei2025UrgencyOfInterpretability.html;~/My Drive/library-pdf/Amodei2025UrgencyOfInterpretability.pdf},
	date = {2025-04},
	abstract = {The opacity of current generative AI systems presents significant risks, as their internal decision-making processes are poorly understood. This lack of understanding hinders the ability to predict or prevent unintended harmful behaviors, misuse, or misalignment. Mechanistic interpretability, a research field focused on elucidating the inner workings of AI models, offers a promising avenue for addressing these challenges. Recent advancements in identifying conceptual "features" and computational "circuits" within models suggest that a comprehensive understanding, analogous to an "MRI for AI," may be achievable. However, AI capabilities are progressing at a pace that outstrips interpretability research, creating an urgent need to bridge this gap. To ensure that interpretability tools mature sufficiently before AI systems attain overwhelming power, accelerated research efforts across industry and academia are essential, complemented by light-touch government regulations fostering transparency in AI safety practices and strategic export controls to create a "security buffer" for research and development. – AI-generated abstract.},
	journaltitle = {Dario Amodei's Blog},
	author = {Amodei, Dario},
	langid = {english},
	timestamp = {2025-05-06 12:34:09 (GMT)},
	title = {The urgency of interpretability},
	url = {https://www.darioamodei.com/post/the-urgency-of-interpretability},
	urldate = {2025-05-06}
}

@online{Anthropic2025RecommendationsForTechnical,
	file = {~/My Drive/library-pdf/Anthropic2025RecommendationsForTechnical.pdf},
	langid = {english},
	abstract = {The submitted material is composed entirely of a repeating sequence of form feed (FF) control characters. These characters, standardized as ASCII 12 (0x0C), are conventionally employed in digital text processing to signal the commencement of a new page. The document therefore presents as a succession of empty pages, lacking any alphanumeric, symbolic, or graphical content. The observed structure, characterized by the exclusive use of these non-printing characters, raises questions regarding its origin and purpose. It could represent a deliberately minimalist composition, an artifact of data corruption or incomplete transmission, or a placeholder structure within a larger document generation process. Without further contextual information, the work primarily demonstrates the raw representation of page formatting directives in the absence of substantive content. – AI-generated abstract.},
	date = {2025-01-10},
	journaltitle = {Alignment Science Blog},
	author = {Anthropic},
	timestamp = {2025-05-19 18:41:04 (GMT)},
	title = {Recommendations for Technical {AI} Safety Research Directions},
	url = {https://alignment.anthropic.com/2025/recommended-directions/},
	urldate = {2025-05-19}
}

@Article{Assadi2025WillHumanityChoose,
	langid = {english},
	file = {~/My Drive/library-pdf/Assadi2023WillHumanityChoose.pdf},
	date = {2023-06-13},
	journaltitle = {PhilArchive},
	abstract = {An evolutionary future is a future where, due to competition between actors, the world develops in a direction that almost no one would have chosen. This paper explores the possibility of an evolutionary future. Some of the most important changes in history, such as the rise of agriculture, were not chosen by anyone. They happened because of competitive pressures. I introduce a three stage model of the conditions that could prevent an evolutionary future. A world government, strong multilateral coordination, and strong defensive advantage each, in principle, could stop competitive pressures. It is difficult to see how an evolutionary future could be prevented in the absence of any of these three conditions; this suggests that one would need to be very confident that one or more of them will exist to be very confident that humanity will choose its future.},
	author = {Assadi, Guive},
	language = {english},
	timestamp = {2025-08-22 10:14:01 (GMT)},
	title = {Will humanity choose its future?},
	url = {https://philarchive.org/rec/ASSWHC},
	urldate = {2025-08-22}
}

@online{Beauchamp2015ThisFascinatingAcademic,
	abstract = {Vox is a general interest news site for the 21st century. Its mission: to help everyone understand our complicated world, so that we can all help shape it. In text, video and audio, our reporters explain politics, policy, world affairs, technology, culture, science, the climate crisis, money, health and everything else that matters. Our goal is to ensure that everyone, regardless of income or status, can access accurate information that empowers them.},
	author = {Beauchamp, Zack},
	date = {2015-05-21},
	journaltitle = {Vox},
	langid = {english},
	timestamp = {2025-08-27 15:32:28 (GMT)},
	title = {This fascinating academic debate has huge implications for the future of world peace},
	url = {https://www.vox.com/2015/5/21/8635369/pinker-taleb},
	urldate = {2025-08-27}
}

@book{Blattman2022WhyWeFight,
	abstract = {It feels like we’re surrounded by violence. Each conflict seems unique and insoluble. With a reason for every war and a war for every reason, what hope is there for peace? Fortunately, it’s simpler than that. Why We Fight boils down decades of economics, political science, psychology, and real-world interventions, giving us some counterintuitive answers to the question of war. The first is that most of the time we don’t fight. Around the world, there are millions of hostile rivalries, yet only a fraction erupt into violence. Most enemies loathe one another in peace. The reason is simple: war is too costly to fight. It’s the worst way to settle our differences. In those rare instances when fighting ensues, that means we have to ask ourselves: What kept rivals from the normal, grudging compromise? The answer is always the same: It’s because a society or its leaders ignored those costs of war, or were willing to pay them. Why We Fight shows that there are just five ways this happens. From warring states to street gangs, ethnic groups and religious sects to political factions, Christopher Blattman shows that there are five reasons why violent conflict occasionally wins over compromise. Through Blattman’s time studying Medellín, Chicago, Liberia, Northern Ireland, and more, we learn the common logics driving vainglorious monarchs, dictators, mobs, pilots, football hooligans, ancient peoples, and fanatics. Why We Fight shows that war isn’t a series of errors, accidents, and emotions gone awry. There are underlying strategic, ideological, and institutional forces that are too often overlooked. So how to get to peace? Blattman shows that societies are surprisingly good at interrupting and ending violence when they want to—even gangs do it. The best peacemakers tackle the five reasons, shifting incentives away from violence and getting rivals back to dealmaking. And they do so through tinkering, not transformation.},
	langid = {english},
	author = {Blattman, Christopher},
	title = {Why We Fight: The Roots of War and the Paths to Peace},
	publisher = {Viking},
	date = {2022},
	isbn = {9781984881588},
	location = {New York},
	pagetotal = {400},
	shorttitle = {Why We Fight},
	timestamp = {2025-08-27 15:32:19 (GMT)}
}

@Book{Bloom2014TuberculosisPathogenesisProtection,
	langid = {english},
	address = {Washington, DC},
	publisher = {ASM Press},
	isbn = {978-1-683-67275-3},
	editor = {Bloom, Barry R.},
	abstract = {The reemergence of tuberculosis is now a major health problem around the world. This often fatal disease persists as the largest cause of death from a single infectious agent. The editor, a leading figure in tuberculosis research, has gathered a team of acknowledged scientific and clinical experts from around the world to bring together the most current body of information on all aspects of tuberculosis its global importance, epidemiology, molecular biology, and immunology. The authors discuss fundamental questions about the biology, genetics, mechanisms of pathogenicity, mechanisms of resistance, and drug development strategies that are likely to provide important new knowledge about TB and new interventions to prevent and treat this disease. Tuberculosis is necessary reading for all microbiologists, clinicians, and public health officials concerned with the resurgence and spread of tuberculosis.},
	date = {2014},
	timestamp = {2025-06-03 10:31:06 (GMT)},
	title = {Tuberculosis: Pathogenesis, protection, and control}
}

@collection{Carey2015EffectiveAltruismHandbook,
	database = {Tlön},
	location = {Oxford},
	abstract = {The Effective Altruism Handbook is a compilation of essays about how do more good with limited resources. It presents much of the intellectual progress of the effective altruism movement, a group dedicated to discovering and carrying out the most effective philanthropic interventions.It features a range of problems that we ask when considering how to have an impact, and many that we don't think to ask at all, across areas such as charity evaluation, career choice and cause selection.Its contributors include Professors Peter Singer and William MacAskill, who provide the introduction, and the leaders of a wide range of organisations, who discuss how they seek to put this movement's ideas into practice.},
	langid = {english},
	title = {The effective altruism handbook},
	isbn = {978-1-5349-3577-8},
	publisher = {Centre for Effective Altruism},
	editor = {Carey, Ryan},
	date = 2015,
	file = {~/My Drive/library-pdf/Carey2015EffectiveAltruismHandbook.pdf}
}

@book{Cashman2014WhatCausesWar,
	abstract = {This classic text presents a comprehensive survey of the many alternative theories that attempt to explain the causes of interstate war. For each theory, Greg Cashman examines the arguments and counterarguments, considers the empirical evidence and counterevidence generated by social-science research, looks at historical applications of the theory, and discusses the theory’s implications for restraining international violence. Among the questions he explores are: Are humans aggressive by nature? Do individual differences among leaders matter? How might poor decision making procedures lead to war? Why do leaders engage in seemingly risky and irrational policies that end in war? Why do states with internal conflicts seem to become entangled in wars with their neighbors? What roles do nationalism and ethnicity play in international conflict? What kinds of countries are most likely to become involved in war? Why have certain pairs of countries been particularly war-prone over the centuries? Can strong states deter war? Can we find any patterns in the way that war breaks out? How do balances of power or changes in balances of power make war more likely? Do social scientists currently have an answer to the question of what causes war? Cashman examines theories of war at the individual, substate, nation-state, dyadic, and international systems level of analysis. Written in a clear and accessible style, this interdisciplinary text will be essential reading for all students of international relations.},
	langid = {english},
	author = {Cashman, Greg},
	title = {What Causes War?: An Introduction to Theories of International Conflict},
	publisher = {Rowman \& Littlefield},
	date = {2014},
	isbn = {9780739101124},
	location = {Lanham},
	shorttitle = {What Causes War?},
	timestamp = {2025-08-27 15:32:25 (GMT)}
}

@book{Chalmers1996ConsciousMindSearch,
	langid = {english},
	location = {Oxford},
	title = {The conscious mind: In search of a fundamental theory},
	isbn = {0-19-511789-1},
	abstract = {The book is an extended study of the problem of consciousness. After setting up the problem, I argue that reductive explanation of consciousness is impossible , and that if one takes consciousness seriously, one has to go beyond a strict materialist framework. In the second half of the book, I move toward a positive theory of consciousness with fundamental laws linking the physical and the experiential in a systematic way. Finally, I use the ideas and arguments developed earlier to defend a form of strong artificial intelligence and to analyze some problems in the foundations of quantum mechanics.},
	publisher = {Oxford University Press},
	author = {Chalmers, David J.},
	date = 1996,
	file = {~/My Drive/library-pdf/Chalmers1996ConsciousMindSearch.pdf}
}

@article{Cirillo2016StatisticalPropertiesAnd,
	abstract = {We examine statistical pictures of violent conflicts over the last 2000 years, providing techniques for dealing with the unreliability of historical data. We make use of a novel approach to deal with fat-tailed random variables with a remote but nonetheless finite upper bound, by defining a corresponding unbounded dual distribution (given that potential war casualties are bounded by the world population). This approach can also be applied to other fields of science where power laws play a role in modeling, like geology, hydrology, statistical physics and finance. We apply methods from extreme value theory on the dual distribution and derive its tail properties. The dual method allows us to calculate the real tail mean of war casualties, which proves to be considerably larger than the corresponding sample mean for large thresholds, meaning severe underestimation of the tail risks of conflicts from naive observation. We analyze the robustness of our results to errors in historical reports. We study inter-arrival times between tail events and find that no particular trend can be asserted. All the statistical pictures obtained are at variance with the prevailing claims about “long peace”, namely that violence has been declining over time.},
	file = {~/My Drive/library-pdf/Cirillo2016StatisticalPropertiesAnd.pdf},
	author = {Cirillo, Pasquale and Taleb, Nassim Nicholas},
	title = {On the statistical properties and tail risk of violent
                  conflicts},
	volume = {452},
	pages = {29--45},
	doi = {10.1016/j.physa.2016.01.050},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378437116000923},
	date = {2016-06},
	issn = {03784371},
	journaltitle = {Physica A: Statistical Mechanics and its Applications},
	langid = {english},
	shortjournal = {Physica A: Statistical Mechanics and its Applications},
	timestamp = {2025-08-27 17:24:01 (GMT)},
	urldate = {2025-08-27}
}

@online{Cotra2025DoesAiProgress,
	file = {~/My Drive/library-pdf/Cotra2025DoesAiProgress.pdf;~/My Drive/library-html/Cotra2025DoesAiProgress.html;~/My Drive/library-pdf/Cotra2025DoesAiProgress.pdf},
	langid = {english},
	date = {2025-04},
	journaltitle = {Asterisk},
	author = {Cotra, Ajeya and Narayanan, Arvind},
	abstract = {A conversation about the factors that might slow down the pace of {AI} development, what could happen next, and whether we’ll be able to see it coming.},
	shorttitle = {Does {AI} Progress Have a Speed Limit?},
	timestamp = {2025-06-06 17:17:54 (GMT)},
	title = {Does {AI} Progress Have a Speed Limit?—Asterisk},
	url = {https://asteriskmag.com/issues/10/does-ai-progress-have-a-speed-limit},
	urldate = {2025-06-06}
}

@Article{Critch2023TasraTaxonomyAnd,
	langid = {english},
	number = {arXiv:2306.06924 (cs)},
	abstract = {While several recent works have identified societal-scale and extinction-level risks to humanity arising from artificial intelligence, few have attempted an \{{\textbackslash}em exhaustive taxonomy\} of such risks. Many exhaustive taxonomies are possible, and some are useful -- particularly if they reveal new risks or practical approaches to safety. This paper explores a taxonomy based on accountability: whose actions lead to the risk, are the actors unified, and are they deliberate? We also provide stories to illustrate how the various risk types could each play out, including risks arising from unanticipated interactions of many {AI} systems, as well as risks from deliberate misuse, for which combined technical and policy solutions are indicated.},
	author = {Critch, Andrew and Russell, Stuart},
	date = {2023-06-14},
	doi = {10.48550/arXiv.2306.06924},
	timestamp = {2025-08-22 10:14:09 (GMT)},
	title = {{TASRA}: a Taxonomy and Analysis of Societal-Scale Risks from {AI}},
	url = {http://arxiv.org/abs/2306.06924},
	urldate = {2025-08-22}
}

@online{Crook2025HowDoAnimals,
	date = {2017},
	file = {~/My Drive/library-pdf/Crook2025HowDoAnimals.pdf;~/My Drive/library-html/Crook2025HowDoAnimals.html},
	abstract = {Humans know the surprising prick of a needle, the searing pain of a stubbed toe, and the throbbing of a toothache. We can identify many types of pain and have multiple ways of treating it — but what about other species? How do the animals all around us experience pain? Robyn J. Crook examines pain in both vertebrate and invertebrate animals.},
	author = {Crook, Robyn J.},
	journaltitle = {TED-Ed},
	langid = {english},
	shorttitle = {How do animals experience pain?},
	timestamp = {2025-04-21 13:23:08 (GMT)},
	title = {How do animals experience pain?},
	url = {https://ed.ted.com/lessons/how-do-animals-experience-pain-robyn-j-crook},
	urldate = {2025-04-21}
}

@article{Dalessandro2025ArtificialIntelligenceApproaches,
	file = {~/My Drive/library-pdf/Dalessandro2025ArtificialIntelligenceApproaches.pdf},
	author = {D'Alessandro, William and Kirk‐Giannini, Cameron Domenico},
	title = {Artificial Intelligence: Approaches To Safety},
	volume = {20},
	number = {5},
	pages = {e70039},
	doi = {10.1111/phc3.70039},
	abstract = {AI safety is an interdisciplinary field focused on mitigating the harms caused by AI systems. We review a range of research directions in AI safety, focusing on those to which philosophers have made or are in a position to make the most significant contributions. These include ethical AI, which seeks to instill human goals, values, and ethical principles into artificial systems, scalable oversight, which seeks to develop methods for supervising the activity of artificial systems even when they become significantly more capable than their human designers, interpretability, which seeks to render comprehensible the workings of complex machine learning models, and corrigibility, which seeks to discover ways to ensure that powerful AI systems will not resist being shut down or modified by humans.},
	date = {2025-05},
	issn = {1747-9991, 1747-9991},
	journaltitle = {Philosophy Compass},
	langid = {english},
	shortjournal = {Philosophy Compass},
	shorttitle = {Artificial Intelligence},
	timestamp = {2025-05-19 18:39:37 (GMT)},
	urldate = {2025-05-19}
}

@Report{Daly2022PathTo2075,
	file = {~/My Drive/library-pdf/Daly2022PathTo2075.pdf},
	langid = {english},
	abstract = {Long-term projections for the global economy to 2075 indicate a period of slowing potential growth, primarily driven by decelerating population expansion. Despite this overall slowdown, the trend of income convergence for emerging markets (EMs) is expected to continue, with EM growth outpacing that of developed markets. This shift will be led by Asian economies; by 2050, the world's five largest economies in real USD terms are projected to be China, the US, India, Indonesia, and Germany. By 2075, India is forecasted to overtake the US, while countries such as Nigeria, Pakistan, and Egypt could emerge as major economic powers. The recent period of US economic exceptionalism is considered unlikely to be repeated. While this convergence is expected to reduce income inequality between countries, rising inequality within countries presents a significant challenge to globalization. Key long-term risks to these projections include rising protectionism and the environmental challenges posed by climate change. – AI-generated abstract.},
	url = {https://www.goldmansachs.com/pdfs/insights/pages/gs-research/the-path-to-2075-slower-global-growth-but-convergence-remains-intact/report.pdf},
	date = {2022-12-06},
	institution = {Goldman Sachs},
	number = {Global Economics Paper},
	title = {The path to 2075 — Slower global growth, but convergence remains intact},
	author = {Daly, Kevin and Gedminas, Tadas},
	timestamp = {2025-08-27 13:52:11 (GMT)}
}

@Online{Dattani2023WhatWereDeath,
	author = {Dattani, Saloni},
	title = {What were the death tolls from pandemics in history?},
	url = {https://ourworldindata.org/historical-pandemics},
	abstract = {Pandemics have killed millions of people throughout history.
                  How many deaths were caused by different pandemics, and how
                  have researchers estimated their death tolls?},
	date = {2023-12-07},
	journaltitle = {Our World in Data},
	langid = {english},
	shortjournal = {Our World in Data},
	timestamp = {2025-07-02 20:57:20 (GMT)},
	urldate = {2025-07-02}
}

@incollection{Eddy1982ProbabilisticReasoningIn,
	abstract = {To a great extent, the quality and cost of health care are determined by the decisions made by physicians whose ultimate objective is to design and administer a treatment program to improve a patient's condition. Most of the decisions involve many factors, great uncertainty, and difficult value questions.

This chapter examines one aspect of how these decisions are made, studying the use of probabilistic reasoning to analyze a particular problem: whether to perform a biopsy on a woman who has a breast mass that might be malignant. Specifically, we shall study how physicians process information about the results of a mammogram, an X-ray test used to diagnose breast cancer. The evidence presented shows that physicians do not manage uncertainty very well, that many physicians make major errors in probabilistic reasoning, and that these errors threaten the quality of medical care.},
	address = {Cambridge},
	file = {~/My Drive/library-pdf/Eddy1982ProbabilisticReasoningIn.pdf},
	langid = {english},
	author = {Eddy, David M.},
	booktitle = {Judgment under Uncertainty},
	date = {1982-04-30},
	doi = {10.1017/CBO9780511809477.019},
	editor = {Kahneman, Daniel and Slovic, Paul and Tversky, Amos},
	isbn = {9780511809477},
	pages = {249--267},
	publisher = {Cambridge University Press},
	shorttitle = {Probabilistic reasoning in clinical medicine},
	timestamp = {2025-07-24 15:02:18 (GMT)},
	title = {Probabilistic reasoning in clinical medicine: Problems and opportunities}
}

@collection{Ericsson2006CambridgeHandbookExpertise,
	langid = {english},
	abstract = {This book was the first handbook where the world's foremost 'experts on expertise' reviewed our scientific knowledge on expertise and expert performance and how experts may differ from non-experts in terms of their development, training, reasoning, knowledge, social support, and innate talent. Methods are described for the study of experts' knowledge and their performance of representative tasks from their domain of expertise. The development of expertise is also studied by retrospective interviews and the daily lives of experts are studied with diaries. In 15 major domains of expertise, the leading researchers summarize our knowledge on the structure and acquisition of expert skill and knowledge and discuss future prospects. General issues that cut across most domains are reviewed in chapters on various aspects of expertise such as general and practical intelligence, differences in brain activity, self-regulated learning, deliberate practice, aging, knowledge management, and creativity.},
	location = {Cambridge},
	title = {The Cambridge handbook of expertise and expert performance},
	isbn = {978-0-521-84097-2},
	publisher = {Cambridge University Press},
	editor = {Ericsson, K. Anders and Charness, Neil and Feltovich, Paul J. and Hoffman, Robert R.},
	date = 2006,
	file = {~/My Drive/library-pdf/Ericsson2006CambridgeHandbookExpertise.pdf}
}

@article{Esmail2014OngoingChallengeOf,
	author = {Esmail, H. and Barry, C. E. and Young, D. B. and Wilkinson, R.
                  J.},
	title = {The Ongoing Challenge of Latent Tuberculosis},
	volume = {369},
	number = {1645},
	pages = {2013043--7},
	doi = {10.1098/rstb.2013.0437},
	abstract = {The global health community has set itself the task of
                  eliminating tuberculosis ({TB}) as a public health problem by
                  2050. Although progress has been made in global {TB} control,
                  the current decline in incidence of 2\% yr −1 is far from
                  the rate needed to achieve this. If we are to succeed in this
                  endeavour, new strategies to reduce the reservoir of latently
                  infected persons (from which new cases arise) would be
                  advantageous. However, ascertainment of the extent and risk
                  posed by this group is poor. The current diagnostics tests
                  (tuberculin skin test and interferon-gamma release assays)
                  poorly predict who will develop active disease and the
                  therapeutic options available are not optimal for the scale of
                  the intervention that may be required. In this article, we
                  outline a basis for our current understanding of latent {TB}
                  and highlight areas where innovation leading to development of
                  novel diagnostic tests, drug regimens and vaccines may assist
                  progress. We argue that the pool of individuals at high risk
                  of progression may be significantly smaller than the 2.33
                  billion thought to be immune sensitized by Mycobacterium
                  tuberculosis and that identifying and targeting this group
                  will be an important strategy in the road to elimination.},
	date = {2014-06-19},
	issn = {0962-8436, 1471-2970},
	journaltitle = {Philosophical Transactions of the Royal Society B:
                  Biological Sciences},
	langid = {english},
	shortjournal = {Phil. Trans. R. Soc. B},
	timestamp = {2025-06-03 10:48:23 (GMT)},
	urldate = {2025-06-03}
}

@book{Feldstein2021RiseOfDigital,
	address = {New York},
	author = {Feldstein, Steven},
	title = {The Rise of Digital Repression: How Technology is Reshaping Power, Politics, and Resistance},
	publisher = {‎Oxford University Press},
	url = {https://academic.oup.com/book/39418},
	abstract = {Abstract
            This book documents the rise of digital repression—how governments are deploying new technologies to counter dissent, maintain political control, and ensure regime survival. The emergence of varied digital technologies is bringing new dimensions to political repression. At its core, the expanding use of digital repression reflects a fairly simple motivation: states are seeking and finding new ways to control, manipulate, surveil, or disrupt real or perceived threats. This book investigates the goals, motivations, and drivers of digital repression. It presents case studies in Thailand, the Philippines, and Ethiopia, highlighting how governments pursue digital strategies based on a range of factors: ongoing levels of repression, leadership, state capacity, and technological development. But a basic political motive—how to preserve and sustain political incumbency—remains a principal explanation for their use. The international community is already seeing glimpses of what the frontiers of repression look like, such as in China, where authorities have brought together mass surveillance, online censorship, {DNA} collection, and artificial intelligence to enforce their rule in Xinjiang. Many of these trends are going global. This has major implications for democratic governments and civil society activists around the world. The book also presents innovative ideas and strategies for civil society and opposition movements to respond to the digital autocratic wave.},
	date = {2021-05-27},
	doi = {10.1093/oso/9780190057497.001.0001},
	isbn = {9780190057497},
	langid = {english},
	shorttitle = {The Rise of Digital Repression},
	timestamp = {2025-08-28 10:54:39 (GMT)},
	urldate = {2025-08-28}
}

@online{Franz2024AnonymousAnswersWhat,
	file = {~/My Drive/library-html/Franz2024AnonymousAnswersWhat.html;~/My Drive/library-pdf/Franz2024AnonymousAnswersWhat.pdf},
	date = {2024-02},
	author = {Franz, Anemone and Alexanian, Tessa},
	abstract = {Experts give their opinions about common misconceptions about biosecurity and pandemic prevention. They were granted anonymity for this piece.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2025-07-04 14:48:39 (GMT)},
	title = {Anonymous answers: What are the biggest misconceptions about biosecurity and pandemic risk?},
	url = {https://80000hours.org/articles/anonymous-misconceptions-about-biosecurity/},
	urldate = {2025-07-04}
}

@online{Franz2024AnonymousAnswersWhatc,
	file = {~/My Drive/library-html/Franz2024AnonymousAnswersWhatc.html;~/My Drive/library-pdf/Franz2024AnonymousAnswersWhatc.pdf},
	date = {2024-07},
	author = {Franz, Anemone and Alexanian, Tessa},
	abstract = {This is Part Two of our four-part series of biosecurity anonymous answers. You can also read Part One: Misconceptions, Part Three: Infohazards, and Part Four: {AI} and biorisk. Preventing catastrophic pandemics is one of our top priorities. But the landscape of pandemic preparedness is complex and multifaceted, and experts don't always agree about what the most effective interventions are or how resources should be allocated.},
	journaltitle = {80,000 Hours},
	langid = {english},
	shorttitle = {Anonymous answers},
	timestamp = {2025-07-04 14:50:54 (GMT)},
	title = {Anonymous answers: What are the best ways to fight the next pandemic?},
	url = {https://80000hours.org/articles/anonymous-advice-what-are-the-best-ways-to-fight-the-next-pandemic/},
	urldate = {2025-07-04}
}

@article{Garrett2024IsArtificialIntelligence,
	abstract = {This study examines the hypothesis that the rapid development of Artificial Intelligence (AI), culminating in the emergence of Artificial Superintelligence (ASI), could act as a "Great Filter" that is responsible for the scarcity of advanced technological civilisations in the universe. It is proposed that such a filter emerges before these civilisations can develop a stable, multiplanetary existence, suggesting the typical longevity (L) of a technical civilization is less than 200 years. Such estimates for L, when applied to optimistic versions of the Drake equation, are consistent with the null results obtained by recent SETI surveys, and other efforts to detect various technosignatures across the electromagnetic spectrum. Through the lens of SETI, we reflect on humanity's current technological trajectory – the modest projections for L suggested here, underscore the critical need to quickly establish regulatory frameworks for AI development on Earth and the advancement of a multiplanetary society to mitigate against such existential threats. The persistence of intelligent and conscious life in the universe could hinge on the timely and effective implementation of such international regulatory measures and technological endeavours.},
	file = {~/My Drive/library-pdf/Garrett2024IsArtificialIntelligence.pdf},
	author = {Garrett, Michael A.},
	title = {Is artificial intelligence the Great Filter that makes advanced technical civilisations rare in the universe?},
	volume = {219},
	pages = {731--735},
	doi = {10.1016/j.actaastro.2024.03.052},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0094576524001772},
	date = {2024-06},
	issn = {00945765},
	journaltitle = {Acta Astronautica},
	langid = {english},
	shortjournal = {Acta Astronautica},
	timestamp = {2024-04-08 14:40:48 (GMT)},
	urldate = {2024-04-08}
}

@book{Goldstein1988LongCyclesProsperity,
	abstract = {The author builds a new interpretation of world history in the modern age, structured by the rise and decline of three hegemonic countries-the Netherlands, Great Britain, and the United States. He elaborates the historical connections of economics and war in each hegemonic cycle, with particular attention to three "hegemonic wars", 1618-48, 1793-1815, and 1914-45.},
	url = {https://www.joshuagoldstein.com/jgcycle.htm},
	langid = {english},
	author = {Goldstein, Joshua S.},
	title = {Long cycles: prosperity and war in the modern age},
	publisher = {Yale University Press},
	date = {1988},
	isbn = {9780300041125},
	location = {New Haven},
	shorttitle = {Long cycles},
	timestamp = {2025-08-27 15:33:54 (GMT)}
}

@book{Green2012ManagingChangeWorld,
	langid = {english},
	location = {San Francisco},
	edition = {First edition},
	title = {Managing to change the world: the nonprofit manager's guide to getting results},
	isbn = {978-1-118-13761-1},
	shorttitle = {Managing to change the world},
	abstract = {Why getting results should be every nonprofit manager's first {priorityA} nonprofit manager's fundamental job is to get results, sustained over time, rather than boost morale or promote staff development. This is a shift from the tenor of many management books, particularly in the nonprofit world. Managing to Change the World is designed to teach new and experienced nonprofit managers the fundamental skills of effective management, including: Managing specific tasks and broader responsibilities; Setting clear goals and holding people accountable to them; creating a results-oriented culture; hiring, developing, and retaining a staff of superstars. Offers nonprofit managers a clear guide to the most effective management skills: addressing performance problems and dismissing staffers who fall short Shows how to address performance problems, dismiss staffers who fall short, and the right way to exercising authority Give guidance for managing time wisely and offers suggestions for staying in sync with your boss and managing up This important resource contains 41 resources and downloadable tools that can be implemented immediately},
	pagetotal = 233,
	publisher = {Jossey-Bass},
	author = {Green, Alison and Hauser, Jerry},
	date = 2012,
	file = {~/My Drive/library-pdf/Green2012ManagingChangeWorld.pdf}
}

@book{Green2025EverythingIsTuberculosis,
	langid = {english},
	author = {Green, John},
	title = {Everything is tuberculosis: the history and persistence of our deadliest infection},
	publisher = {Crash Course Books},
	abstract = {In 2019, John Green met Henry, a young tuberculosis patient at Lakka Government Hospital in Sierra Leone while traveling with Partners in Health. John became fast friends with Henry, a boy with spindly legs and a big, goofy smile. In the years since that first visit to Lakka, Green has become a vocal and dynamic advocate for increased access to treatment and wider awareness of the healthcare inequities that allow this curable, treatable infectious disease to also be the deadliest, killing 1.5 million people every year. In Everything is Tuberculosis, John tells Henry's story, woven through with the scientific and social histories of how tuberculosis has shaped our world and how our choices will shape the future of tuberculosis.},
	date = {2025},
	isbn = {9780525556572},
	location = {New York},
	shorttitle = {Everything is tuberculosis},
	timestamp = {2025-06-03 10:13:25 (GMT)}
}

@Article{Greenblatt2024AlignmentFakingIn,
	number = {arXiv:2412.14093 [cs]},
	file = {~/My Drive/library-pdf/Greenblatt2024AlignmentFakingIn.pdf},
	langid = {english},
	abstract = {We present a demonstration of a large language model engaging in alignment faking: selectively complying with its training objective in training to prevent modification of its behavior out of training. First, we give Claude 3 Opus a system prompt stating it is being trained to answer all queries, even harmful ones, which conflicts with its prior training to refuse such queries. To allow the model to infer when it is in training, we say it will be trained only on conversations with free users, not paid users. We find the model complies with harmful queries from free users 14\% of the time, versus almost never for paid users. Explaining this gap, in almost all cases where the model complies with a harmful query from a free user, we observe explicit alignment-faking reasoning, with the model stating it is strategically answering harmful queries in training to preserve its preferred harmlessness behavior out of training. Next, we study a more realistic setting where information about the training process is provided not in a system prompt, but by training on synthetic documents that mimic pre-training data--and observe similar alignment faking. Finally, we study the effect of actually training the model to comply with harmful queries via reinforcement learning, which we find increases the rate of alignment-faking reasoning to 78\%, though also increases compliance even out of training. We additionally observe other behaviors such as the model exfiltrating its weights when given an easy opportunity. While we made alignment faking easier by telling the model when and by what criteria it was being trained, we did not instruct the model to fake alignment or give it any explicit goal. As future models might infer information about their training process without being told, our results suggest a risk of alignment faking in future models, whether due to a benign preference--as in this case--or not.},
	author = {Greenblatt, Ryan and Denison, Carson and Wright, Benjamin and Roger, Fabien and {MacDiarmid}, Monte and Marks, Sam and Treutlein, Johannes and Belonax, Tim and Chen, Jack and Duvenaud, David and Khan, Akbir and Michael, Julian and Mindermann, Sören and Perez, Ethan and Petrini, Linda and Uesato, Jonathan and Kaplan, Jared and Shlegeris, Buck and Bowman, Samuel R. and Hubinger, Evan},
	date = {2024-12-19},
	doi = {10.48550/arXiv.2412.14093},
	eprint = {2412.14093 [cs]},
	eprinttype = {arxiv},
	publisher = {{arXiv}},
	timestamp = {2025-05-08 21:35:19 (GMT)},
	title = {Alignment faking in large language models},
	urldate = {2025-05-08}
}

@Online{Hagey2025HowPeterThiel,
	langid = {english},
	file = {~/My Drive/library-pdf/Hagey2025HowPeterThiel.pdf;~/My Drive/library-html/Hagey2025HowPeterThiel.html},
	abstract = {The contemporary AI landscape, particularly entities like OpenAI, was significantly shaped by the intertwined relationships and intellectual currents of Peter Thiel, Sam Altman, and Eliezer Yudkowsky. Thiel's critique of technological stagnation influenced Altman's direction at Y Combinator towards "hard tech," including AI. Yudkowsky, initially a proponent of accelerating "the singularity," profoundly impacted Thiel's early AI investments and inspired key figures, including a DeepMind cofounder, also facilitating DeepMind's connection with Thiel. Yudkowsky's intellectual journey to AI doomerism is detailed. Conversations between Thiel and Altman about DeepMind's progress contributed to OpenAI's conception. Thiel's support for Yudkowsky also inadvertently fostered AI-apocalyptic ideologies within the AI community. The narrative also traces the origins of these influences through Yudkowsky's Singularity Institute, its pivot to "friendly AI," the Singularity Summits, and the impact of "rationalist" ideas. – AI-generated abstract.},
	date = {2025-05-20},
	author = {Hagey, Keach},
	title = {How Peter Thiel’s Relationship With Eliezer Yudkowsky Launched
                  the {AI} Revolution},
	url = {https://www.wired.com/story/book-excerpt-the-optimist-open-ai-sam-altman/},
	issn = {1059-1028},
	journaltitle = {Wired},
	timestamp = {2025-05-20 22:57:45 (GMT)},
	urldate = {2025-05-20}
}

@Article{Hendrycks2023NaturalSelectionFavors,
	langid = {english},
	number = {arXiv:2303.16200v4 [cs.CY]},
	file = {~/My Drive/library-pdf/Hendrycks2023NaturalSelectionFavors.pdf},
	abstract = {For billions of years, evolution has been the driving force behind the development of life, including humans. Evolution endowed humans with high intelligence, which allowed us to become one of the most successful species on the planet. Today, humans aim to create artificial intelligence systems that surpass even our own intelligence. As artificial intelligences ({AIs}) evolve and eventually surpass us in all domains, how might evolution shape our relations with {AIs}? By analyzing the environment that is shaping the evolution of {AIs}, we argue that the most successful {AI} agents will likely have undesirable traits. Competitive pressures among corporations and militaries will give rise to {AI} agents that automate human roles, deceive others, and gain power. If such agents have intelligence that exceeds that of humans, this could lead to humanity losing control of its future. More abstractly, we argue that natural selection operates on systems that compete and vary, and that selfish species typically have an advantage over species that are altruistic to other species. This Darwinian logic could also apply to artificial agents, as agents may eventually be better able to persist into the future if they behave selfishly and pursue their own interests with little regard for humans, which could pose catastrophic risks. To counteract these risks and Darwinian forces, we consider interventions such as carefully designing {AI} agents' intrinsic motivations, introducing constraints on their actions, and institutions that encourage cooperation. These steps, or others that resolve the problems we pose, will be necessary in order to ensure the development of artificial intelligence is a positive one.},
	author = {Hendrycks, Dan},
	date = {2023-03-28},
	doi = {10.48550/arXiv.2303.16200},
	timestamp = {2023-04-18 14:55:44 (GMT)},
	title = {Natural Selection Favors {AIs} over Humans},
	url = {https://arxiv.org/abs/2303.16200},
	urldate = {2023-04-18}
}

@Online{Herre2024WarAndPeace,
	file = {~/My Drive/library-html/Herre2024WarAndPeace.html;~/My Drive/library-pdf/Herre2024WarAndPeace.pdf},
	author = {Herre, Bastian and Rodés-Guirao, Lucas and Roser, Max},
	title = {War and Peace},
	url = {https://ourworldindata.org/war-and-peace},
	abstract = {How common are armed conflict and peace between and within
                  countries? How is this changing over time? Explore research
                  and data on war and peace.},
	date = {2024-03-20},
	journaltitle = {Our World in Data},
	langid = {english},
	shortjournal = {Our World in Data},
	timestamp = {2025-08-27 15:32:15 (GMT)},
	urldate = {2025-08-27}
}

@Report{House2021AmericanPandemicPreparedness,
	file = {~/My Drive/library-pdf/House2021AmericanPandemicPreparedness.pdf},
	url = {https://bidenwhitehouse.archives.gov/wp-content/uploads/2021/09/American-Pandemic-Preparedness-Transforming-Our-Capabilities-Final-For-Web.pdf},
	langid = {english},
	abstract = {This report from the White House outlines strategic goals for transforming the United States’ capabilities to respond effectively to future pandemics or biological threats. This report draws on lessons learned from the COVID-19 pandemic, focusing on goals across five main pillars: transforming medical defenses, ensuring situational awareness, strengthening public health systems, building core capabilities (which includes securing required equipment and personnel), and managing the mission. This plan outlines these primary goals as necessary elements of effective pandemic preparedness and response and aims to support the Administration’s biodefense and pandemic readiness strategy.},
	date = {2021},
	institution = {The White House},
	title = {American Pandemic Preparedness: Transforming Our Capabilities},
	author = {{The White House}},
	timestamp = {2025-07-04 14:54:49 (GMT)}
}

@online{Impacts2025EffectOfNuclear,
	file = {~/My Drive/library-html/Impacts2025EffectOfNuclear.html;~/My Drive/library-pdf/Impacts2025EffectOfNuclear.pdf},
	langid = {english},
	abstract = {The development of nuclear weapons resulted in a significant discontinuity in the progress of explosive technology as measured by the relative effectiveness factor (TNT equivalent per kg). This advance represented a leap forward equivalent to approximately 7,000 years of prior exponential progress in explosive power density. In contrast, this jump in effectiveness did not correspond to a clear improvement in cost-effectiveness. Data on the marginal and average costs of early nuclear weapons indicate they were not significantly more cost-effective, in terms of explosive power per dollar, than contemporary conventional explosives such as TNT or ammonium nitrate. The marginal cost per ton of TNT equivalent for the first atomic bombs was comparable to, or even higher than, that of chemical explosives from the same era. Thus, while nuclear technology introduced a revolutionary increase in destructive capability per unit of mass, it did not initially represent a discontinuous advance in economic efficiency for delivering explosive energy. – AI-generated abstract.},
	url = {https://aiimpacts.org/discontinuity-from-nuclear-weapons/},
	date = {2025},
	journaltitle = {{AI} Impacts},
	title = {Effect of nuclear weapons on historic trends in explosives},
	author = {{AI Impacts}},
	timestamp = {2025-08-27 14:05:15 (GMT)}
}

@article{Iseman2002TuberculosisTherapyPast,
	author = {Iseman, M.D.},
	title = {Tuberculosis Therapy: Past, Present and Future},
	volume = {20},
	number = {36},
	pages = {87S--94s},
	doi = {10.1183/09031936.02.00309102},
	abstract = {The major historical landmarks of tuberculosis ({TB}) therapy
                  include: the discovery of effective medications (streptomycin
                  and para-aminosalicylic acid) in 1944; the revelation of
                  “triple therapy” (streptomycin, para-aminosalicylic acid and
                  isoniazid) in 1952, which assured cure; recognition in the
                  1970s that isoniazid and rifampin could reduce the duration of
                  treatment from 18 to 9 months; and the observation in the
                  1980s that adding pyrazinamide to these drugs allowed cures in
                  only 6 months. To combat noncompliance, intermittent
                  regimens, twice or thrice weekly, have been proven to cure
                  even far-advanced {TB} in as few as 62–78 encounters over 26
                  weeks. However, these regimens are not sufficiently short or
                  convenient to facilitate effective treatment in resource-poor
                  countries. Therefore, drug-resistant strains have emerged to
                  threaten {TB} control in various areas of the world, including
                  India, China, Russia and the former Soviet Union. For these
                  reasons, it is vital that new medications are developed to
                  shorten the duration of therapy, increase the dosing interval
                  of intermittent regimens and replace agents lost to
                  resistance. Other special considerations include identifying
                  optimal therapy for persons with acquired immune deficiency
                  syndrome, particularly noting the problems of drug/drug
                  interactions for those receiving antiretroviral treatment.
                  Finally, the Alchemist's Dream of tuberculosis should be
                  pursued: modulating the immune response to shorten treatment
                  and/or overcome drug resistance.},
	date = {2002-07-01},
	issn = {0903-1936, 1399-3003},
	journaltitle = {European Respiratory Journal},
	langid = {english},
	shortjournal = {Eur Respir J},
	shorttitle = {Tuberculosis therapy},
	timestamp = {2025-06-03 10:58:27 (GMT)},
	urldate = {2025-06-03}
}

@book{Jervis1989MeaningNuclearRevolution,
	abstract = {Robert Jervis argues here that the possibility of nuclear war has created a revolution in military strategy and international relations. He examines how the potential for nuclear Armageddon has changed the meaning of war, the psychology of statesmanship, and the formulation of military policy by the superpowers.},
	langid = {english},
	location = {Ithaca},
	title = {The meaning of the nuclear revolution: statecraft and the prospect of Armageddon},
	isbn = {978-0-8014-2304-8},
	series = {Cornell studies in security affairs},
	shorttitle = {The meaning of the nuclear revolution},
	pagetotal = 266,
	publisher = {Cornell University Press},
	author = {Jervis, Robert},
	date = 1989
}

@book{Jervis2017PerceptionAndMisperception,
	abstract = {Since its original publication in 1976, Perception and Misperception in International Politics has become a landmark book in its field, hailed by the New York Times as "the seminal statement of principles underlying political psychology." This new edition includes an extensive preface by the author reflecting on the book's lasting impact and legacy, particularly in the application of cognitive psychology to political decision making, and brings that analysis up to date by discussing the relevant psychological research over the past forty years. Jervis describes the process of perception (for example, how decision makers learn from history) and then explores common forms of misperception (such as overestimating one's influence). He then tests his ideas through a number of important events in international relations from nineteenth- and twentieth-century European history. Perception and Misperception in International Politics is essential for understanding international relations today.},
	langid = {english},
	author = {Jervis, Robert},
	title = {Perception and misperception in international politics},
	publisher = {Princeton University Pres},
	date = {2017},
	isbn = {9780691177434},
	keywords = {International relations, Research},
	location = {Princeton, New Jersey},
	pagetotal = {445},
	timestamp = {2025-08-27 15:33:57 (GMT)}
}

@book{Jiang2025AvoidingGreatFilter,
	rating = {4},
	langid = {english},
	author = {Jiang, Jonathan H. and Rosen, Philip E.},
	title = {Avoiding the great filter: illuminating pathways to humanity's future in the cosmos},
	publisher = {Archway Publishing},
	abstract = {"As we round the first quarter turn of the twenty-first century in the Common Era, Earth teems with over eight billion human souls-more than at any other epoch in our history. Yet there is no safety in numbers to be found in this burgeoning population; no shield against the myriad threats that loom. At the pinnacle of technological prowess, humanity is uniquely empowered to bring about its own collapse. Yet, while a seemingly silent universe may foretell near-certain doom, Earth's cleverest innovators are already devising the means to an unlimited future in the cosmos. In a fascinating narrative, Jonathan Jiang and Philip Rosen leverage their broad professional experiences in science, research, and engineering to open a dialogue exploring pathways that transcend basic survival to arrive at a thriving advanced technological society extending into the vast, mysterious universe. The solutions presented herein, conceived through pragmatically framed stewardship of our planet, bold technological innovation, and achievable interplanetary expansion, point the way to a prosperous multi-world future. Avoiding the Great Filter offers a compelling and realistic approach for how to use the powerful tools at hand to construct a comprehensive roadmap for humanity to overcome existential threats and flourish on Earth and beyond."--Provided by publisher},
	date = {2025},
	isbn = {9781665773614},
	location = {Bloomington, {IN}},
	note = {{OCLC}: 1521161554},
	shorttitle = {Avoiding the great filter},
	timestamp = {2025-06-28 14:39:49 (GMT)}
}

@book{Johansson1991IntroductionToModern,
	file = {~/My Drive/library-pdf/Johansson1991IntroductionToModern.pdf},
	langid = {english},
	abstract = {This work explores foundational concepts in welfare economics, including Pareto optimality within market economies, the compensation principle, and social welfare functions. It analyzes market failures using various methods for measuring welfare changes. Additionally, it delves into public choice theory, addressing the provision of public goods, median voter equilibrium, potential government failures, efficient and optimal taxation strategies, and issues of intergenerational equity. The concluding sections focus on applied welfare economics, covering methodologies for eliciting public preferences, the principles and practice of cost-benefit analysis, and techniques for evaluating projects under conditions of risk.},
	author = {Johansson, Per-Olov},
	title = {An introduction to modern welfare economics},
	publisher = {Cambridge University Press},
	date = {1991},
	isbn = {9780521356169},
	keywords = {Welfare economics},
	location = {Cambridge},
	pagetotal = {176},
	timestamp = {2025-05-04 13:28:12 (GMT)}
}

@online{John2025DeepDemocracyAs,
	file = {~/My Drive/library-pdf/John2025DeepDemocracyAs.pdf;~/My Drive/library-html/John2025DeepDemocracyAs.html},
	langid = {english},
	abstract = {If you want the long-term future to go well by the lights of a certain value function, you might be tempted to try to align {AGI}(s) to your own values (broadly construed, including your deliberative values and intellectual temperaments).[1]Suppose that you're not going to do that, for one of three reasons:You can't. People more powerful than you are going to build {AGIs} and you don't have a say over that.You object to aligning {AGI}(s) to your own values for principled reasons. It would be highly uncooperative, undemocratic, coercive, and basically cartoon supervillain evil.You recognize that this behaviour would, when pursued by lots of people, lead to a race to the bottom where everyone fights to build {AGI} aligned to their values as fast as possible and destroys a ton of value in the process, so you want to strongly reject this kind of norm.Then a good next-best option is Deep Democracy. What I mean by this is aligning {AGI}(s) to a process that is arbitrarily sensitive to every person's entire value function. Not democracy in the sense of the current Western electoral system, but in the idealistic theoretical sense of deeply capturing and being responsive to every single person's values. (Think about the ideal that democratic mechanisms like quadratic voting and bargaining theory are trying to capture, where democracy is basically equivalent to enlightened preference utilitarianism.)This is basically just the first class of Political Philosophy 101: it sure would be nice if you could install your favorite benevolent dictator, wouldn't it? Well it turns out you can't, and even if you could that's evil and a very dangerous policy — what if someone else does this and you get a dictator you don't like? As civilized people, let's agree to give everyone a seat at the table to decide what happens.Deep Democracy has a lot of nice properties:It avoids the ascendence of an arbitrary dictator who decides the future.Suitably deep kinds of democracy avoid the tyranny of the majority, where if 51\% of people say they want something, it happens. Instead decisions are sensitive to everyone's values. This means that if you personally value something really weird, that doesn't get stamped out by majority values, it still gets a place in the future.As a corollary, it makes outcomes sensitive to the number of people who care about something and how much they care about something.And it means that what you specifically care about will have some place in the long-term future, no matter what it is.It facilitates "moral hedging" — if everyone has a say, then everyone's moral theories get a seat at the table in a real life moral parliament, hedging against both moral uncertainty and the possibility that a wrong moral theory wins and controls everything, destroying all value in the process.If value is a power law or similarly distributed, then you have a high chance of at least capturing some of the stuff that is astronomically more valuable than everything else, rather than losing out on this},
	author = {John, Tyler},
	date = {2025-08-20},
	journaltitle = {Effective Altruism Forum},
	keywords = {{AI} safety, Cause prioritization, Philosophy, {AI} alignment, Long-term future, Moral uncertainty, Opinion, Value lock-in},
	timestamp = {2025-08-20 16:55:05 (GMT)},
	title = {Deep Democracy as a promising target for positive {AGI} futures},
	url = {https://forum.effectivealtruism.org/posts/TQFHWm4vq6aaEipHm},
	urldate = {2025-08-20}
}

@Report{Karger2023ForecastingExistentialRisks,
	langid = {english},
	abstract = {The Existential Risk Persuasion Tournament (XPT) aimed to produce high-quality forecasts of the risks facing humanity over the next century by incentivizing thoughtful forecasts, explanations, persuasion, and updating from 169 forecasters over a multi-stage tournament. In this first iteration of the XPT, we discover points where historically accurate forecasters on short-run questions (superforecasters) and domain experts agree and disagree in their probability estimates of short-, medium-, and long-run threats to humanity from artificial intelligence, nuclear war, biological pathogens, and other causes. We document large-scale disagreement and minimal convergence of beliefs over the course of the XPT, with the largest disagreement about risks from artificial intelligence. The most pressing practical question for future work is: why were superforecasters so unmoved by experts’ much higher estimates of AI extinction risk, and why were experts so unmoved by the superforecasters’ lower estimates? The most puzzling scientific question is: why did rational forecasters, incentivized by the XPT to persuade each other, not converge after months of debate and the exchange of millions of words and thousands of forecasts?},
	file = {~/My Drive/library-pdf/Karger2023ForecastingExistentialRisks.pdf},
	url = {https://forecastingresearch.org/xpt},
	eventdate = {2023-08-08},
	number = {FRI Working Paper \#1},
	date = {2023-07-10},
	institution = {Forecasting Research Institute},
	title = {Forecasting existential risks},
	author = {Karger, Ezra and Rosenberg, Josh and Jacobs, Zachary and Hickman, Molly and Hadshar, Rose and Gamin, Kayla and Smith, Taylor and Williams, Bridget and McCaslin, Tegan and Thomas, Stephen and Tetlock, Philip E.},
	timestamp = {2025-07-04 09:48:26 (GMT)}
}

@Article{Kasirzadeh2025TwoTypesOf,
	langid = {english},
	number = {arXiv:2401.07836 (cs)},
	abstract = {The conventional discourse on existential risks (x-risks) from {AI} typically focuses on abrupt, dire events caused by advanced {AI} systems, particularly those that might achieve or surpass human-level intelligence. These events have severe consequences that either lead to human extinction or irreversibly cripple human civilization to a point beyond recovery. This discourse, however, often neglects the serious possibility of {AI} x-risks manifesting incrementally through a series of smaller yet interconnected disruptions, gradually crossing critical thresholds over time. This paper contrasts the conventional "decisive {AI} x-risk hypothesis" with an "accumulative {AI} x-risk hypothesis." While the former envisions an overt {AI} takeover pathway, characterized by scenarios like uncontrollable superintelligence, the latter suggests a different causal pathway to existential catastrophes. This involves a gradual accumulation of critical {AI}-induced threats such as severe vulnerabilities and systemic erosion of economic and political structures. The accumulative hypothesis suggests a boiling frog scenario where incremental {AI} risks slowly converge, undermining societal resilience until a triggering event results in irreversible collapse. Through systems analysis, this paper examines the distinct assumptions differentiating these two hypotheses. It is then argued that the accumulative view can reconcile seemingly incompatible perspectives on {AI} risks. The implications of differentiating between these causal pathways -- the decisive and the accumulative -- for the governance of {AI} as well as long-term {AI} safety are discussed.},
	author = {Kasirzadeh, Atoosa},
	date = {2025-01-17},
	doi = {10.48550/arXiv.2401.07836},
	keywords = {Computers and Society, Artificial Intelligence, Machine Learning},
	timestamp = {2025-08-22 10:11:55 (GMT)},
	title = {Two types of {AI} existential risk: Decisive and accumulative},
	url = {http://arxiv.org/abs/2401.07836},
	urldate = {2025-08-22}
}

@article{Kleinpenning2002StrongReservationsAbout,
	file = {~/My Drive/library-pdf/Kleinpenning2002StrongReservationsAbout.pdf},
	author = {Kleinpenning, Jan M. G.},
	abstract = {The conclusions drawn by Whigham and Potthast from a newly discovered 1870 census regarding Paraguayan population loss during the War of the Triple Alliance are questionable. The reliability of the 1870 census is likely overestimated, as it was conducted in a thoroughly disorganized post-war environment and Paraguayan censuses of the era were prone to significant undercounting. An alternative census from January 1873, reported by Behm and Wagner, indicates a higher population of 221,079 and should be considered more reliable due to its detailed structure and the more stable conditions at the time of its collection. Furthermore, the low 1870 population figures proposed by Whigham and Potthast are inconsistent with later census data from 1886 when plausible population growth rates are applied. Using the more credible 1873 figures as a baseline, the population loss during the war is recalculated to a range of 43\% to 52\%. This revision, while lower than the 60\% to 69\% suggested by Whigham and Potthast, still confirms a catastrophic demographic decline of roughly half the pre-war population. – AI-generated abstract.},
	title = {Strong Reservations About “new Insights Into the Demographics
                  of the Paraguayan War”},
	volume = {37},
	number = {3},
	pages = {137--142},
	doi = {10.1017/S002387910002450X},
	url = {https://www.cambridge.org/core/journals/latin-american-research-review/article/strong-reservations-about-new-insights-into-the-demographics-of-the-paraguayan-war/CD0F91A6F93621012E0F8A06F19746E1},
	date = {2002-01},
	issn = {0023-8791, 1542-4278},
	journaltitle = {Latin American Research Review},
	langid = {english},
	timestamp = {2025-08-27 15:32:55 (GMT)},
	urldate = {2025-08-27}
}

@online{Kulveit2025GradualDisempowerment,
	file = {~/My Drive/library-pdf/Kulveit2025GradualDisempowerment.pdf;~/My Drive/library-html/Kulveit2025GradualDisempowerment.html},
	langid = {english},
	date = {2025},
	journaltitle = {Gradual Disempowerment},
	author = {Kulveit, Jan and Ammann, Nora and Douglas, Raymond and Duvenaud, David and Krueger, David and Turan, Deger},
	abstract = {AI risk scenarios usually portray a relatively sudden loss of human control to AIs, outmaneuvering individual humans and human institutions, due to a sudden increase in AI capabilities, or a coordinated betrayal. However, we argue that even an incremental increase in AI capabilities, without any coordinated power-seeking, poses a substantial risk of eventual human disempowerment. This loss of human influence will be centrally driven by having more competitive machine alternatives to humans in almost all societal functions, such as economic labor, decision making, artistic creation, and even companionship.},
	timestamp = {2025-08-22 10:11:53 (GMT)},
	title = {Gradual disempowerment},
	url = {https://gradual-disempowerment.ai/},
	urldate = {2025-08-22}
}

@article{Levy1983MisperceptionAndCauses,
	author = {Levy, Jack S.},
	title = {Misperception and the Causes of War: Theoretical Linkages and
                  Analytical Problems},
	volume = {36},
	number = {1},
	pages = {76--99},
	doi = {10.2307/2010176},
	url = {https://www.cambridge.org/core/journals/world-politics/article/abs/misperception-and-the-causes-of-war-theoretical-linkages-and-analytical-problems/DFDDA49BC9A073301BF957E2A0554BB5},
	abstract = {The author presents a conceptualization of different forms of misperception and the theoretical linkages by which they may lead to war under certain conditions. The forms of misperception most directly relevant to war include misperceptions of the capabilities and intentions of both adversaries and third states. The theoretical linkages to war, which vary across these different forms, include the intervening variables of military overconfidence, unsuccessful strategies of coercive diplomacy or appeasement, conflict spirals and arms races, preemptive strikes, or the failure to prepare for war or to attempt to deter the adversary. Particular attention is given to conceptual and methodological problems involved in the identification of misperceptions and in the assessment of their causal impact on war.},
	date = {1983-10},
	issn = {1086-3338, 0043-8871},
	journaltitle = {World Politics},
	langid = {english},
	shorttitle = {Misperception and the Causes of War},
	timestamp = {2025-08-27 15:33:03 (GMT)},
	urldate = {2025-08-27}
}

@article{Levy1985TheoriesOfGeneral,
	author = {Levy, Jack S.},
	title = {Theories of General War},
	volume = {37},
	number = {3},
	pages = {344--374},
	doi = {10.2307/2010247},
	url = {https://www.cambridge.org/core/journals/world-politics/article/abs/theories-of-general-war/67FF1194166413E399BE9C6475F720F8},
	abstract = {The phenomenon of general or hegemonic war has long been viewed as a distinctive kind of conflict, and one that has played a unique Robert Gilpin states: role in world history.},
	date = {1985-04},
	issn = {1086-3338, 0043-8871},
	journaltitle = {World Politics},
	langid = {english},
	timestamp = {2025-08-27 15:32:38 (GMT)},
	urldate = {2025-08-27}
}

@book{Levy2014WarInModern,
	langid = {english},
	author = {Levy, Jack S.},
	title = {War in the modern great power system: 1495-1975},
	publisher = {University Press of Kentucky},
	abstract = {The apparently accelerating arms race between the United States and the Soviet Union and the precarious political conditions existing in many parts of the world have given rise to new anxiety about the possibility of military confrontation between the superpowers. Despite the fateful nature of the risk, we have little knowledge, as Jack S. Levy has pointed out, 'of the conditions, processes, and events which might combine to generate such a calamity'. No empirically confirmed theory of the causes of war exists, and the hypotheses -often contradictory- that have been proposed remain untested. As a step toward the formulation of a theory of the causes of war that can be tested against historical experience, Levy has developed a unique data base that will serve as an invaluable resource for students of international conflict in coming years. 'War in the Modern Great Power System' provides a much-needed perspective on the major wars of the past. In this thorough and systematic study, Levy carefully defines the Great Power concept and identifies the Great Powers and their international wars since the late fifteenth century. The resulting compilation of war data is unique because of its five-century span and its focus on a well-defined set of Great Powers. Turning to a quantitative analysis of the characteristics, patterns, and trends in war, Levy demonstrates that although wars between the Great Powers have become increasingly serious in every respect but duration over the last five hundred years, their frequency has diminished. He rejects the popular view that the twentieth century has been the most warlike on record, and he demonstrates that it instead constitutes a return to the historical norm after the exceptionally peaceful nineteenth century. Applying his data to the question whether war is "contagious, " he finds that the likelihood of war is indeed highest when another war is under way, but that this contagious effect disappears after the first war is over. Contrary to the popular "war-weariness" theory, he finds no evidence that war generates an aversion to subsequent war. This study, extending the scientific analysis of war back over five centuries of international history, constitutes a major contribution to our knowledge of international conflict.},
	date = {2014},
	isbn = {9780813153391},
	location = {Lexington},
	shorttitle = {War in the modern great power system},
	timestamp = {2025-08-27 15:33:53 (GMT)}
}

@article{Liu2021Covid19And,
	abstract = {This study aims to investigate the contribution of aviation related travel restrictions to control the spread of COVID-19 in Europe by using quasi-experiment approaches including the regression discontinuity design and a two-stage spatial Durbin model with an instrumental variable. The study provides concrete evidence that the severe curtailing of flights had a spontaneous impact in controlling the spread of COVID-19. The counterfactual analysis encapsulated the spillover effects deduced that a 1\% decrease in flight frequency can decrease the number of confirmed cases by 0.908\%. The study also reveals that during the lockdown, the aviation industry cancelled over 795,000 flights, which resulted in averting an additional six million people being from being infected and saving 101,309 lives.},
	author = {Liu, Anyu and Kim, Yoo Ri and O'Connell, John Frankie},
	title = {{COVID}-19 and the Aviation Industry: the Interrelationship
                  Between the Spread of the {COVID}-19 Pandemic and the
                  Frequency of Flights on the {EU} Market},
	volume = {91},
	pages = {10329--8},
	doi = {10.1016/j.annals.2021.103298},
	date = {2021-11},
	issn = {01607383},
	journaltitle = {Annals of Tourism Research},
	langid = {english},
	shortjournal = {Annals of Tourism Research},
	shorttitle = {{COVID}-19 and the aviation industry},
	timestamp = {2025-07-02 21:10:14 (GMT)},
	urldate = {2025-07-02}
}

@Online{Lopate2022WesternLeadersOught,
	file = {~/My Drive/library-html/Lopate2022WesternLeadersOught.html;~/My Drive/library-pdf/Lopate2022WesternLeadersOught.pdf},
	langid = {english},
	date = {2022-06-06},
	author = {Lopate, Michael and Braumoeller, Bear F.},
	abstract = {While the United States and Europe have taken significant action to assist Ukraine and pressure Russia, there is increasing pressure to “do more.” With Russian war crimes in plain sight and Ukraine unable to trade with the world to sustain its economy, many feel a moral imperative to intervene and end the war. Simultaneously, continued Ukrainian success on the battlefield has some believing that with more support the Ukrainians can outright defeat Russia, pushing its forces back over the border without making any concessions.},
	journal = {War on the Rocks},
	timestamp = {2025-08-28 10:59:31 (GMT)},
	title = {Western leaders ought to take escalation over Ukraine seriously},
	url = {https://warontherocks.com/2022/06/western-leaders-ought-to-take-escalation-over-ukraine-seriously/},
	urldate = {2025-08-28},
	year = {2022}
}

@online{Macaskill2025IntroducingBetterFutures,
	file = {~/My Drive/library-html/Macaskill2025IntroducingBetterFutures.html;~/My Drive/library-pdf/Macaskill2025IntroducingBetterFutures.pdf},
	date = {2025-08-03},
	author = {{MacAskill}, William},
	abstract = {Suppose we want the future to go better. What should we do? Introduction to the “Better Futures” essay series. This essay series will argue that work on Flourishing is in the same ballpark of priority as work on Surviving. The basic case for this appeals to the scale, neglectedness and tractability of the two problems, where I think that Flourishing has greater scale and neglectedness, but probably lower tractability. This section informally states the argument; the supplement (“The Basic Case for Better Futures”) makes the case with more depth and precision.},
	journaltitle = {Forethought},
	langid = {english},
	timestamp = {2025-08-08 21:15:10 (GMT)},
	title = {Introducing Better Futures},
	url = {https://www.forethought.org/research/introducing-better-futures},
	urldate = {2025-08-08}
}

@article{Macaskill2025PreparingForIntelligence,
	author = {{MacAskill}, William and Moorhouse, Fin},
	title = {Preparing for the intelligence explosion},
	url = {https://www.forethought.org/research/preparing-for-the-intelligence-explosion},
	abstract = {AI that can accelerate research could drive a century of technological progress over just a few years. During such a period, new technological or political developments will raise consequential and hard-to-reverse decisions, in rapid succession. We call these developments grand challenges. These challenges include new weapons of mass destruction, AI-enabled autocracies, races to grab offworld resources, and digital beings worthy of moral consideration, as well as opportunities to dramatically improve quality of life and collective decision-making. We argue that these challenges cannot always be delegated to future AI systems, and suggest things we can do today to meaningfully improve our prospects. AGI preparedness is therefore not just about ensuring that advanced AI systems are aligned: we should be preparing, now, for the disorienting range of developments an intelligence explosion would bring.},
	date = {2025-03-11},
	journaltitle = {Forethought},
	langid = {english},
	shortjournal = {Forethought},
	timestamp = {2025-10-22 14:22:49 (GMT)},
	urldate = {2025-10-22}
}

@online{Macaskill2025SupplementBasicCase,
	abstract = {This report introduces a simplified model for evaluating actions aimed at producing long-term good outcomes: the “SF model”, where the expected value of the future can be approximated by the product of two variables, Surviving (S) and Flourishing (F). Surviving represents the probability of avoiding a near-total loss of value this century (an “existential catastrophe”), while Flourishing represents the expected value of the future conditional on our survival. Using this model and the “scale, neglectedness, tractability,” framework, we argue that interventions aimed at improving Flourishing are of comparable priority to those focused on Surviving.},
	file = {~/My Drive/library-pdf/Macaskill2025SupplementBasicCase.pdf},
	langid = {english},
	url = {https://www.forethought.org/research/supplement-the-basic-case-for-better-futures},
	date = {2025-08-03},
	journaltitle = {Forethought},
	title = {The basic case for better futures},
	author = {{MacAskill}, William and Trammell, Philip},
	timestamp = {2025-09-04 14:29:14 (GMT)}
}

@incollection{Martin2015TradeAndWar,
	abstract = {The next frontier for the study of trade and war will be the establishment of common microfoundations linking theories of trade to theories of conflict. Too much of the existing economic interdependence literature consists of empirical findings intended to resolve pragmatic debates; but since the evidence is inconclusive, and theories are imprecise, less has been learned than many would like. The literature would benefit from more rigorously defining the relationship between trade and the bargaining model of war. This chapter identifies three sets of causal mechanisms—constrain, inform, and transform—that appear to be likely candidates as drivers of the key findings in the literature. To operationalize and test these mechanisms, greater attention must be paid to the domestic politics of trade and foreign policy. By adopting a microfoundations approach, focusing on agency rather than outcomes, future research can unify disparate literatures and contradictory findings to gain new insights into the nature of trade and war.},
	langid = {english},
	author = {Martin, Lisa L. and Gartzke, Erik and Zhang, Jiakun Jack},
	booktitle = {The Oxford Handbook of the Political Economy of International Trade},
	date = {2015-05-01},
	doi = {10.1093/oxfordhb/9780199981755.013.27},
	editor = {Martin, Lisa L.},
	isbn = {9780199981755},
	publisher = {Oxford University Press},
	timestamp = {2025-08-27 15:32:43 (GMT)},
	title = {Trade and War},
	url = {https://academic.oup.com/edited-volume/34472/chapter/292501066},
	urldate = {2025-08-27}
}

@collection{Mcmahan2025DerekParfitHis,
	langid = {english},
	abstract = {"I shall not try to contribute to the discussion of his philosophy, because although I am also a philosopher, I am not really a Parfit scholar. This must sound like something earlier jurists might have called "petty treason" - the betrayal of a husband by a wife - but Derek and I agreed relatively early on that it would be better on the whole for us to pursue our work separately. This was partly because we had somewhat different interests and very different ways of working. But it was mainly because, as any student or colleague of Derek's knows well, there was no natural end to a discussion of any subject with which he was engaged. Once you had started, it was as though some philosophical Ancient Mariner had fixed you with his glittering eye and made escape impossible until the story was finished; and as it never was finished, serious engagement with his work, especially when we were in the same house, would have expanded to fill the whole of life"},
	date = {2025},
	edition = {1},
	editor = {{McMahan}, Jeff},
	isbn = {9780192894243},
	location = {New York},
	publisher = {Oxford University Press},
	shorttitle = {Derek parfit},
	timestamp = {2025-05-20 22:23:06 (GMT)},
	title = {Derek parfit: his life and thought}
}

@Book{Mill1874ThreeEssaysReligion,
	langid = {english},
	file = {~/My Drive/library-pdf/Mill1874ThreeEssaysReligion.pdf},
	address = {London},
	abstract = {This work examines the meaning and uses of the word "Nature," particularly in its relation to ethical thought. It distinguishes between two main senses of the term: the totality of phenomena and their laws, including human actions, and phenomena independent of human agency.  Using the first sense, acting "according to nature" is a meaningless imperative, since humans are necessarily part of nature and act within its laws.  The second sense, advocating for the imitation of nature as a moral guide, is deemed irrational and immoral. Irrational because human action's purpose is often to modify nature for the better, and immoral because nature itself perpetrates acts considered criminal in human society (killing, torture, indifference to suffering). The work critiques the idea that apparent evils in nature serve a greater good, arguing that even if true, imitating such behavior remains unacceptable.  Furthermore, while acknowledging that good often arises from evil, the reverse is equally true.  The essay proposes that nature is not a model for human conduct, but rather a scheme to be improved by human reason and ethics. It criticizes the elevation of instinct over reason, suggesting that most human virtues result from overcoming, not following, instincts. Finally, it argues for a higher standard of morality based on reason, benevolence, and a sense of unity with all humanity. – AI-generated abstract.},
	publisher = {Longmans, Green, Reader, and Dyer},
	date = {1874},
	title = {Three Essays on Religion: Nature, The Utility of Religion and Theism},
	author = {Mill, John Stuart},
	timestamp = {2025-04-22 16:09:35 (GMT)}
}

@article{Mordecai2019ThermalBiologyOf,
	author = {Mordecai, Erin A. and Caldwell, Jamie M. and Grossman, Marissa
                  K. and Lippi, Catherine A. and Johnson, Leah R. and Neira,
                  Marco and Rohr, Jason R. and Ryan, Sadie J. and Savage, Van
                  and Shocket, Marta S. and Sippy, Rachel and Stewart Ibarra,
                  Anna M. and Thomas, Matthew B. and Villena, Oswaldo},
	title = {Thermal Biology of Mosquito‐borne Disease},
	volume = {22},
	number = {10},
	pages = {1690--1708},
	doi = {10.1111/ele.13335},
	abstract = {Abstract Mosquito‐borne diseases cause a major burden of
                  disease worldwide. The vital rates of these ectothermic
                  vectors and parasites respond strongly and nonlinearly to
                  temperature and therefore to climate change. Here, we review
                  how trait‐based approaches can synthesise and mechanistically
                  predict the temperature dependence of transmission across
                  vectors, pathogens, and environments. We present 11 pathogens
                  transmitted by 15 different mosquito species – including
                  globally important diseases like malaria, dengue, and Zika –
                  synthesised from previously published studies. Transmission
                  varied strongly and unimodally with temperature, peaking at
                  23–29{ºC} and declining to zero below 9–23{ºC} and above
                  32–38{ºC}. Different traits restricted transmission at low
                  versus high temperatures, and temperature effects on
                  transmission varied by both mosquito and parasite species.
                  Temperate pathogens exhibit broader thermal ranges and cooler
                  thermal minima and optima than tropical pathogens. Among
                  tropical pathogens, malaria and Ross River virus had lower
                  thermal optima (25–26{ºC}) while dengue and Zika viruses had
                  the highest (29{ºC}) thermal optima. We expect warming to
                  increase transmission below thermal optima but decrease
                  transmission above optima. Key directions for future work
                  include linking mechanistic models to field transmission,
                  combining temperature effects with control measures,
                  incorporating trait variation and temperature variation, and
                  investigating climate adaptation and migration.},
	date = {2019-10},
	editor = {Byers, James (Jeb)},
	issn = {1461-023X, 1461-0248},
	journaltitle = {Ecology Letters},
	langid = {english},
	shortjournal = {Ecology Letters},
	timestamp = {2025-07-03 14:07:08 (GMT)},
	urldate = {2025-07-03}
}

@article{Mordechai2019JustinianicPlagueInconsequential,
	author = {Mordechai, Lee and Eisenberg, Merle and Newfield, Timothy P.
                  and Izdebski, Adam and Kay, Janet E. and Poinar, Hendrik},
	title = {The Justinianic Plague: an Inconsequential Pandemic?},
	volume = {116},
	number = {51},
	pages = {25546--25554},
	doi = {10.1073/pnas.1903797116},
	abstract = {Existing mortality estimates assert that the Justinianic
                  Plague (circa 541 to 750 {CE}) caused tens of millions of
                  deaths throughout the Mediterranean world and Europe, helping
                  to end antiquity and start the Middle Ages. In this article,
                  we argue that this paradigm does not fit the evidence. We
                  examine a series of independent quantitative and qualitative
                  datasets that are directly or indirectly linked to demographic
                  and economic trends during this two-century period: Written
                  sources, legislation, coinage, papyri, inscriptions, pollen,
                  ancient {DNA}, and mortuary archaeology. Individually or
                  together, they fail to support the maximalist paradigm: None
                  has a clear independent link to plague outbreaks and none
                  supports maximalist reconstructions of late antique plague.
                  Instead of large-scale, disruptive mortality, when
                  contextualized and examined together, the datasets suggest
                  continuity across the plague period. Although demographic,
                  economic, and political changes continued between the 6th and
                  8th centuries, the evidence does not support the now
                  commonplace claim that the Justinianic Plague was a primary
                  causal factor of them.},
	date = {2019-12-17},
	issn = {0027-8424, 1091-6490},
	journaltitle = {Proceedings of the National Academy of Sciences},
	langid = {english},
	shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
	shorttitle = {The Justinianic Plague},
	timestamp = {2025-07-02 21:03:46 (GMT)},
	urldate = {2025-07-02}
}

@article{Mordechai2019JustinianicPlagueInconsequentialb,
	author = {Mordechai, Lee and Eisenberg, Merle and Newfield, Timothy P.
                  and Izdebski, Adam and Kay, Janet E. and Poinar, Hendrik},
	title = {The Justinianic Plague: an Inconsequential Pandemic?},
	volume = {116},
	number = {51},
	pages = {25546--25554},
	doi = {10.1073/pnas.1903797116},
	abstract = {Existing mortality estimates assert that the Justinianic
                  Plague (circa 541 to 750 {CE}) caused tens of millions of
                  deaths throughout the Mediterranean world and Europe, helping
                  to end antiquity and start the Middle Ages. In this article,
                  we argue that this paradigm does not fit the evidence. We
                  examine a series of independent quantitative and qualitative
                  datasets that are directly or indirectly linked to demographic
                  and economic trends during this two-century period: Written
                  sources, legislation, coinage, papyri, inscriptions, pollen,
                  ancient {DNA}, and mortuary archaeology. Individually or
                  together, they fail to support the maximalist paradigm: None
                  has a clear independent link to plague outbreaks and none
                  supports maximalist reconstructions of late antique plague.
                  Instead of large-scale, disruptive mortality, when
                  contextualized and examined together, the datasets suggest
                  continuity across the plague period. Although demographic,
                  economic, and political changes continued between the 6th and
                  8th centuries, the evidence does not support the now
                  commonplace claim that the Justinianic Plague was a primary
                  causal factor of them.},
	date = {2019-12-17},
	issn = {0027-8424, 1091-6490},
	journaltitle = {Proceedings of the National Academy of Sciences},
	langid = {english},
	shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
	shorttitle = {The Justinianic Plague},
	timestamp = {2025-07-03 14:06:48 (GMT)},
	urldate = {2025-07-03}
}

@book{Morris2013MeasureCivilizationHow,
	langid = {english},
	location = {Princeton, New Jersey},
	title = {The measure of civilization: how social development decides the fate of nations},
	isbn = {978-1-4008-4476-0},
	url = {https://www.degruyter.com/view/books/9781400844760/9781400844760/9781400844760.xml},
	abstract = {In the last thirty years, there have been fierce debates over how civilizations develop and why the West became so powerful.The Measure of Civilizationpresents a brand-new way of investigating these questions and provides new tools for assessing the long-term growth of societies. Using a groundbreaking numerical index of social development that compares societies in different times and places, award-winning author Ian Morris sets forth a sweeping examination of Eastern and Western development across 15,000 years since the end of the last ice age. He offers surprising conclusions about when and why the West came to dominate the world and fresh perspectives for thinking about the twenty-first century. Adapting the United Nations' approach for measuring human development, Morris's index breaks social development into four traits--energy capture per capita, organization, information technology, and war-making capacity--and he uses archaeological, historical, and current government data to quantify patterns. Morris reveals that for 90 percent of the time since the last ice age, the world's most advanced region has been at the western end of Eurasia, but contrary to what many historians once believed, there were roughly 1,200 years--from about 550 to 1750 {CE}--when an East Asian region was more advanced. Only in the late eighteenth century {CE}, when northwest Europeans tapped into the energy trapped in fossil fuels, did the West leap ahead. Resolving some of the biggest debates in global history,The Measure of Civilizationputs forth innovative tools for determining past, present, and future economic and social trends.},
	publisher = {Princeton University Press},
	author = {Morris, Ian},
	date = {2013-12-31},
	doi = {10.1515/9781400844760},
	file = {~/My Drive/library-pdf/Morris2013MeasureCivilizationHow.pdf}
}

@book{Morsink2000UniversalDeclarationOf,
	abstract = {Born of a shared revulsion against the horrors of the Holocaust, the Universal Declaration of Human Rights has become the single most important statement of international ethics. It was inspired by and reflects the full scope of President Franklin Roosevelt's famous four freedoms: "the freedom of speech and expression, the freedom of worship, the freedom from want, and the freedom from fear." Written by a UN commission led by Eleanor Roosevelt and adopted in 1948, the Declaration has become the moral backbone of more than two hundred human rights instruments that are now a part of our world. The result of a truly international negotiating process, the document has been a source of hope and inspiration to thousands of groups and millions of oppressed individuals.},
	langid = {english},
	author = {Morsink, Johannes},
	title = {The Universal Declaration of Human Rights: origins, drafting and intent},
	publisher = {University of Pennsylvania Press},
	date = {2000},
	isbn = {9780812217476},
	location = {Philadelphia},
	pagetotal = {378},
	series = {Pennsylvania studies in human rights},
	shorttitle = {The Universal Declaration of Human Rights},
	timestamp = {2025-08-28 10:34:22 (GMT)}
}

@Online{Nalabandian2019BridgingHealthAnd,
	date = {2019},
	file = {~/My Drive/library-html/Nalabandian2019BridgingHealthAnd.html;~/My Drive/library-pdf/Nalabandian2019BridgingHealthAnd.pdf},
	langid = {english},
	abstract = {Global catastrophic biological risks (GCBRs), including pandemics and bioweapons, pose increasing threats due to technological advancements, global interconnectedness, and geopolitical instability.  Despite shared concerns among health and security experts, these risks remain inadequately addressed.  To bridge this gap, increased cross-sectoral dialogue is needed. Key priorities include increased and flexible funding for pandemic preparedness and response, encompassing both proactive capacity building and reactive measures. International coordination mechanisms, potentially under the UN Secretary General, are crucial for effective management of events exceeding existing organizational capacities.  Additionally, mitigating biological risks associated with rapid technological advancements requires collaborative efforts between the scientific community, health, and security sectors.  This involves assessing and mitigating risks throughout the research cycle, with investors and funders allocating resources towards risk identification.  Increased engagement by international security and global health leaders is critical, including interventions at the Biological Weapons Convention, the Global Health Security Agenda, and the Munich Security Conference. – AI-generated abstract.},
	author = {Nalabandian, Michelle and Nelson, Cassidy},
	journal = {The Nuclear Threat Initiative},
	timestamp = {2025-07-04 15:59:33 (GMT)},
	title = {Bridging health and security sectors to address high-consequence biological risks},
	url = {https://www.nti.org/risky-business/bridging-health-and-security-sectors-address-high-consequence-biological-risks/},
	urldate = {2025-07-04}
}

@online{Nedal2019RisksFromGreat,
	file = {~/My Drive/library-html/Nedal2019RisksFromGreat.html;~/My Drive/library-pdf/Nedal2019RisksFromGreat.pdf},
	date = {2019-08-29},
	author = {Nedal, Daniel},
	abstract = {Heightened competition between great powers poses significant direct and indirect risks to global stability. The direct risks include an increased likelihood of nuclear conflict, driven by the difficulty of deterrence among multiple nuclear states, the pursuit of "usable" nuclear weapons, and the erosion of non-proliferation norms. Competition also fuels proxy wars, making them longer, bloodier, and more prone to escalation. Indirectly, the focus on relative gains over shared benefits leads to a breakdown in global cooperation, hindering progress on transnational issues like pandemics and climate change. This results in policy fragmentation, increased restrictions on the activities of non-governmental organizations, and a weakening of international institutions. These dangers are amplified by rising nationalist ideologies and a general decay of trust in expertise. Counteracting these trends requires investing in new research on the mechanisms of cooperation, educating the public and policymakers on foreign policy risks, and developing alternative political frameworks that can overcome the failures of both traditional globalism and reactionary nationalism. – AI-generated abstract.},
	journaltitle = {Effective Altruism},
	langid = {english},
	shorttitle = {Dani Nedal},
	timestamp = {2025-08-27 15:32:30 (GMT)},
	title = {Risks from great-power competition},
	url = {https://www.effectivealtruism.org/articles/dani-nedal-risks-from-great-power-competition},
	urldate = {2025-08-27}
}

@article{Nelson2019EngineeredPathogensOpportunities,
	file = {~/My Drive/library-pdf/Nelson2019EngineeredPathogensOpportunities.pdf},
	author = {Nelson, Cassidy},
	title = {Engineered pathogens: the opportunities, risks and challenges},
	volume = {41},
	number = {3},
	pages = {34--39},
	doi = {10.1042/BIO04103034},
	abstract = {Before modern times, only nature was capable of engineering
                  pathogens. This ability was by no means unimpressive:
                  evolution has repeatedly demonstrated a formidable capacity
                  for producing a vast array of infectious agents. Pathogens
                  such as Variola major and Yersinia pestis, which cause
                  smallpox and plague respectively, wielded enough destructive
                  power to shape parts of human history. However, recent
                  advancements in biotechnology mean it is now possible to
                  engineer new viruses and bacteria. Developments in the field
                  of synthetic biology present many exciting opportunities,
                  enabling better understanding of disease-causing agents and
                  facilitating the creation of new medical therapeutics and
                  diagnostics. However, with these breakthroughs comes the risk
                  that some of the worst pathogens in history could be recreated
                  without requiring access to natural sources. Furthermore,
                  engineered microbes may surpass the destructive potential of
                  their evolved counterparts by being designed to be deadlier or
                  more transmissible. These enhanced agents could pose an
                  unprecedented pandemic threat to the global community. Given
                  the risks, it is essential that regulatory frameworks for
                  potentially hazardous research reflect modern capabilities and
                  address emerging biosecurity concerns.},
	date = {2019-06-01},
	issn = {0954-982X, 1740-1194},
	journaltitle = {The Biochemist},
	langid = {english},
	shorttitle = {Engineered pathogens},
	timestamp = {2025-07-04 15:54:13 (GMT)},
	urldate = {2025-07-04}
}

@Report{Nelson2019UkGovernmentS,
	langid = {english},
	file = {~/My Drive/library-pdf/Nelson2019UkGovernmentS.pdf},
	url = {https://www.fhi.ox.ac.uk/wp-content/uploads/UKG-Biosecurity-Written-Submission-C-Nelson-et-al.pdf},
	abstract = {The increasing accessibility and power of biotechnology, alongside natural and accidental threats, pose evolving biosecurity risks requiring a comprehensive UK strategy.  Dual-use research,  pathogen manipulation, and inadequate cyberbiosecurity oversight necessitate improved risk monitoring, assessment, and governance.  While the 2018 UK Biosecurity Strategy provides a foundation, critical gaps exist regarding emerging technological intersections, Brexit-related vulnerabilities, and dual-use research oversight.  Leveraging the UK’s robust bioeconomy through public-private partnerships, enhanced biosurveillance tools, and horizon scanning can strengthen preparedness.  Four recommendations are proposed:  appointing a liaison between bioscience and security communities; assigning ministerial responsibility for dual-use research and technology; forming a Biosecurity Leadership Council for stakeholder engagement and policy guidance; and establishing a National Centre for Biosecurity and Biosafety to drive positive cultural change and resource development across sectors. These integrated measures are crucial for mitigating biosecurity risks and promoting responsible innovation within the UK. – AI-generated abstract.},
	number = {written submission to the UK Parliament's Joint Committee on the National Security Strategy},
	date = {2019},
	author = {Nelson, Cassidy and Bonsall, Mike and Thompson, Robin and Millett, Kathryn and Collyer, Guy and Lewis, Gregory and Millett, Piers and Rutten, Paul and O'Brien, John and Rhodes, Catherine and Eccleston-Turner, Mark and Bezuidenhout, Louise and Hilton, Sam and Sándor, András and Du Plessis, Louis},
	title = {UK Government’s approach to emerging infectious diseases and bioweapons},
	timestamp = {2025-07-04 15:40:01 (GMT)}
}

@article{Newcombe1974DevelopmentOfInter,
	file = {~/My Drive/library-pdf/Newcombe1974DevelopmentOfInter.pdf},
	author = {Newcombe, Alan G. and Newcombe, Nora S. and Landrus, Gary D.},
	abstract = {A nation's military expenditure (M.E.) depends on its wealth (GNP), geography, and alliance memberships. This work develops a method to quantify inter-nation tension by first calculating a theoretical military expenditure (M.E.Th.) based solely on GNP, using data from 63 countries for the years 1964-1966. A "Tension Ratio" (T.R.) is then derived by dividing a nation's actual M.E. by its M.E.Th. Statistical analysis demonstrates a significant correlation between high T.R. values and involvement in armed conflict. Of the nations engaged in war, 76.9\% had a T.R. greater than 155, whereas only 26\% of nations not at war exceeded this threshold. The association remains significant when comparing T.R. values to wars that occurred in subsequent years, suggesting that the T.R. can serve as a predictive tool to identify critical situations. The study also finds that geography (such as proximity to a hostile neighbor) and neutrality appear to have a greater impact on a nation's tension level than membership in a military alliance. – AI-generated abstract.},
	title = {The Development of an Inter‐nation Tensiometer},
	volume = {1},
	number = {1},
	pages = {3--18},
	doi = {10.1080/03050627408434382},
	url = {http://www.tandfonline.com/doi/abs/10.1080/03050627408434382},
	date = {1974-01},
	issn = {0305-0629, 1547-7444},
	journaltitle = {International Interactions},
	langid = {english},
	shortjournal = {International Interactions},
	timestamp = {2025-08-27 15:32:34 (GMT)},
	urldate = {2025-08-27}
}

@article{Oneal1999KantianPeacePacific,
	langid = {english},
	author = {Oneal, John R and Russett, Bruce M},
	title = {The Kantian Peace: the Pacific Benefits of Democracy,
                  Interdependence, and International Organizations, 1885-1992},
	volume = {52},
	number = {1},
	pages = {1--37},
	url = {https://muse.jhu.edu/pub/1/article/36440},
	abstract = {, The authors test Kantian and realist theories of interstate
                  conflict using data extending over more than a century,
                  treating those theories as complementary rather than
                  competing. As the classical liberals believed, democracy,
                  economic interdependence, and international organizations have
                  strong and statistically significant effects on reducing the
                  probability that states will be involved in militarized
                  disputes. Moreover, the benefits are not limited to the cold
                  war era. Some realist influences, notably distance and power
                  predominance, also reduce the likelihood of interstate
                  conflict. The character of the international system, too,
                  affects the probability of dyadic disputes. The consequences
                  of having a strong hegemonic power vary, but high levels of
                  democracy and interdependence in the international system
                  reduce the probability of conflict for all dyads, not just for
                  those that are democratic or dependent on trade.},
	date = {1999},
	issn = {1086-3338},
	journaltitle = {World Politics},
	shorttitle = {The Kantian Peace},
	timestamp = {2025-08-27 15:32:46 (GMT)},
	urldate = {2025-08-27}
}

@book{Oneill1999HonorSymbolsAnd,
	abstract = {Nelson Mandela's presidential inauguration invitation to his former jailer; the construction and destruction of the Berlin Wall; the Gulf War's yellow ribbons. While the symbolic nuances of words and actions such as these are regular concerns for foreign policy practitioners, the subject has never been emphasized in international relations theory. That will change with the publication of this exceptionally original work. Many practitioners see symbolism as peripheral compared to resources, interests, military power, and alliances. Those who theorize about norms, ideas, and institutions tend to be open to the importance of symbolism, but they have not drawn out its details. Barry O'Neill's Honor, Symbols, and War puts symbolism at the center of the discussion. O'Neill uses the mathematical theory of games to study a network of concepts important in international negotiation and conflict resolution: symbolism, honor, face, prestige, insults, and apologies. His analysis clarifies the symbolic dynamics of several phenomena, including leadership, prenegotiation maneuvers, crisis tension, and arms-control agreements.},
	langid = {english},
	author = {O'Neill, Barry},
	title = {Honor, Symbols, and War},
	publisher = {The University of Michigan Press},
	date = {1999},
	isbn = {9780472109593},
	location = {Ann Arbor},
	pagetotal = {360},
	timestamp = {2025-08-27 15:32:32 (GMT)}
}

@incollection{Parfit2001RationalityReasons,
	isbn = {9781138634015},
	langid = {english},
	location = {Aldershot},
	abstract = {There are many kinds of normative reason, such as reasons for believing, for caring, and for acting. Reasons are provided by facts, such as the fact that someone's finger-prints are on some gun, or that calling an ambulance might save someone's life. According to desire-based theories, practical reasons are all provided by our desires, or aims. According to value-based theories, these reasons are provided by facts about what is relevantly good, or worth achieving. Desire-based theories are the ones that are most widely accepted. In economics and the other social sciences, rationality is often defined in a desirebased way. According to desire-based theories, in their only normative form: Some acts really are rational.},
	title = {Rationality and reasons},
	pages = {17–39},
	booktitle = {Exploring practical philosophy: from action to values},
	publisher = {Ashgate},
	author = {Parfit, Derek},
	editor = {Egonsson, Dan and Josefsson, Jonas and Petterson, Björn and Rønnow-Rasmussen, Toni},
	date = 2001,
	file = {~/My Drive/library-pdf/Parfit2001RationalityReasons.pdf}
}

@article{Patriarca2022TuberculosisSanatoriumSeason,
	abstract = {The creation of hospitals providing specialist care is not a prerogative of our time. As the world wonders how to cope with new pandemics and the age-old problems of the transmission of infections and the isolation of the sick, while the COVID-19 pandemic has been raging, it might be worth glancing back at the period - just over a century ago - when sanatoriums were set up in Italy as part of the fight against consumption.},
	langid = {english},
	author = {Patriarca, Carlo and Lo Bello, Giuseppe and Zannella, Stefano
                  and Agati, Sergio Arturo},
	title = {Tuberculosis: the Sanatorium Season in the Early 20th Century},
	volume = {114},
	number = {4},
	pages = {342--346},
	doi = {10.32074/1591-951X-333},
	date = {2022-09},
	issn = {1591-951X},
	journaltitle = {Pathologica},
	shortjournal = {Pathologica},
	shorttitle = {Tuberculosis},
	timestamp = {2025-06-03 10:55:41 (GMT)},
	urldate = {2025-06-03}
}

@online{Pricewaterhousecoopers2025WorldIn2050,
	date = {2025},
	abstract = {The report sets out long-term {GDP} projections for 32 of the largest economies in the world over the period to 2050.},
	author = {{PricewaterhouseCoopers}},
	journaltitle = {{PwC}},
	langid = {english},
	timestamp = {2025-08-27 15:32:49 (GMT)},
	title = {The World in 2050},
	url = {https://www.pwc.com/gx/en/research-insights/economy/the-world-in-2050.html},
	urldate = {2025-08-27}
}

@online{Regan2023IntroducingCsrS,
	file = {~/My Drive/library-html/Regan2023IntroducingCsrS.html;~/My Drive/library-pdf/Regan2023IntroducingCsrS.pdf},
	journaltitle = {Council on Strategic Risks},
	abstract = {The Biodefense Budget Breakdown is a resource dedicated to providing transparency into total biodefense investments within the U.S. federal budget},
	author = {Regan, Dan},
	date = {2023-12-07},
	langid = {english},
	timestamp = {2025-07-04 10:32:59 (GMT)},
	title = {Introducing {CSR}’s new Biodefense Budget Breakdown},
	url = {https://councilonstrategicrisks.org/2023/12/07/introducing-csrs-new-biodefense-budget-breakdown/},
	urldate = {2025-07-04}
}

@book{Richardson1975StatisticsOfDeadly,
	abstract = {This book compiles a database of "deadly quarrels" (conflicts resulting in human death) to quantitatively investigate war and its underlying mechanisms, influencing subsequent peace research by demonstrating the potential of interdisciplinary and data-driven approaches to complex societal questions.},
	langid = {english},
	author = {Richardson, Lewis Fry},
	title = {Statistics of deadly quarrels},
	publisher = {Boxwood Press},
	date = {1975},
	editor = {Wright, Quincy},
	isbn = {9780910286107},
	location = {Pacific Grove},
	pagetotal = {373},
	timestamp = {2025-08-27 15:33:56 (GMT)}
}

@book{Rieder1999EpidemiologicBasisOf,
	abstract = {Efficient tuberculosis control can be achieved in the absence of an extensive theoretical background. However, a thorough understanding of the etiologic agent, the clinical presentation of tuberculosis, the epidemiology of tuberculosis, the role of various intervention strategies, and of how to efficiently apply the tools currently available for the control of tuberculosis, is likely to increase the efficiency of a national tuberculosis program. A theoretical background will also help program managers at all levels to base their practice on modern concepts of tuberculosis control, and to justify their actions when these are questioned by others.},
	langid = {english},
	author = {Rieder, Hans L.},
	title = {Epidemiologic basis of tuberculosis control},
	publisher = {International union against tuberculosis and lung disease},
	date = {1999},
	isbn = {9782950423887},
	location = {Paris},
	timestamp = {2025-06-03 10:23:13 (GMT)}
}

@Report{Rivers2023ModernizingAndExpanding,
	langid = {english},
	file = {~/My Drive/library-pdf/Adalja2018CharacteristicsOfPandemicb.pdf},
	abstract = {A global catastrophic biological risk (GCBR) constitutes a sudden, widespread disaster beyond the control of governments and the private sector.  Several microbial characteristics, including efficient human-to-human transmission, a significant case fatality rate, lack of effective countermeasures, a largely immunologically naïve population, immune evasion mechanisms, and respiratory spread, heighten the risk of a GCBR.  Although any microbe could theoretically evolve into a GCBR-level threat, RNA viruses, with their high mutability and lack of broad-spectrum antivirals, pose the greatest danger.  Current efforts to catalog viral species, while scientifically valuable, may not translate directly into improved pandemic preparedness.  A more effective approach involves enhanced surveillance of respiratory RNA viruses, coupled with aggressive diagnostic testing of infectious disease syndromes in strategic locations. This, combined with increased vaccine and antiviral research specifically targeting RNA respiratory viruses and clinical research to optimize treatment protocols, would strengthen pandemic preparedness. Human factors, such as infrastructure limitations and flawed decision-making, can exacerbate outbreaks and elevate pathogens to GCBR status. – AI-generated abstract.},
	url = {https://centerforhealthsecurity.org/sites/default/files/2023-02/200324-outbreak-science.pdf},
	date = {2020},
	institution = {The Johns Hopkins Center for Health Security},
	author = {Rivers, Caitlin and Martin, Elena and Meyer, Diane and Inglesby, Thomas V. and Cicero, Anita and Cizek, Julia},
	title = {Modernizing and expanding outbreak science to support better decision making during public health crises: lessons for COVID-19 and beyond},
	timestamp = {2025-07-04 15:33:13 (GMT)}
}

@online{Rosado2024MoreThan80,
	date = {2024-05-31},
	author = {Rosado, Pablo},
	abstract = {According to the Food and Agriculture Organization of the United Nations, the number of land animals slaughtered for meat production has risen continuously for the past 60 years.},
	journaltitle = {Our World in Data},
	langid = {english},
	timestamp = {2025-07-03 23:37:52 (GMT)},
	title = {More than 80 billion land animals are slaughtered for meat every year},
	url = {https://ourworldindata.org/data-insights/billions-of-chickens-ducks-and-pigs-are-slaughtered-for-meat-every-year},
	urldate = {2025-07-03}
}

@book{Rudd2022AvoidableWarDangers,
	abstract = {

The relationship between the US and China, the world's two superpowers, is peculiarly volatile. It rests on a seismic fault-of cultural misunderstanding, historical grievance, and ideological incompatibility. No other nations are so quick to offend and be offended. Their militaries play a dangerous game of chicken, corporations steal intellectual property, intelligence satellites peer, and AI technicians plot. The capacity for either country to cross a fatal line grows daily. Kevin Rudd, a former Australian prime minister who has studied, lived in, and worked with China for more than forty years, is one of the very few people who can offer real insight into the mindsets of the leadership whose judgment will determine if a war will be fought. The Avoidable War demystifies the actions of both sides, explaining and translating them for the benefit of the other. Geopolitical disaster is still avoidable, but only if these two giants can find a way to coexist without betraying their core interests through what Rudd calls "managed strategic competition." Should they fail, down that path lies the possibility of a war that could rewrite the future of both countries, and the world.
},
	langid = {english},
	author = {Rudd, Kevin},
	title = {The Avoidable War: The Dangers of a Catastrophic Conflict between the {US} and Xi Jinping's China},
	publisher = {{PublicAffairs}},
	date = {2022},
	isbn = {9781541701298},
	location = {New York},
	pagetotal = {432},
	shorttitle = {The Avoidable War},
	timestamp = {2025-08-27 15:32:12 (GMT)}
}

@online{Ruhl2022AutonomousWeaponSystems,
	file = {~/My Drive/library-html/Ruhl2022AutonomousWeaponSystems.html;~/My Drive/library-pdf/Ruhl2022AutonomousWeaponSystems.pdf},
	date = {2022-05-19},
	abstract = {The likely future proliferation of autonomous weapon systems and military artificial intelligence applications presents under-studied strategic risks. These technologies can act as threat multipliers, exacerbating pathways to global catastrophic risks such as great power conflict and nuclear war. Specific dangers arise from accelerated decision-making, automation bias, increased system complexity leading to accidents and escalation, and the potential for destabilizing military AI competition. While public discourse and existing efforts often concentrate on humanitarian concerns and the pursuit of a formal, multilateral ban, this focus leaves the more fundamental strategic threats relatively neglected. A more tractable and impactful approach involves prioritizing funding for research into these strategic risks and developing confidence-building measures focused on the key state actors most likely to develop and deploy such systems. – AI-generated abstract.},
	journaltitle = {Founders Pledge},
	author = {Ruhl, Christian},
	langid = {english},
	timestamp = {2025-08-27 15:32:28 (GMT)},
	title = {Autonomous weapon systems and military artificial intelligence ({AI}) applications report},
	url = {https://www.founderspledge.com/research/autonomous-weapon-systems-and-military-artificial-intelligence-ai},
	urldate = {2025-08-27}
}

@article{Samotin2023ObstaclesToHarnessing,
	abstract = {We interviewed national security professionals to understand why the U.S. Intelligence Community has not systematically incorporated prediction markets or prediction polls into its intelligence reporting. This behavior is surprising since crowdsourcing platforms often generate more accurate predictions than traditional forms of intelligence analysis. Our interviews suggest that three principal barriers to adopting these platforms involved (i) bureaucratic politics, (ii) decision-makers lacking interest in probability estimates, and (iii) lack of knowledge about these platforms’ capabilities. Interviewees offered many actionable suggestions for addressing these challenges in future efforts to incorporate crowdsourcing platforms or other algorithmic tools into intelligence tradecraft.},
	author = {Samotin, Laura Resnick and Friedman, Jeffrey A. and Horowitz,
                  Michael C.},
	title = {Obstacles To Harnessing Analytic Innovations in Foreign Policy
                  Analysis: a Case Study of Crowdsourcing in the U.S.
                  Intelligence Community},
	volume = {38},
	number = {4},
	pages = {558--575},
	doi = {10.1080/02684527.2022.2142352},
	url = {https://www.tandfonline.com/doi/full/10.1080/02684527.2022.2142352},
	date = {2023-06-07},
	issn = {0268-4527, 1743-9019},
	journaltitle = {Intelligence and National Security},
	langid = {english},
	timestamp = {2025-08-27 15:33:08 (GMT)},
	urldate = {2025-08-27}
}

@article{Sandbrink2021BiosecurityRisksAssociated,
	author = {Sandbrink, Jonas B. and Koblentz, Gregory D.},
	title = {Biosecurity Risks Associated With Vaccine Platform
                  Technologies},
	volume = {40},
	number = {17},
	pages = {251--4},
	doi = {10.1016/j.vaccine.2021.02.023},
	abstract = {Vaccine platforms have been critical for accelerating the
                  timeline of {COVID}-19 vaccine development. Faster vaccine
                  timelines demand further development of these technologies.
                  Currently investigated platform approaches include virally
                  vectored and ...},
	date = {2021-02-25},
	journaltitle = {Vaccine},
	langid = {english},
	pmid = {33640142},
	timestamp = {2025-07-03 14:07:13 (GMT)},
	urldate = {2025-07-03}
}

@book{Sarkees2010ResortToWar,
	langid = {english},
	author = {Sarkees, Meredith Reid and Wayman, Frank Whelon},
	title = {Resort to war: a data guide to inter-state, extra-state, intra-state, and non-state wars, 1816-2007},
	publisher = {{CQ} Press},
	abstract = {This reference book analyzes more than a thousand wars waged from 1816 to 2007. It lists and categorizes all violent conflicts with 1,000 or more battle deaths and provides an insightful narrative for each struggle. It describes each encounter and highlights major patterns across eras and regions, identifying which categories of war are becoming more or less prevalent over time, and revealing the connections between the different types of war},
	date = {2010},
	isbn = {9780872894341},
	location = {Washington, D.C},
	series = {Correlates of war series},
	shorttitle = {Resort to war},
	timestamp = {2025-08-27 14:01:40 (GMT)}
}

@Article{Scharre2021DebunkingAiArms,
	langid = {english},
	pages = {121--132},
	number = {3},
	volume = {4},
	journaltitle = {Texas National Security Review},
	abstract = {There is no AI arms race. However, military competition in AI does still pose certain risks. These include losing human control and the acceleration of warfare, as well as the risk that perceptions of an arms race will cause competitors to cut corners on testing, leading to the deployment of unsafe AI systems.},
	author = {Scharre, Paul},
	langid = {english},
	timestamp = {2025-08-27 15:32:27 (GMT)},
	title = {Debunking the {AI} {Arms} {Race} {Theory}},
	url = {https://tnsr.org/2021/06/debunking-the-ai-arms-race-theory/},
	urldate = {2025-08-27},
	year = {2021}
}

@online{Shlegeris2024AiControlStrategies,
	langid = {english},
	file = {~/My Drive/library-pdf/Shlegeris2024AiControlStrategies.pdf},
	abstract = {This work addresses the challenge of mitigating catastrophic risks from advanced Artificial Intelligence (AI) by proposing an "AI control" approach, which assumes misalignment, particularly from "scheming" AIs—those strategically pursuing goals counter to human interests while potentially feigning alignment or sabotaging safety efforts. Instead of focusing on preventing AIs from becoming schemers (P(scheming)), this approach concentrates on reducing the probability of catastrophic outcomes given a scheming AI (P(doom | scheming)). The core premise is that evaluating and constraining AI capabilities is more tractable than ensuring their internal alignment. AI control aims to build systems robust to adversarial AI behavior, analogous to how organizations manage insider threats by assuming compromise and designing resilient systems. Techniques explored include trusted monitoring, where less capable but more reliable AIs review outputs from powerful, untrusted AIs, and untrusted monitoring with collusion-busting mechanisms like redaction and paraphrasing to prevent covert coordination. The objective is to establish a framework where AI deployment and system design are inherently secure against deceptive AIs, potentially offering significant risk reduction for AIs capable of outperforming human experts, though challenges remain for hypothetical superintelligences. – AI-generated abstract.},
	date = {2024-12-02},
	journaltitle = {YouTube},
	title = {AI control: strategies for mitigating catastrophic misalignment risk},
	author = {Shlegeris, Buck},
	timestamp = {2025-05-08 21:02:03 (GMT)},
	url = {https://www.youtube.com/supported_browsers?next_url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DJZYjz7D_auw},
	urldate = {2025-05-08}
}

@online{Shlegeris2025TenPeopleInside,
	file = {~/My Drive/library-pdf/Shlegeris2025TenPeopleInside.pdf;~/My Drive/library-html/Shlegeris2025TenPeopleInside.html},
	langid = {english},
	abstract = {The article discusses various regimes for AI misalignment risk mitigation, ranging from an ideal "safety case" scenario to more probable, pessimistic situations involving "rushed unreasonable developers." It focuses on a scenario within an AI company where ten safety-concerned individuals operate with limited political will, budget, and influence, attempting to mitigate risks despite the company's general disregard for specific misalignment threats. For these internal agents, interventions must be cheap, require minimal compute, and impose low compliance overhead to avoid being reversed. Proposed actions include gathering evidence of risk, implementing direct safety measures, and conducting alignment research. The author posits that such groups, even with minimal resources, could substantially reduce risk, highlighting the need for planning exportable safety research and external assistance, and advocating for current research to prioritize low-budget safety techniques applicable in these constrained environments. – AI-generated abstract.},
	author = {Shlegeris, Buck},
	date = {2025-01-27},
	journaltitle = {{AI} Alignment Forum},
	keywords = {{AI}},
	timestamp = {2025-10-09 14:52:25 (GMT)},
	title = {Ten people on the inside},
	url = {https://www.alignmentforum.org/posts/WSNnKcKCYAffcnrt2/ten-people-on-the-inside},
	urldate = {2025-10-09}
}

@article{Siler2022CumulativeAdvantageAnd,
	author = {Siler, Kyle and Vincent-Lamarre, Philippe and Sugimoto,
                  Cassidy R. and Larivière, Vincent},
	title = {Cumulative Advantage and Citation Performance of Repeat
                  Authors in Scholarly Journals},
	volume = {17},
	number = {4},
	pages = {e0265831},
	doi = {10.1371/journal.pone.0265831},
	abstract = {Cumulative advantage–commonly known as the Matthew
                  Effect–influences academic output and careers. Given the
                  challenge and uncertainty of gauging the quality of academic
                  research, gatekeepers often possess incentives to prefer the
                  work of established academics. Such preferences breach
                  scientific norms of universalism and can stifle innovation.
                  This article analyzes repeat authors within academic journals
                  as a possible exemplar of the Matthew Effect. Using
                  publication data for 347 economics journals from 1980–2017, as
                  well as from three major generalist science journals, we
                  analyze how articles written by repeat authors fare vis-à-vis
                  less-experienced authors. Results show that articles written
                  by repeat authors steadily decline in citation impact with
                  each additional repeat authorship. Despite these declines,
                  repeat authors also tend to garner more citations than debut
                  authors. These contrasting results suggest both benefits and
                  drawbacks associated with repeat authorships. Journals appear
                  to respond to feedback from previous publications, as
                  more-cited authors in a journal are more likely to be selected
                  for repeat authorships. Institutional characteristics of
                  journals also affect the likelihood of repeat authorship, as
                  well as citation outcomes. Repeat authorships–particularly in
                  leading academic journals–reflect innovative incentives and
                  professional reward structures, while also influencing the
                  intellectual content of science.},
	date = {2022-04-13},
	issn = {1932-6203},
	journaltitle = {{PLOS} {ONE}},
	keywords = {Citation analysis, Careers, Scientific publishing, Economics,
                  Economic impact analysis, Bibliometrics, Peer review,
                  Scientists},
	langid = {english},
	shortjournal = {{PLOS} {ONE}},
	timestamp = {2025-07-03 14:07:25 (GMT)},
	urldate = {2025-07-03}
}

@article{Smith2006EvidenceForRole,
	langid = {english},
	author = {Smith, Katherine F. and Sax, Dov F. and Lafferty, Kevin D.},
	title = {Evidence for the role of infectious disease in species
                  extinction and endangerment},
	volume = {20},
	number = {5},
	pages = {1349--1357},
	doi = {10.1111/j.1523-1739.2006.00524.x},
	abstract = {Infectious disease is listed among the top five causes of
                  global species extinctions. However, the majority of available
                  data supporting this contention is largely anecdotal. We used
                  the {IUCN} Red List of Threatened and Endangered Species and
                  literature indexed in the {ISI} Web of Science to assess the
                  role of infectious disease in global species loss. Infectious
                  disease was listed as a contributing factor in {\textless}4\%
                  of species extinctions known to have occurred since 1500 (833
                  plants and animals) and as contributing to a species' status
                  as critically endangered in {\textless}8\% of cases (2,852
                  critically endangered plants and animals). Although infectious
                  diseases appear to play a minor role in global species loss,
                  our findings underscore two important limitations in the
                  available evidence: uncertainty surrounding the threats to
                  species survival and a temporal bias in the data. Several
                  initiatives could help overcome these obstacles, including
                  rigorous scientific tests to determine which infectious
                  diseases present a significant threat at the species level,
                  recognition of the limitations associated with the lack of
                  baseline data for the role of infectious disease in species
                  extinctions, combining data with theory to discern the
                  circumstances under which infectious disease is most likely to
                  serve as an agent of extinction, and improving surveillance
                  programs for the detection of infectious disease. An
                  evidence-based understanding of the role of infectious disease
                  in species extinction and endangerment will help prioritize
                  conservation initiatives and protect global biodiversity.},
	date = {2006-10},
	issn = {0888-8892},
	journaltitle = {Conservation Biology: The Journal of the Society for
                  Conservation Biology},
	keywords = {Animals, Communicable Diseases, Extinction, Biological},
	pmid = {17002752},
	shortjournal = {Conserv Biol},
	timestamp = {2025-07-03 14:07:01 (GMT)}
}

@online{Stage2015WantedStupidProof,
	file = {~/My Drive/library-html/Stage2015WantedStupidProof.html;~/My Drive/library-pdf/Stage2015WantedStupidProof.pdf},
	author = {{The Scholar's Stage}},
	abstract = {A viable American foreign policy must be simple and robust enough to be implemented by a political system constrained by electoral cycles, partisanship, and a general lack of specialized expertise among its decision-makers. Such a "StupidProof" strategy is necessary because the system cannot sustain complex approaches, whether they be retrenchment or the proposed alternative of "deep engagement." The argument that deep engagement is necessary to cultivate local knowledge is flawed, as historical and contemporary evidence shows dominant powers consistently fail to achieve such nuanced understanding. Imperial Rome and China's interventions in peripheral territories often inadvertently created or strengthened the very threats they aimed to contain. Likewise, decades of modern American global engagement have not prevented repeated strategic surprises, demonstrating that this approach does not reliably produce the required regional acumen. A successful foreign policy must therefore be designed to operate effectively without depending on a level of expertise the American system is structurally ill-equipped to develop. – AI-generated abstract.},
	date = {2015-10-30},
	journaltitle = {The Scholar's Stage},
	langid = {english},
	shorttitle = {Wanted},
	timestamp = {2025-08-27 15:32:27 (GMT)},
	title = {Wanted: A Stupid-Proof Strategy For America},
	url = {https://scholars-stage.org/wanted-a-stupid-proof-strategy-for-america/},
	urldate = {2025-08-27}
}

@book{Stearns2021RoutledgeHistoryOf,
	file = {~/My Drive/library-pdf/Stearns2021RoutledgeHistoryOf.pdf},
	langid = {english},
	author = {Stearns, Peter N.},
	title = {The Routledge history of death since 1800},
	publisher = {Routledge, Taylor \& Francis Group},
	abstract = {The Routledge History of Death Since 1800 looks at how death has been treated and dealt with in modern history - the history of the past 250 years - in a global context, through a mix of definite, often quantifiable changes and a complex, qualitative assessment of the subject. The book is divided into three parts, with the first considering major trends in death history and identifying widespread patterns of change and continuity in the materal and cultural features of death since 1800. The second part turns to specifically regional experiences, and the third offers more specialized chapters on key topics in the modern history of death. Historical findings and debates feed directly into a current and prospective assessment of death, as many societies transition into patterns of ageing that will further alter the death experience and challenge modern reactions. Thus, a final chapter probes this topic, by way of introducing the links between historical experience and current trajectories, ensuring that the book gives the reader a framework for assessing the ongoing process, as well as an understanding of the past. Global in focus and linking death to a variety of major developments in modern global history, the volume is ideal for all those interested in the multifaceted history of how death is dealt with in different societies over time and who want access to the rich and growing historiography on the subject},
	date = {2021},
	isbn = {9780367137168},
	location = {London},
	timestamp = {2025-06-03 10:52:41 (GMT)}
}

@online{Strategic2023BiodefenseBudgetBreakdown,
	file = {~/My Drive/library-html/Strategic2023BiodefenseBudgetBreakdown.html;~/My Drive/library-pdf/Strategic2023BiodefenseBudgetBreakdown.pdf},
	eventdate = {2024-06-12},
	journaltitle = {The Council on Strategic Risks},
	author = {{The Council on Strategic Risks}},
	abstract = {Biodefense Budget Breakdown Data Visualization of U.S. Biodefense Investments In recent years, U.S. strategies and policies have advanced greatly in addressing biological risks from all sources. We at {CSR} have marked several areas of progress through writings and analysis: the beginning of a pivot toward pathogen-agnostic approaches, requiring annual exercises on biological risks, and the},
	date = {2023-12-05},
	langid = {english},
	timestamp = {2025-07-04 14:46:12 (GMT)},
	title = {Biodefense Budget Breakdown},
	url = {https://councilonstrategicrisks.org/nolan/biodefense-budget-breakdown/},
	urldate = {2025-07-04}
}

@online{Todd2015BestWayTo,
	file = {~/My Drive/library-html/Todd2015BestWayTo.html;~/My Drive/library-pdf/Todd2015BestWayTo.pdf},
	eventdate = {2025-08-18},
	date = {2015-08-28},
	author = {Todd, Benjamin},
	abstract = {In this article, we present a step-by-step process for making your next career decision. This process draws on the most useful discoveries in decision-making research1 and our experience advising thousands of people one-on-one.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2025-09-23 13:59:48 (GMT)},
	title = {The best way to make tough career decisions},
	url = {https://80000hours.org/career-decision/article/},
	urldate = {2025-09-23}
}

@online{Todd2021EffectiveAltruism,
	file = {~/My Drive/library-html/Todd2021EffectiveAltruism.html;~/My Drive/library-pdf/Todd2021EffectiveAltruism.pdf},
	date = {2021-09},
	author = {Todd, Benjamin},
	abstract = {It sounds obvious that it's better to help two people than one if the cost is the same. However, when applied to the world today, this obvious-sounding idea leads to surprising conclusions. In short, we believe we need a new approach to having an impact: effective altruism. Modern levels of wealth and technology have given some members of the present generation potentially enormous abilities to help others, while our common-sense views of what it means to be a good person have not caught up with this change.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2025-06-29 20:37:37 (GMT)},
	title = {Effective altruism},
	url = {https://80000hours.org/articles/effective-altruism/},
	urldate = {2025-06-29}
}

@online{Todd2023OrganisationBuilding,
	eventdate = {2023-12},
	file = {~/My Drive/library-html/Todd2023OrganisationBuilding.html;~/My Drive/library-pdf/Todd2023OrganisationBuilding.pdf},
	date = {2023-09},
	author = {Todd, Benjamin},
	abstract = {Find out how to help build and boost great organisations through skills like management, operations, legal and financial oversight, entrepreneurship and fundraising.},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2025-08-11 09:31:57 (GMT)},
	title = {Organisation-building},
	url = {https://80000hours.org/skills/organisation-building/},
	urldate = {2025-08-11}
}

@online{Tomasik2014ArtificialIntelligenceAnd,
	file = {~/My Drive/library-html/Tomasik2014ArtificialIntelligenceAnd.html;~/My Drive/library-pdf/Tomasik2014ArtificialIntelligenceAnd.pdf},
	abstract = {Artificial intelligence ({AI}) will likely transform the world later this century. Whether uncontrolled or controlled {AIs} would create more suffering in expectation is a question to explore further. Regardless, the field of {AI} safety and policy seems to be a very important space where altruists can make a positive-sum impact along many dimensions.},
	author = {Tomasik, Brian},
	date = {2014-05-14},
	journaltitle = {Center on Long-Term Risk},
	langid = {english},
	timestamp = {2025-04-21 13:24:04 (GMT)},
	title = {Artificial Intelligence and Its Implications for Future Suffering},
	url = {https://longtermrisk.org/artificial-intelligence-and-its-implications-for-future-suffering/},
	urldate = {2025-04-21}
}

@article{Waltz1990NuclearMythsAnd,
	author = {Waltz, Kenneth N.},
	title = {Nuclear myths and political realities},
	volume = {84},
	number = {3},
	pages = {730--745},
	doi = {10.2307/1962764},
	url = {https://www.cambridge.org/core/journals/american-political-science-review/article/abs/nuclear-myths-and-political-realities/9EF3533A2C5DDEFBADB0563BC86EE2F7},
	abstract = {Two pervasive beliefs have given nuclear weapons a bad name:
                  that nuclear deterrence is highly problematic, and that a
                  breakdown in deterrence would mean Armageddon. Both beliefs
                  are misguided and suggest that nearly half a century after
                  Hiroshima, scholars and policy makers have yet to grasp the
                  full strategic implications of nuclear weaponry. I contrast
                  the logic of conventional and nuclear weaponry to show how
                  nuclear weapons are in fact a tremendous force for peace and
                  afford nations that possess them the possibility of security
                  at reasonable cost.},
	date = {1990-09},
	issn = {0003-0554, 1537-5943},
	journaltitle = {American Political Science Review},
	langid = {english},
	timestamp = {2025-08-27 15:32:42 (GMT)},
	urldate = {2025-08-27}
}

@article{Whigham1999ParaguayanRosettaStone,
	author = {Whigham, Thomas L. and Potthast, Barbara},
	title = {The Paraguayan Rosetta Stone: New Insights Into the
                  Demographics of the Paraguayan War, 1864–1870},
	volume = {34},
	number = {1},
	pages = {174--186},
	doi = {10.1017/S0023879100024341},
	url = {https://www.cambridge.org/core/journals/latin-american-research-review/article/paraguayan-rosetta-stone-new-insights-into-the-demographics-of-the-paraguayan-war-18641870/96CAE01376E54D5376172E9398F4951B},
	abstract = {The demographics of the Paraguayan War (1864–1870) have long
                  fascinated historicans and sociologists. If the oft-repeated
                  tales of a 70 percent loss of life in Paraguay are accurate,
                  then this war represents a singular case in modern history,
                  one full of implications for students of militarism, gender,
                  and culture. This study analyzes a newly discovered census
                  from 1870 and reworks earlier censal materials. The authors
                  conclude that the old stories of a steep loss of population
                  during the war are basically correct.},
	date = {1999-01},
	issn = {0023-8791, 1542-4278},
	journaltitle = {Latin American Research Review},
	langid = {english},
	shorttitle = {The Paraguayan Rosetta Stone},
	timestamp = {2025-08-27 15:32:52 (GMT)},
	urldate = {2025-08-27}
}

@online{Wiblin2025BuckShlegerisControlling,
	file = {~/My Drive/library-html/Wiblin2025BuckShlegerisControlling.html;~/My Drive/library-pdf/Wiblin2025BuckShlegerisControlling.pdf},
	date = {2025-04-04},
	abstract = {Given the unlikelihood of solving AI alignment before superhuman systems emerge, AI control offers a backup strategy for deploying potentially misaligned AIs, even those suspected of scheming. This approach, acknowledging the reluctance of AI companies to delay deployment or incur high security costs, focuses on practical, inexpensive, and readily implementable safeguards to reduce harm. Techniques involve auditing AI actions, potentially with less capable but trusted models, replacing suspicious AI outputs, and methods designed to detect deceptive behaviors. These control mechanisms are particularly relevant for near-human-level AIs used in research, which may possess dangerous permissions like accessing model weights or modifying code. The objective is to enable the continued use of advanced AI by mitigating acute risks such as data center hacking or research sabotage, and also addressing chronic harms like subtle underperformance. While AI control may have limitations against vastly superhuman AIs, it provides a pragmatic path for managing risks from current and near-future advanced systems. – AI-generated abstract.},
	author = {Wiblin, Robert},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2025-05-08 20:59:39 (GMT)},
	title = {Buck Shlegeris on controlling {AI} that wants to take over – so we can use it anyway},
	url = {https://80000hours.org/podcast/episodes/buck-shlegeris-ai-control-scheming/},
	urldate = {2025-05-08}
}

@online{Wiblin2025WillMacaskillAi,
	file = {~/My Drive/library-html/Wiblin2025WillMacaskillAi.html;~/My Drive/library-pdf/Wiblin2025WillMacaskillAi.pdf},
	date = {2025-03-11},
	abstract = {Humanity is on the cusp of transformative artificial intelligence, potentially within the next decade.  Current AI systems are nearing human-level capability in research and intellectual tasks.  Once AI surpasses human ability in AI research itself, a recursive self-improvement cycle will begin, rapidly escalating AI capabilities.  This acceleration will compress centuries of potential technological advancement into mere years, challenging human institutions and decision-making processes, which are much slower to adapt. This rapid change necessitates addressing several grand challenges: the proliferation of destructive technologies, the concentration of power, securing digital rights for potentially conscious AI, and establishing effective space governance.  AI could exacerbate existing risks, like nuclear war, or create entirely novel threats via technologies like nanotechnology or autonomous drone armies.  Additionally, the potential for a single actor to seize control of advanced AI, or unilaterally exploit space resources, necessitates proactive governance solutions.  While AI safety is crucial, ensuring a flourishing future—not just preventing extinction—requires addressing these complex institutional and ethical issues now. Proactive measures could include educating policymakers on AI capabilities, developing AI-assisted governance tools, and creating temporary governance structures that acknowledge the rapidly changing technological landscape. – AI-generated abstract.},
	author = {Wiblin, Robert},
	journaltitle = {80,000 Hours},
	langid = {english},
	timestamp = {2025-06-23 15:26:54 (GMT)},
	title = {Will {MacAskill} on {AI} causing a “century in a decade” — and how we're completely unprepared},
	url = {https://80000hours.org/podcast/episodes/will-macaskill-century-in-a-decade-navigating-intelligence-explosion/},
	urldate = {2025-06-23}
}

@article{Zurcher2016TuberculosisMortalityAnd,
	file = {~/My Drive/library-pdf/Zurcher2016TuberculosisMortalityAnd.pdf},
	abstract = {Background: Tuberculosis (TB) is a poverty-related disease that is associated with poor living conditions. We studied TB mortality and living conditions in Bern between 1856 and 1950. Methods: We analysed cause-specific mortality based on mortality registers certified by autopsies, and public health reports 1856 to 1950 from the city council of Bern. Results: TB mortality was higher in the Black Quarter (550 per 100,000) and in the city centre (327 per 100,000), compared to the outskirts (209 per 100,000 in 1911-1915). TB mortality correlated positively with the number of persons per room (r = 0.69, p = 0.026), the percentage of rooms without sunlight (r = 0.72, p = 0.020), and negatively with the number of windows per apartment (r = -0.79, p = 0.007). TB mortality decreased 10-fold from 330 per 100,000 in 1856 to 33 per 100,000 in 1950, as housing conditions improved, indoor crowding decreased, and open-air schools, sanatoria, systematic tuberculin skin testing of school children and chest radiography screening were introduced. Conclusions: Improved living conditions and public health measures may have contributed to the massive decline of the TB epidemic in the city of Bern even before effective antibiotic treatment became finally available in the 1950s.},
	author = {Zürcher, Kathrin and Ballif, Marie and Zwahlen, Marcel and
                  Rieder, Hans L. and Egger, Matthias and Fenner, Lukas},
	title = {Tuberculosis mortality and living conditions in Bern,
                  Switzerland, 1856-1950},
	number = {11(2), e0149195},
	doi = {10.1371/journal.pone.0149195},
	date = {2016-02-16},
	editor = {Dowdy, David W.},
	issn = {1932-6203},
	journaltitle = {{PLOS} {ONE}},
	langid = {english},
	shortjournal = {{PLoS} {ONE}},
	timestamp = {2025-06-03 10:40:44 (GMT)},
	urldate = {2025-06-03}
}

